{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q peft bitsandbytes accelerate datasets tensorboardX loralib\n",
    "!pip install -q --upgrade git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "Using MPS device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "# Purpose of notebook: fine-tune LongT5 on exctracted sentences from studies, but using LoRA and bitsandbytes quantization\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    LongT5ForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS device.\")\n",
    "    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = \"0.0\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA device.\")\n",
    "    max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "    os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"MPS/CUDA not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d19e998382e4787be444409ebb0c6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/14188 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6eb9fe8f664caa90006a5b33315400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/11350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6791bfa45cb643c1bec2f2a5664309d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2838 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14188\n",
      "11350\n",
      "2838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "model_id = 'pszemraj/long-t5-tglobal-base-16384-book-summary'\n",
    "output_dir = \"training_history\"\n",
    "# output_dir = \"/content/drive/MyDrive/266 final project/notebooks/peft_training_history\"  # Colab\n",
    "\n",
    "extracted_file_path = '../experiment_1/biobert_extractive_only_training_dataset.csv.gz'\n",
    "# extracted_file_path = '/content/drive/MyDrive/266 final project/notebooks/biobert_extractive_only_training_dataset.csv.gz'  # Colab\n",
    "\n",
    "# longT5 max token length is 16384\n",
    "max_input_token_length = 8192\n",
    "\n",
    "ms2_dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split=\"train\")\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(extracted_file_path, compression='gzip')\n",
    "\n",
    "# # ---- not available yet. in the meantime:\n",
    "# all_extracted_summaries = []\n",
    "# for fpath in os.listdir('../experiment_1/biobert_extractive_only_training_dataset'):\n",
    "#     all_extracted_summaries.append(\n",
    "#         pickle.load(open(os.path.join('../experiment_1/biobert_extractive_only_training_dataset', fpath), 'rb'))\n",
    "#     )\n",
    "# df = pd.DataFrame(all_extracted_summaries)\n",
    "# # ----\n",
    "\n",
    "target_texts = ms2_dataset['target']\n",
    "input_texts = [\n",
    "    df[df['review_id'] == int(i)]['summary'].tolist()[0] for i in ms2_dataset['review_id']\n",
    "]\n",
    "dataset = Dataset.from_dict({'input_text': input_texts, 'target_text': target_texts})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Tokenize data\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples['input_text'], padding='max_length', truncation=True, max_length=max_input_token_length)\n",
    "    labels = tokenizer(text_target=examples['target_text'], padding='max_length', truncation=True, max_length=256)\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"input_text\", \"target_text\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_datasets.features)}\")\n",
    "\n",
    "label_pad_token_id = -100\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model_id,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    ")\n",
    "\n",
    "# Split the dataset\n",
    "shuffle_dataset = tokenized_datasets.shuffle(seed=42)\n",
    "shuffle_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "train_dataset = shuffle_dataset.select(range(len(tokenized_datasets) * 8 // 10))\n",
    "val_dataset = shuffle_dataset.select(range(len(tokenized_datasets) * 8 // 10, len(tokenized_datasets)))\n",
    "\n",
    "# save to disk for easy loading\n",
    "train_dataset.save_to_disk('data/train_tokenized_dataset')\n",
    "val_dataset.save_to_disk('data/val_tokenized_dataset')\n",
    "\n",
    "print(shuffle_dataset.num_rows)\n",
    "print(train_dataset.num_rows)\n",
    "print(val_dataset.num_rows)\n",
    "\n",
    "type(shuffle_dataset[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11350.000000\n",
       "mean        86.599912\n",
       "std         57.467615\n",
       "min          9.000000\n",
       "25%         44.000000\n",
       "50%         70.000000\n",
       "75%        114.000000\n",
       "max        256.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% percentile is 214.0\n"
     ]
    }
   ],
   "source": [
    "# ANALYSIS: what's the distribution of non-padding tokens in train_dataset[\"labels\"]?\n",
    "all_tokens = train_dataset[\"labels\"].numpy()\n",
    "non_pad_token_counts = np.array([len(np.where(tokens != label_pad_token_id)[0]) for tokens in all_tokens])\n",
    "# distribution of non_pad_token_counts\n",
    "display(pd.Series(non_pad_token_counts).describe())\n",
    "\n",
    "# what's the 95% percentile?\n",
    "print(\"95% percentile is\", np.percentile(non_pad_token_counts, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11350.000000\n",
       "mean      3661.722291\n",
       "std       2308.642882\n",
       "min         71.000000\n",
       "25%       1855.000000\n",
       "50%       3050.000000\n",
       "75%       5047.000000\n",
       "max       8192.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% percentile is 8192.0\n",
      "If we truncated input_ids to 8192, this is the percentile it'll be at (anything at a higher percentile could risk losing information): 0.9473568281938326\n",
      "8192.0\n"
     ]
    }
   ],
   "source": [
    "# ANALYSIS: what's the distribution of non-padding tokens in train_dataset[\"input_ids\"]?\n",
    "all_tokens = train_dataset[\"input_ids\"].numpy()\n",
    "non_pad_token_counts = np.array([len(np.where(tokens != 0)[0]) for tokens in all_tokens])\n",
    "# distribution of non_pad_token_counts\n",
    "display(pd.Series(non_pad_token_counts).describe())\n",
    "\n",
    "# what's the 95% percentile?\n",
    "print(\"95% percentile is\", np.percentile(non_pad_token_counts, 95))\n",
    "\n",
    "# which percentile is \"8192 non-padding tokens\" on?\n",
    "print(\n",
    "    \"If we truncated input_ids to 8192, this is the percentile it'll be at (anything at a higher percentile could risk losing information):\",\n",
    "    (perc_8192 := pd.Series(non_pad_token_counts).rank(pct=True)[np.where(non_pad_token_counts <= 8192)[0]].max())\n",
    ")\n",
    "# confirm\n",
    "print(np.percentile(non_pad_token_counts, perc_8192 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 248,472,192 || trainable%: 0.3560704289999583\n"
     ]
    }
   ],
   "source": [
    "# bitsandbytes\n",
    "# Source notebooks:\n",
    "# - https://colab.research.google.com/drive/1Vvju5kOyBsDr7RX_YAvp6ZsSOoSMjhKD?usp=sharing#scrollTo=E0Nl5mWL0k2T\n",
    "# - https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing#scrollTo=HOWcL0LU3JYt\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    # load_in_8bit=True,\n",
    ")\n",
    "\n",
    "base_model = LongT5ForConditionalGeneration.from_pretrained(model_id)\n",
    "model = LongT5ForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    # quantization_config=bnb_config,  # enable when in CUDA\n",
    "    # load_in_8bit=True,\n",
    "    # device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# BUG: `model` has its embeddings reinitiated. Copy over from `base_model` but retain data type\n",
    "# reinited_params = ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
    "# for param_name in reinited_params:\n",
    "#     model_param = model.get_parameter(param_name)\n",
    "#     base_model_param = base_model.get_parameter(param_name)\n",
    "#     model_param.data = base_model_param.data.to(model_param.dtype)\n",
    "\n",
    "# use PEFT LoRA\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    # target_modules=[\"q\", \"v\", \"k\"],\n",
    "    # target_modules=[\"q\", \"v\"],\n",
    "    target_modules=[\"q\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "# model = prepare_model_for_kbit_training(model)  # enable for 4bit or 8bit quantization\n",
    "model.enable_input_require_grads()\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Fix idea from this GitHub issue: https://github.com/huggingface/peft/issues/522#issuecomment-1705989330\n",
    "model.base_model.model.encoder.enable_input_require_grads()\n",
    "model.base_model.model.decoder.enable_input_require_grads()\n",
    "model.train()\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(output_dir, \"longt5-qlora\"),\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,  # Adjust batch size according to memory constraints\n",
    "    evaluation_strategy=\"steps\",  # or, \"epoch\" ?\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    max_steps=100,  # For debugging\n",
    "    learning_rate=1e-4,\n",
    "    logging_dir=os.path.join(output_dir, \"longt5-qlora\", \"logs\"),\n",
    "    logging_steps=50,\n",
    "    # # for 4bit or 8bit quantization\n",
    "    # fp16=True,\n",
    "    # optim=\"paged_adamw_8bit\",  # default: adamw_torch\n",
    ")\n",
    "\n",
    "# training_args = Seq2SeqTrainingArguments(\n",
    "#     output_dir=os.path.join(output_dir, \"longt5-qlora\"),\n",
    "#     num_train_epochs=1,  # For debugging\n",
    "#     auto_find_batch_size=True,\n",
    "#     evaluation_strategy=\"steps\",  # alternatively, \"epoch\"\n",
    "#     eval_steps=500,\n",
    "#     max_steps=100,  # For debugging\n",
    "#     learning_rate=1e-4,\n",
    "#     logging_dir=os.path.join(output_dir, \"longt5-qlora\", \"logs\"),\n",
    "#     logging_steps=50,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     report_to=\"tensorboard\",\n",
    "#     # # for 4bit or 8bit quantization\n",
    "#     # fp16=True,\n",
    "#     # optim=\"paged_adamw_8bit\",  # default: adamw_torch\n",
    "# )\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "# )\n",
    "\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5561,  0.4233,  0.8544,  ..., -0.9618,  0.6647,  0.9398],\n",
       "        [ 0.4269,  1.6681,  4.5766,  ..., -2.2274, -0.5151,  2.1782],\n",
       "        [-5.4195, -2.4177, -0.8740,  ..., -0.2788, -1.3139, -1.5880],\n",
       "        ...,\n",
       "        [ 1.5533,  0.5635,  1.6218,  ...,  1.9036,  0.7348,  0.1447],\n",
       "        [ 0.2494,  0.8528, -0.6396,  ...,  0.1166, -1.1269,  0.8604],\n",
       "        [ 0.8795, -0.3369, -1.7056,  ...,  0.4987,  1.2487,  0.6472]],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameter(\"encoder.embed_tokens.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='mps:0', requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameter(\"encoder.block.0.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()  # Colab\n",
    "torch.mps.empty_cache()  # MPS\n",
    "\n",
    "model.device\n",
    "# model.hf_device_map  # enable for 4bit or 8bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try inferring for a single example\n",
    "id_to_choose = 1\n",
    "inputs = tokenizer(dataset[id_to_choose]['input_text'], return_tensors='pt').to(device)\n",
    "labels = tokenizer(dataset[id_to_choose]['target_text'], return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = base_model.generate(**inputs, max_new_tokens=256, num_beams=4)\n",
    "output = model.generate(**inputs, max_new_tokens=256, num_beams=4)\n",
    "# output = trainer.model.generate(**inputs, max_new_tokens=256, num_beams=4)\n",
    "pprint(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "pprint(dataset[id_to_choose][\"target_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/torch/utils/checkpoint.py:441: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/torch/utils/checkpoint.py:73: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/transformers/models/longt5/modeling_longt5.py:74: UserWarning: MPS: The constant padding of more than 3 dimensions is not currently supported natively. It uses View Ops default implementation to run. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Pad.mm:474.)\n",
      "  x = nn.functional.pad(x, pad=pad, mode=\"constant\", value=pad_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006]) torch.int64 mps:0\n",
      "tensor torch.Size([1, 8, 12, 128, 446]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/transformers/modeling_utils.py:865: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([1, 228, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 228]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1006, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 1, 1, 1006]) torch.float32 mps:0\n",
      "tensor torch.Size([1, 12, 228, 1006]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n"
     ]
    }
   ],
   "source": [
    "call_outputs = model(**inputs, labels=labels['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5540, device='mps:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16384])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_sample_input_ids = train_dataset[\"input_ids\"][:1].to(device)\n",
    "one_sample_attention_mask = train_dataset[\"attention_mask\"][:1].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(one_sample_input_ids, attention_mask=one_sample_attention_mask, return_dict=True)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.shared.weight False\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.relative_attention_bias.weight False\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.global_relative_attention_bias.weight False\n",
      "base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.0.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.0.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.0.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.0.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.0.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.1.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.1.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.1.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.1.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.1.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.2.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.2.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.2.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.2.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.2.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.3.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.3.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.3.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.3.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.3.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.4.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.4.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.4.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.4.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.4.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.5.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.5.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.5.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.5.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.5.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.6.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.6.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.6.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.6.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.6.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.7.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.7.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.7.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.7.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.7.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.8.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.8.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.8.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.8.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.8.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.9.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.9.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.9.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.9.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.9.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.10.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.10.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.10.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.10.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.10.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.q.weight False\n",
      "base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.k.weight False\n",
      "base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.v.weight False\n",
      "base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.o.weight False\n",
      "base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.global_input_layer_norm.weight False\n",
      "base_model.model.encoder.block.11.layer.0.layer_norm.weight False\n",
      "base_model.model.encoder.block.11.layer.1.DenseReluDense.wi_0.weight False\n",
      "base_model.model.encoder.block.11.layer.1.DenseReluDense.wi_1.weight False\n",
      "base_model.model.encoder.block.11.layer.1.DenseReluDense.wo.weight False\n",
      "base_model.model.encoder.block.11.layer.1.layer_norm.weight False\n",
      "base_model.model.encoder.final_layer_norm.weight False\n",
      "base_model.model.decoder.block.0.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.0.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.0.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.0.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight False\n",
      "base_model.model.decoder.block.0.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.0.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.0.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.0.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.0.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.0.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.0.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.0.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.0.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.0.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.1.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.1.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.1.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.1.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.1.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.1.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.1.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.1.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.1.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.1.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.1.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.1.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.1.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.1.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.2.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.2.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.2.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.2.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.2.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.2.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.2.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.2.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.2.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.2.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.2.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.2.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.2.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.2.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.3.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.3.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.3.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.3.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.3.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.3.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.3.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.3.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.3.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.3.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.3.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.3.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.3.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.3.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.4.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.4.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.4.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.4.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.4.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.4.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.4.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.4.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.4.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.4.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.4.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.4.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.4.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.4.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.5.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.5.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.5.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.5.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.5.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.5.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.5.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.5.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.5.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.5.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.5.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.5.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.5.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.5.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.6.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.6.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.6.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.6.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.6.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.6.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.6.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.6.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.6.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.6.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.6.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.6.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.6.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.6.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.7.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.7.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.7.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.7.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.7.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.7.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.7.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.7.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.7.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.7.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.7.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.7.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.7.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.7.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.8.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.8.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.8.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.8.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.8.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.8.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.8.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.8.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.8.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.8.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.8.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.8.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.8.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.8.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.9.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.9.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.9.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.9.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.9.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.9.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.9.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.9.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.9.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.9.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.9.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.9.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.9.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.9.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.10.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.10.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.10.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.10.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.10.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.10.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.10.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.10.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.10.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.10.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.10.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.10.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.10.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.10.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.block.11.layer.0.SelfAttention.q.weight False\n",
      "base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.11.layer.0.SelfAttention.k.weight False\n",
      "base_model.model.decoder.block.11.layer.0.SelfAttention.v.weight False\n",
      "base_model.model.decoder.block.11.layer.0.SelfAttention.o.weight False\n",
      "base_model.model.decoder.block.11.layer.0.layer_norm.weight False\n",
      "base_model.model.decoder.block.11.layer.1.EncDecAttention.q.weight False\n",
      "base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight True\n",
      "base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight True\n",
      "base_model.model.decoder.block.11.layer.1.EncDecAttention.k.weight False\n",
      "base_model.model.decoder.block.11.layer.1.EncDecAttention.v.weight False\n",
      "base_model.model.decoder.block.11.layer.1.EncDecAttention.o.weight False\n",
      "base_model.model.decoder.block.11.layer.1.layer_norm.weight False\n",
      "base_model.model.decoder.block.11.layer.2.DenseReluDense.wi_0.weight False\n",
      "base_model.model.decoder.block.11.layer.2.DenseReluDense.wi_1.weight False\n",
      "base_model.model.decoder.block.11.layer.2.DenseReluDense.wo.weight False\n",
      "base_model.model.decoder.block.11.layer.2.layer_norm.weight False\n",
      "base_model.model.decoder.final_layer_norm.weight False\n",
      "base_model.model.lm_head.weight False\n"
     ]
    }
   ],
   "source": [
    "for name, param in trainer.model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor without grad_fn: base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.0.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.1.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.2.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.3.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.4.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.5.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.6.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.7.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.8.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.9.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.10.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.encoder.block.11.layer.0.TransientGlobalSelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.0.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.0.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.1.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.1.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.2.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.2.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.3.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.3.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.4.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.4.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.5.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.5.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.6.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.6.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.7.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.7.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.8.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.8.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.9.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.9.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.10.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.10.layer.1.EncDecAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.11.layer.0.SelfAttention.q.lora_B.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_A.default.weight\n",
      "Tensor without grad_fn: base_model.model.decoder.block.11.layer.1.EncDecAttention.q.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "def find_tensor_without_grad_fn(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.grad is None:\n",
    "            print(f\"Tensor without grad_fn: {name}\")\n",
    "\n",
    "find_tensor_without_grad_fn(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f1d46d9f7444c4b34d4a7642374794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/torch/utils/checkpoint.py:441: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/transformers/modeling_utils.py:865: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 1 tensors\n",
      "backward ran successfully for 1 tensors\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192]) torch.int64 mps:0\n",
      "tensor torch.Size([2, 64, 12, 128, 896]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "check_backward_validity\n",
      "len(inputs) 11\n",
      "tensor torch.Size([2, 256, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 256]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 8192, 768]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 1, 1, 8192]) torch.float32 mps:0\n",
      "tensor torch.Size([2, 12, 256, 8192]) torch.float32 mps:0\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor NoneType\n",
      "non-tensor bool\n",
      "non-tensor bool\n",
      "end check_backward_validity\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 3 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 2 tensors\n",
      "backward ran successfully for 1 tensors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaelenghoekhor/Documents/GitHub/266_final_proj/experiment_5_peft/peft_kmeans_longt5.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelenghoekhor/Documents/GitHub/266_final_proj/experiment_5_peft/peft_kmeans_longt5.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaelenghoekhor/Documents/GitHub/266_final_proj/experiment_5_peft/peft_kmeans_longt5.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Downloads/pytorch-test/env/lib/python3.8/site-packages/transformers/trainer.py:1530\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1528\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1529\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1530\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1531\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1532\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1533\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1534\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1535\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/pytorch-test/env/lib/python3.8/site-packages/transformers/trainer.py:1844\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1843\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1844\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1846\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1847\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1848\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1849\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1850\u001b[0m ):\n\u001b[1;32m   1851\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1852\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Downloads/pytorch-test/env/lib/python3.8/site-packages/transformers/trainer.py:2710\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   2709\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2710\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[1;32m   2712\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/Downloads/pytorch-test/env/lib/python3.8/site-packages/accelerate/accelerator.py:1989\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1989\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Downloads/pytorch-test/env/lib/python3.8/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/pytorch-test/env/lib/python3.8/site-packages/torch/autograd/__init__.py:253\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39m# try/except\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    254\u001b[0m         tensors,\n\u001b[1;32m    255\u001b[0m         grad_tensors_,\n\u001b[1;32m    256\u001b[0m         retain_graph,\n\u001b[1;32m    257\u001b[0m         create_graph,\n\u001b[1;32m    258\u001b[0m         inputs,\n\u001b[1;32m    259\u001b[0m         allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    260\u001b[0m         accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    261\u001b[0m     )  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbackward ran successfully for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(tensors)\u001b[39m}\u001b[39;00m\u001b[39m tensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    264\u001b[0m     \u001b[39m# interrogate tensors\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelenghoekhor/Downloads/pytorch-test/env/lib/python3.8/site-packages/transformers/modeling_utils.py:861: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bc1d2c42184a7898609da28cdfdc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 11.186555862426758,\n",
       " 'eval_runtime': 21.3928,\n",
       " 'eval_samples_per_second': 1.215,\n",
       " 'eval_steps_per_second': 0.187,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view results\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the same example\n",
    "id_to_choose = 1\n",
    "inputs = tokenizer(dataset[id_to_choose]['input_text'], return_tensors='pt').to(device)\n",
    "output = model.generate(**inputs, max_new_tokens=256, num_beams=4)\n",
    "pprint(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "pprint(dataset[id_to_choose][\"target_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "trainer.save_model(os.path.join(output_dir, \"longt5-qlora-final\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
