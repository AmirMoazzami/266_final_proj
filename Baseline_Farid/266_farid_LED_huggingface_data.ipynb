{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29af5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Download and Extract the Dataset:\n",
    "# !wget https://ai2-s2-mslr.s3.us-west-2.amazonaws.com/mslr_data.tar.gz\n",
    "# !tar -xvf mslr_data.tar.gz\n",
    "\n",
    "# #Delete the Cochrane dataset and any other unwanted files:\n",
    "# !rm -r mslr_data/cochrane/\n",
    "# !rm mslr_data.tar.gz*\n",
    "\n",
    "# #Move the ms2 directory up one level and remove the parent mslr_data directory:\n",
    "# !mv mslr_data/ms2 ./\n",
    "# !rm -r mslr_data/\n",
    "# !rm -r sample_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import evaluate\n",
    "from pprint import pprint\n",
    "import csv\n",
    "from datasets import load_dataset\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "\n",
    "\n",
    "\n",
    "# # Check TensorFlow setup\n",
    "# print(f\"TensorFlow version: {tf.__version__}\")\n",
    "# print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# # Load the dataset using Hugging Face datasets\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "\n",
    "# Load the data- test inputs\n",
    "df = pd.read_csv('mslr2022_validation.csv')\n",
    "df = df[['review_id', 'abstract']]\n",
    "\n",
    "#save the first 5 rows for practice \n",
    "df= df[:10]\n",
    "\n",
    "\n",
    "# # Split the concatenated abstracts into lists of abstracts\n",
    "# df['split_abstracts'] = df['abstract'].apply(lambda x: x.split('\\n '))\n",
    "\n",
    "# df.head(20)\n",
    "\n",
    "# Optional: Save the DataFrame to a CSV file\n",
    "# Uncomment the following lines if you want to save the DataFrame\n",
    "# df.to_csv(\"mslr2022_validation_short.csv\", index=False)\n",
    "# print(\"Dataset saved to mslr2022_validation.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b47dea",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eec2dfd",
   "metadata": {},
   "source": [
    "***Run the code on validation dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6973a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LED model and tokenizer\n",
    "model_name = \"allenai/led-base-16384\"\n",
    "\n",
    "# Create tokenizer instance\n",
    "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Create model instance\n",
    "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Convert abstracts to a list\n",
    "abstracts = df['abstract'].tolist()\n",
    "\n",
    "# Tokenize the texts and prepare inputs\n",
    "inputs = tokenizer(\n",
    "    abstracts, \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    return_tensors=\"pt\", \n",
    "    max_length=16384  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c047762d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved summaries to val-prediction.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the batch size\n",
    "batch_size = 5\n",
    "\n",
    "# Initialize the results list\n",
    "results = []\n",
    "\n",
    "# Generate summaries in batches\n",
    "for i in range(0, len(inputs['input_ids']), batch_size):\n",
    "    # Get the batch of input IDs and the corresponding ReviewIDs\n",
    "    input_ids_batch = inputs['input_ids'][i:i+batch_size]\n",
    "    review_ids_batch = df['review_id'][i:i+batch_size].tolist()\n",
    "\n",
    "    # Generate summaries\n",
    "    summary_ids = model.generate(input_ids_batch,\n",
    "                                 num_beams=2,\n",
    "                                 no_repeat_ngram_size=2,\n",
    "                                 min_length=10,  # Adjusted minimum length\n",
    "                                 max_length=512,  # Adjusted maximum length\n",
    "                                 early_stopping=True)\n",
    "\n",
    "    # Decode the summaries\n",
    "    batch_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Append each summary with its ReviewID to the results list\n",
    "    for review_id, summary in zip(review_ids_batch, batch_summaries):\n",
    "        results.append({'review_id': review_id, 'Summary': summary})\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "summaries_df_val = pd.DataFrame(results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file_val = 'val-prediction.csv'\n",
    "summaries_df_val.to_csv(output_file_val, index=True)\n",
    "print(f\"Saved summaries to {output_file_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38646801",
   "metadata": {},
   "source": [
    "***version 2 of LED***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c841d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
