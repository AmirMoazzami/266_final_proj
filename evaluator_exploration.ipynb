{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siWmXXPgidJi",
        "outputId": "9eb9c98c-9305-4217-f389-3c7f79ea9a57"
      },
      "outputs": [],
      "source": [
        "!pip install -q rouge_score transformers bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dycHxY1_idJj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from typing import List, Dict\n",
        "from rouge_score import rouge_scorer, scoring\n",
        "import bert_score\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "START_POPULATION='<pop>'\n",
        "END_POPULATION='</pop>'\n",
        "START_INTERVENTION='<int>'\n",
        "END_INTERVENTION='</int>'\n",
        "START_OUTCOME='<out>'\n",
        "END_OUTCOME='</out>'\n",
        "START_BACKGROUND = '<background>'\n",
        "END_BACKGROUND = '</background>'\n",
        "START_REFERENCE = '<ref>'\n",
        "END_REFERENCE = '</ref>'\n",
        "START_EVIDENCE = '<evidence>'\n",
        "END_EVIDENCE = '</evidence>'\n",
        "SEP_TOKEN = '<sep>'\n",
        "EXTRA_TOKENS = [\n",
        "    START_BACKGROUND,\n",
        "    END_BACKGROUND,\n",
        "    START_REFERENCE,\n",
        "    END_REFERENCE,\n",
        "    SEP_TOKEN,\n",
        "    START_POPULATION,\n",
        "    END_POPULATION,\n",
        "    START_INTERVENTION,\n",
        "    END_INTERVENTION,\n",
        "    START_OUTCOME,\n",
        "    END_OUTCOME,\n",
        "    START_EVIDENCE,\n",
        "    END_EVIDENCE,\n",
        "]\n",
        "\n",
        "\n",
        "def rouge_scores(\n",
        "    preds: List[List[torch.Tensor]], targets: List[List[torch.Tensor]],\n",
        "    tokenizer, use_stemmer=False, use_aggregator=False\n",
        "):\n",
        "    # largely copied from https://github.com/huggingface/nlp/blob/master/metrics/rouge/rouge.py#L84\n",
        "    # and from https://github.com/allenai/ms2/blob/a03ab009e00c5e412b4c55f6ec4f9b49c2d8a7f6/ms2/models/utils.py\n",
        "    rouge_types = ['rouge1', 'rouge2', 'rougeL', 'rougeLsum']\n",
        "    scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types, use_stemmer=use_stemmer)\n",
        "    refs, hyps = [], []\n",
        "    for p, t in zip(preds, targets):\n",
        "        assert len(p) == len(t)\n",
        "        refs.extend(p)\n",
        "        hyps.extend(t)\n",
        "\n",
        "    if use_aggregator:\n",
        "        aggregator = scoring.BootstrapAggregator()\n",
        "        scores = None\n",
        "    else:\n",
        "        aggregator = None\n",
        "        scores = []\n",
        "\n",
        "    for ref, pred in zip(refs, hyps):\n",
        "        if isinstance(ref, torch.Tensor):\n",
        "            ref = tokenizer.decode(ref).lower()\n",
        "        if isinstance(pred, torch.Tensor):\n",
        "            pred = tokenizer.decode(pred).lower()\n",
        "        score = scorer.score(ref, pred)\n",
        "        if use_aggregator:\n",
        "            aggregator.add_scores(score)\n",
        "        else:\n",
        "            scores.append(score)\n",
        "\n",
        "    if use_aggregator:\n",
        "        result = aggregator.aggregate()\n",
        "    else:\n",
        "        result = {}\n",
        "        for key in scores[0]:\n",
        "            result[key] = list(score[key] for score in scores)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_tokenizer(tokenizer_type: str):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_type, additional_special_tokens=EXTRA_TOKENS)\n",
        "    return tokenizer\n",
        "\n",
        "\n",
        "def calculate_rouge(targets: Dict[str, Dict], generated: Dict[str, str]) -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate ROUGE scores\n",
        "    :param targets: dict of docid -> {'target': target_text}\n",
        "    :param generated: dict of docid -> generated_text\n",
        "    :return: dict of ROUGE scores (rouge1, rouge2, rougeL, rougeLsum)\n",
        "    \"\"\"\n",
        "    # copied from https://github.com/allenai/mslr-shared-task/blob/c2218c1a440cf5172d784065b48af2d6c5c50f9a/evaluator/evaluator.py\n",
        "    print(\"Computing ROUGE scores...\")\n",
        "    docids = list(targets.keys())\n",
        "    target_texts = [[targets[docid]['target']] for docid in docids]\n",
        "    generated_texts = [[generated.get(docid, '')] for docid in docids]\n",
        "\n",
        "    # rouge scoring\n",
        "    tokenizer = get_tokenizer('facebook/bart-base')\n",
        "    rouge_results = rouge_scores(generated_texts, target_texts, tokenizer, use_aggregator=True)\n",
        "    return rouge_results\n",
        "\n",
        "\n",
        "def calculate_mid_rouge(targets: Dict[str, Dict], generated: Dict[str, str]) -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate ROUGE scores but only return mid fmeasure.\n",
        "    :param targets: dict of docid -> {'target': target_text}\n",
        "    :param generated: dict of docid -> generated_text\n",
        "    :return: dict of ROUGE scores (rouge1, rouge2, rougeL, rougeLsum)\n",
        "    \"\"\"\n",
        "    results = calculate_rouge(targets, generated)\n",
        "    return {\n",
        "        \"rouge\": results,\n",
        "        \"rouge1\": results[\"rouge1\"].mid.fmeasure,\n",
        "        \"rouge2\": results[\"rouge2\"].mid.fmeasure,\n",
        "        \"rougeL\": results[\"rougeL\"].mid.fmeasure,\n",
        "        \"rougeLsum\": results[\"rougeLsum\"].mid.fmeasure,\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_bertscore(\n",
        "    targets: Dict[str, Dict], generated: Dict[str, str], model_type=\"roberta-large\"\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate BERTscore\n",
        "    :param targets: dict of docid -> {'target': target_text}\n",
        "    :param generated: dict of docid -> generated_text\n",
        "    :param model_type: model type for BERTscore. Choose from many choices (look\n",
        "        up bert-score github). Note that MSLR/MS2 uses roberta-large in default\n",
        "        args, but https://huggingface.co/allenai/led-base-16384-ms2 uses\n",
        "        `microsoft/deberta-xlarge-mnli`. Note that `bert-score`\n",
        "        recommends `microsoft/deberta-xlarge-mnli` as the one with best\n",
        "        correlation with human judgement. Details here:\n",
        "        https://huggingface.co/microsoft/deberta-xlarge-mnli\n",
        "    :return: dict of BERTscore results (bs_ps, bs_rs, bs_fs) (precision, recall, f1)\n",
        "    \"\"\"\n",
        "    # copied from https://github.com/allenai/mslr-shared-task/blob/c2218c1a440cf5172d784065b48af2d6c5c50f9a/evaluator/evaluator.py\n",
        "    # original bert score: https://github.com/Tiiiger/bert_score\n",
        "    print(\"Computing BERTscore...\")\n",
        "    docids = list(targets.keys())\n",
        "    target_texts = [targets[docid]['target'] for docid in docids]\n",
        "    generated_texts = [generated.get(docid, '') for docid in docids]\n",
        "\n",
        "    # BERTscore\n",
        "    bs_ps, bs_rs, bs_fs = bert_score.score(generated_texts, target_texts, model_type=model_type)\n",
        "    return {\n",
        "        \"bs_ps\": bs_ps,\n",
        "        \"bs_rs\": bs_rs,\n",
        "        \"bs_fs\": bs_fs\n",
        "    }\n",
        "\n",
        "\n",
        "def calculate_mean_bertscore(\n",
        "    targets: Dict[str, Dict], generated: Dict[str, str], model_type=\"roberta-large\"\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate mean BERTscore\n",
        "    :param targets: dict of docid -> {'target': target_text}\n",
        "    :param generated: dict of docid -> generated_text\n",
        "    :param model_type: model type for BERTscore.\n",
        "    :return: dict of mean BERTscore results (bs_ps, bs_rs, bs_fs) (precision, recall, f1)\n",
        "    \"\"\"\n",
        "    individual_results = calculate_bertscore(targets, generated, model_type=model_type)\n",
        "\n",
        "    results = {\n",
        "        \"bertscore_avg_p\": torch.mean(individual_results[\"bs_ps\"]).item(),\n",
        "        \"bertscore_avg_r\": torch.mean(individual_results[\"bs_rs\"]).item(),\n",
        "        \"bertscore_avg_f\": torch.mean(individual_results[\"bs_fs\"]).item(),\n",
        "        \"bertscore_std_p\": torch.std(individual_results[\"bs_ps\"]).item(),\n",
        "        \"bertscore_std_r\": torch.std(individual_results[\"bs_rs\"]).item(),\n",
        "        \"bertscore_std_f\": torch.std(individual_results[\"bs_fs\"]).item(),\n",
        "    }\n",
        "    return results\n",
        "\n",
        "\n",
        "# pull in original validation data from huggingface datasets\n",
        "dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split=\"validation\")  # takes 9 mins\n",
        "display(dataset)\n",
        "\n",
        "# organize target data into dicts for rouge and bertscore\n",
        "targets = {row['review_id']: row for row in dataset}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Gu8yijH1qwmg",
        "outputId": "4108ea03-fba8-4a22-d769-f50c3e4313f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing ROUGE scores...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.12222222222222223, recall=0.0787037037037037, fmeasure=0.0989010989010989), mid=Score(precision=0.35555555555555557, recall=0.28703703703703703, fmeasure=0.31684981684981683), high=Score(precision=0.6333333333333333, recall=0.5972222222222222, fmeasure=0.6068376068376068)),\n",
              " 'rouge2': AggregateScore(low=Score(precision=0.020833333333333332, recall=0.020833333333333332, fmeasure=0.020833333333333332), mid=Score(precision=0.20833333333333334, recall=0.20833333333333334, fmeasure=0.20833333333333334), high=Score(precision=0.5625, recall=0.5416666666666666, fmeasure=0.548611111111111)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.07407407407407407, recall=0.05787037037037037, fmeasure=0.07326007326007326), mid=Score(precision=0.30370370370370364, recall=0.26157407407407407, fmeasure=0.2716727716727717), high=Score(precision=0.5711111111111105, recall=0.5578703703703703, fmeasure=0.5626780626780626)),\n",
              " 'rougeLsum': AggregateScore(low=Score(precision=0.07037037037037037, recall=0.05787037037037037, fmeasure=0.06267806267806268), mid=Score(precision=0.30370370370370364, recall=0.2615740740740741, fmeasure=0.27696377696377694), high=Score(precision=0.6037037037037037, recall=0.5740740740740741, fmeasure=0.5846560846560847))}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing BERTscore...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'bs_ps': tensor([0.7381, 0.5301, 0.5480, 0.3825, 0.6740, 1.0000]),\n",
              " 'bs_rs': tensor([0.7276, 0.5883, 0.6598, 0.4499, 0.6900, 1.0000]),\n",
              " 'bs_fs': tensor([0.7328, 0.5577, 0.5987, 0.4135, 0.6819, 1.0000])}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test with some toy examples\n",
        "\n",
        "targets_toy = {\n",
        "    \"doc1\": {\"target\": \"The quick brown fox jumps over the lazy dog\"},\n",
        "    \"doc2\": {\"target\": \"fruit flies like a banana\"},\n",
        "    \"doc3\": {\"target\": \"fruit flies like a banana\"},\n",
        "    \"doc4\": {\"target\": \"fruit flies like a banana\"},\n",
        "    \"doc5\": {\"target\": \"everything is chaotic\"},\n",
        "    \"doc6\": {\"target\": \"The quick brown fox jumps over the lazy dog\"},\n",
        "}\n",
        "\n",
        "generated_toy = {\n",
        "    \"doc1\": \"A lazy dog is under a hopping speedy fox\",  # synonym\n",
        "    \"doc2\": \"some insects are attracted to a yellow fruit\",  # one interpretation\n",
        "    \"doc3\": \"most fruits have the aerodynamic properties of a banana\",  # another interpretation\n",
        "    \"doc4\": \"nothing makes sense\",  # completely irrelevant\n",
        "    \"doc5\": \"nothing makes sense\",  # synonym\n",
        "    \"doc6\": \"The quick brown fox jumps over the lazy dog\",  # perfect/identical\n",
        "}\n",
        "\n",
        "rouge_results = calculate_rouge(targets_toy, generated_toy)\n",
        "display(rouge_results)\n",
        "\n",
        "bertscore_results = calculate_bertscore(targets_toy, generated_toy, \"microsoft/deberta-xlarge-mnli\")\n",
        "display(bertscore_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "DjR_IKBpwCJl",
        "outputId": "5ec2166c-b1e6-40fa-d1d4-f180ba4929e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing ROUGE scores...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge': {'rouge1': AggregateScore(low=Score(precision=0.4727272727272727, recall=0.09961685823754789, fmeasure=0.16455696202531644), mid=Score(precision=0.4754940711462451, recall=0.10959103781442611, fmeasure=0.1779306549257017), high=Score(precision=0.4782608695652174, recall=0.11956521739130435, fmeasure=0.19130434782608696)),\n",
              "  'rouge2': AggregateScore(low=Score(precision=0.08823529411764706, recall=0.019230769230769232, fmeasure=0.03184713375796178), mid=Score(precision=0.09041394335511982, recall=0.020524475524475526, fmeasure=0.033416278249243286), high=Score(precision=0.09259259259259259, recall=0.02181818181818182, fmeasure=0.03498542274052478)),\n",
              "  'rougeL': AggregateScore(low=Score(precision=0.2727272727272727, recall=0.05747126436781609, fmeasure=0.0949367088607595), mid=Score(precision=0.2812911725955204, recall=0.06496751624187906, fmeasure=0.10543936892313338), high=Score(precision=0.2898550724637681, recall=0.07246376811594203, fmeasure=0.11594202898550726)),\n",
              "  'rougeLsum': AggregateScore(low=Score(precision=0.2727272727272727, recall=0.05747126436781609, fmeasure=0.0949367088607595), mid=Score(precision=0.2812911725955204, recall=0.06496751624187906, fmeasure=0.10543936892313338), high=Score(precision=0.2898550724637681, recall=0.07246376811594203, fmeasure=0.11594202898550726))},\n",
              " 'rouge1': 0.1779306549257017,\n",
              " 'rouge2': 0.033416278249243286,\n",
              " 'rougeL': 0.10543936892313338,\n",
              " 'rougeLsum': 0.10543936892313338}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing BERTscore...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'bertscore_avg_p': 0.47608551383018494,\n",
              " 'bertscore_avg_r': 0.6032038927078247,\n",
              " 'bertscore_avg_f': 0.5320615768432617,\n",
              " 'bertscore_std_p': 0.006571114994585514,\n",
              " 'bertscore_std_r': 0.014886646531522274,\n",
              " 'bertscore_std_f': 0.0016888664104044437}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test with some toy examples\n",
        "\n",
        "targets_x_sample = {\n",
        "    \"28514886\": {\n",
        "        \"target\": \"Current evidence from systematic review and meta- analysis revealed that probiotics are the most promising intervention in reduction of the incidence of NEC in VLBW neonates . As per the evidence , prebiotics modulate the composition of human intestine microflora to the benefit of the host by suppression of colonization of harmful microorganism and /or the stimulation of bifidobacterial growth , decreased stool viscosity , reduced gastrointestinal transit time , and better feed tolerance .\",\n",
        "        \"background\": targets[\"28514886\"][\"background\"],\n",
        "    },\n",
        "    \"18842808\": {\n",
        "        \"target\": \"The use of glucomannan did not appear to significantly alter any other study endpoints . Pediatric patients , patients receiving dietary modification , and patients with impaired glucose metabolism did not benefit from glucomannan to the same degree . Glucomannan appears to beneficially affect total cholesterol , LDL cholesterol , triglycerides , body weight , and FBG , but not HDL cholesterol or BP\",\n",
        "        \"background\": targets[\"18842808\"][\"background\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "generated_2_sample = {\n",
        "    \"28514886\": \"Retrieve concise conclusion without background: BACKGROUND : Necrotizing enterocolitis ( NEC ) is one of the most destructive diseases associated with the intestine. We aim to determine the effect of a preterm formula containing partially hydrolyzed whey protein, modified vegetable oil with a high & bgr;-palmitic acid content, on the intestinal flora. We hypothesized that enteral supplementation of a prebiotic mixture consisting of neutral oligosaccharides ( (SC)GOS/(LC)FOS ) and acidic oligosaccharides ( AOS ) on intestinal permeability. In a double-blind trial 20 preterm infants ( gestational age 27 ( 24 - 31 ) weeks, postnatal age 42 ( 11 - 84 ) days ), and weight at study entry 1570 ( 1080 - 2300 ) g were enrolled. The infants were randomized to receive either a formula with 8 g/L of either GOS/LCFOS ( 1.5 or 3.0 g/kg ). The stool specimens were quantitatively cultured weekly for the number of bifidobacteria, gastric residue, bowel habits, and feeding tolerance.  Clinical examination including anthropometric measurements, microbiological analysis of fecal sample s, and blood leukocyte population analysis were performed at birth and 6 and 10 weeks... The results showed that the incidence of NEC, the group fed the oligosaccharide supplemented formula increased to the upper range of infant growth, and the placebo group. The incidence of > or = 1 serious infection, as measured by extrusion force ( P=0.006 ), was not significantly different in the supplemented group ( P = 0.056 )..  The intestinal microbiota of infants who received a st and ard formula seems to resemble a more mature gut flora, while the 0.8 g/dL group, 9.7 - 14 % of these neonates.. Conclusion : Neonatal enteric NEC. The intestinal flora of preterm neonates was not different between the 2 groups. and/.}).\",\n",
        "    \"18842808\": \"Retrieve concise conclusion without background: BACKGROUND The purpose of this study was to evaluate the effectiveness of the hydrosoluble fiber glucomannan to a Step-One-Diet in mildly hypercholesterolemic type II diabetic and non-diabetic subjects and to compare the response of these two subject groups to the treatments. MATERIAL / METHODS One hundred and seventy six men and women were included to receive either active fiber substance or placebo in r and omized placebo-controlled studies. The subjects were encouraged not to change their ordinary diets or general lifestyle during the investigation. RESULTS : After a three-days food recall, a balanced diet with adequate caloric intake was provided to all obese children. In all patients before and 2 - 4 months after the intervention, the plasma lipids ( weight, height, weight excess ) and laboratory data ( serum levels of cholesterol, HDL, triglycerides, glucose, fructosamine, glycosylated hemoglobin, RBC, WBC, hemoglobin, iron, calcium, Cu and Zn ) have been determined. Excess weight and triglycerids levels were significantly decreased in treated obese patients than in obese controls 4 months later. Both groups experienced decreases in ( P < 0.01 ) body weight, percent body fat, systolic blood pressure, waist circumference, and plasma glucose levels. After 12 weeks, HDL-C and TAG improved significantly in the fiber ( 10 % and -34 % ) and placebo ( 14 %, -43 % ) groups. The results of lipid profiles did not differ between subject groups. Overall plasma lathosterol concentrations, as well as FBG, and other lipids were lowered ( P<0.05 ). The study to perform a meta- analysis of r, omized controlled trials of glucarannan on plasma lipid, FBG.. and).-..\",\n",
        "}\n",
        "\n",
        "rouge_results = calculate_mid_rouge(targets_2_sample, generated_2_sample)\n",
        "display(rouge_results)\n",
        "\n",
        "bertscore_results = calculate_mean_bertscore(targets_2_sample, generated_2_sample, \"microsoft/deberta-xlarge-mnli\")\n",
        "display(bertscore_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating on model outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BioBART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26762372</td>\n",
              "      <td>Background : The aim of the present study was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28723736</td>\n",
              "      <td>BACKGROUND Surgical site infections ( SSIs ) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22002191</td>\n",
              "      <td>BACKGROUND AND PURPOSE : The purpose of this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31921439</td>\n",
              "      <td>Background : Several established tools are av...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30301735</td>\n",
              "      <td>Background Topical glyceryl trinitrate ( GTN ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  review_id                                          candidate\n",
              "0  26762372   Background : The aim of the present study was...\n",
              "1  28723736   BACKGROUND Surgical site infections ( SSIs ) ...\n",
              "2  22002191   BACKGROUND AND PURPOSE : The purpose of this ...\n",
              "3  31921439   Background : Several established tools are av...\n",
              "4  30301735   Background Topical glyceryl trinitrate ( GTN ..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Open results from BioBART on validation set\n",
        "df_biobart = pd.read_csv(\"pretrained_no_finetune/biobart/biobart_validation.csv\")\n",
        "# review_id is the docid and should be a string\n",
        "df_biobart['review_id'] = df_biobart['review_id'].astype(str)\n",
        "display(df_biobart.head())\n",
        "\n",
        "# organize into dicts for rouge and bertscore\n",
        "generated_biobart = {row['review_id']: row['candidate'] for _, row in df_biobart.iterrows()}\n",
        "\n",
        "# check to see if all docids are present and unique\n",
        "assert set(generated_biobart.keys()) == set(targets.keys())\n",
        "assert len(generated_biobart) == len(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_biobart.candidate.str.len().hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing ROUGE scores...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge': {'rouge1': AggregateScore(low=Score(precision=0.4085764548117969, recall=0.09217051335154197, fmeasure=0.1448897839623271), mid=Score(precision=0.46691416592132295, recall=0.1346856479283819, fmeasure=0.19092749741701748), high=Score(precision=0.5227113929191609, recall=0.18335498949362816, fmeasure=0.24417392291854567)),\n",
              "  'rouge2': AggregateScore(low=Score(precision=0.07378749078582353, recall=0.019862255033613725, fmeasure=0.030216589670523743), mid=Score(precision=0.1241565192861693, recall=0.029366603129565398, fmeasure=0.042641450275991935), high=Score(precision=0.17737006675077563, recall=0.04004910719325335, fmeasure=0.05588984314531449)),\n",
              "  'rougeL': AggregateScore(low=Score(precision=0.2140476538033701, recall=0.05383590357501683, fmeasure=0.08535759468459861), mid=Score(precision=0.2782796951002747, recall=0.07385370559083271, fmeasure=0.10569908603798697), high=Score(precision=0.349088778867628, recall=0.09313559353500153, fmeasure=0.12639377488587802)),\n",
              "  'rougeLsum': AggregateScore(low=Score(precision=0.2541063885717719, recall=0.057616764009429784, fmeasure=0.09270628865518564), mid=Score(precision=0.30040165033178545, recall=0.08443637581661043, fmeasure=0.11992510707873644), high=Score(precision=0.36140156820303876, recall=0.11074462147619998, fmeasure=0.14793002632371963))},\n",
              " 'rouge1': 0.19092749741701748,\n",
              " 'rouge2': 0.042641450275991935,\n",
              " 'rougeL': 0.10569908603798697,\n",
              " 'rougeLsum': 0.11992510707873644}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing BERTscore...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'bertscore_avg_p': 0.47950369119644165,\n",
              " 'bertscore_avg_r': 0.5985714197158813,\n",
              " 'bertscore_avg_f': 0.5301606059074402,\n",
              " 'bertscore_std_p': 0.05009160935878754,\n",
              " 'bertscore_std_r': 0.039970237761735916,\n",
              " 'bertscore_std_f': 0.03192624822258949}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# SMALL SUBSET DATASET - calculate rouge and bertscore for only 10 docs\n",
        "\n",
        "subset_review_ids = list(generated_biobart.keys())[:10]\n",
        "targets_subset = {docid: targets[docid] for docid in subset_review_ids}\n",
        "generated_subset = {docid: generated_biobart[docid] for docid in subset_review_ids}\n",
        "\n",
        "rouge_results = calculate_mid_rouge(targets_subset, generated_subset)\n",
        "display(rouge_results)\n",
        "\n",
        "bertscore_results = calculate_mean_bertscore(targets_subset, generated_subset, \"microsoft/deberta-xlarge-mnli\")\n",
        "display(bertscore_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing ROUGE scores...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge': {'rouge1': AggregateScore(low=Score(precision=0.4961293110596966, recall=0.09804610749650168, fmeasure=0.15496854682493477), mid=Score(precision=0.5010460912997867, recall=0.10033882683006921, fmeasure=0.15787649150257704), high=Score(precision=0.5061464436016391, recall=0.10296259138737313, fmeasure=0.16123738642284913)),\n",
              "  'rouge2': AggregateScore(low=Score(precision=0.12074097153798954, recall=0.021833711098443242, fmeasure=0.03501379734426587), mid=Score(precision=0.12477178207184145, recall=0.022547010164837327, fmeasure=0.03609727189353998), high=Score(precision=0.1284730654869281, recall=0.023239723047089753, fmeasure=0.03711046213471403)),\n",
              "  'rougeL': AggregateScore(low=Score(precision=0.3091211111639237, recall=0.05700992858853988, fmeasure=0.09137477431435435), mid=Score(precision=0.3138483862064446, recall=0.05815324451429994, fmeasure=0.09277901738343573), high=Score(precision=0.31780643509315887, recall=0.059300800373725426, fmeasure=0.09430320248381381)),\n",
              "  'rougeLsum': AggregateScore(low=Score(precision=0.34022809189644826, recall=0.06522637932743615, fmeasure=0.1037920479790383), mid=Score(precision=0.3443802745766378, recall=0.06691941306703642, fmeasure=0.10582250252061917), high=Score(precision=0.348589540310728, recall=0.06843215052089782, fmeasure=0.1077508540229986))},\n",
              " 'rouge1': 0.15787649150257704,\n",
              " 'rouge2': 0.03609727189353998,\n",
              " 'rougeL': 0.09277901738343573,\n",
              " 'rougeLsum': 0.10582250252061917}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing BERTscore...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'bertscore_avg_p': 0.4647563397884369,\n",
              " 'bertscore_avg_r': 0.6073237061500549,\n",
              " 'bertscore_avg_f': 0.524921178817749,\n",
              " 'bertscore_std_p': 0.04064429923892021,\n",
              " 'bertscore_std_r': 0.04167566075921059,\n",
              " 'bertscore_std_f': 0.030336380004882812}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# FULL DATASET - calculate rouge and bertscore\n",
        "rouge_results = calculate_mid_rouge(targets, generated_biobart)\n",
        "display(rouge_results)\n",
        "\n",
        "bertscore_results = calculate_mean_bertscore(targets, generated_biobart, \"microsoft/deberta-xlarge-mnli\")\n",
        "display(bertscore_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LongT5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>candidate</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28514886</td>\n",
              "      <td>In this paper, the authors present a detailed ...</td>\n",
              "      <td>Current evidence from systematic review and me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18842808</td>\n",
              "      <td>The effects of soluble fiber Konjacglucomannaa...</td>\n",
              "      <td>The use of glucomannan did not appear to signi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24297836</td>\n",
              "      <td>In this study, we examine the autonomic functi...</td>\n",
              "      <td>Ensuring that the characteristics of the histo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32367221</td>\n",
              "      <td>The first four months after ACL-reconstruction...</td>\n",
              "      <td>The QT autograft detected comparable rate of L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25038833</td>\n",
              "      <td>In this study, we examine the effects of a com...</td>\n",
              "      <td>medicines with anti-cholinergic properties hav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  review_id                                          candidate  \\\n",
              "0  28514886  In this paper, the authors present a detailed ...   \n",
              "1  18842808  The effects of soluble fiber Konjacglucomannaa...   \n",
              "2  24297836  In this study, we examine the autonomic functi...   \n",
              "3  32367221  The first four months after ACL-reconstruction...   \n",
              "4  25038833  In this study, we examine the effects of a com...   \n",
              "\n",
              "                                              Target  \n",
              "0  Current evidence from systematic review and me...  \n",
              "1  The use of glucomannan did not appear to signi...  \n",
              "2  Ensuring that the characteristics of the histo...  \n",
              "3  The QT autograft detected comparable rate of L...  \n",
              "4  medicines with anti-cholinergic properties hav...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do the same for LongT5\n",
        "df_longt5 = pd.read_csv(\"pretrained_no_finetune/longt5_validation_output.csv\")\n",
        "# rename columns\n",
        "df_longt5.rename(columns={\"ReviewID\": \"review_id\", \"Candidate_Summary\": \"candidate\"}, inplace=True)\n",
        "df_longt5['review_id'] = df_longt5['review_id'].astype(str)\n",
        "display(df_longt5.head())\n",
        "\n",
        "# organize into dicts for rouge and bertscore\n",
        "generated_longt5 = {row['review_id']: row['candidate'] for _, row in df_longt5.iterrows()}\n",
        "\n",
        "# check to see if all docids are present and unique\n",
        "assert set(generated_longt5.keys()) == set(targets.keys())\n",
        "assert len(generated_longt5) == len(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_longt5.candidate.str.len().hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing ROUGE scores...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge': {'rouge1': AggregateScore(low=Score(precision=0.3689880935169033, recall=0.1373716882683111, fmeasure=0.18146408062581565), mid=Score(precision=0.37411828801996916, recall=0.1409145648626524, fmeasure=0.18470632255173647), high=Score(precision=0.3794242086017666, recall=0.14449596274682863, fmeasure=0.1879584466757623)),\n",
              "  'rouge2': AggregateScore(low=Score(precision=0.04557487872639194, recall=0.01590814686224898, fmeasure=0.021231856485365564), mid=Score(precision=0.04793996144557606, recall=0.016668281522408682, fmeasure=0.0221177594000776), high=Score(precision=0.050202056518269936, recall=0.017373962287074943, fmeasure=0.022961333533190822)),\n",
              "  'rougeL': AggregateScore(low=Score(precision=0.21965267778396885, recall=0.07783630907778631, fmeasure=0.10407646651699773), mid=Score(precision=0.22360079833164628, recall=0.07955625729090238, fmeasure=0.105555116591603), high=Score(precision=0.22757073587894702, recall=0.08141784681695725, fmeasure=0.10705688532393431)),\n",
              "  'rougeLsum': AggregateScore(low=Score(precision=0.2441192413906547, recall=0.08978796439477985, fmeasure=0.11882565080150424), mid=Score(precision=0.2478403228735478, recall=0.09202858211867199, fmeasure=0.12067120374709103), high=Score(precision=0.25174149547059227, recall=0.09415420511489385, fmeasure=0.12253281134260406))},\n",
              " 'rouge1': 0.18470632255173647,\n",
              " 'rouge2': 0.0221177594000776,\n",
              " 'rougeL': 0.105555116591603,\n",
              " 'rougeLsum': 0.12067120374709103}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing BERTscore...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'bertscore_avg_p': 0.511027991771698,\n",
              " 'bertscore_avg_r': 0.5844007730484009,\n",
              " 'bertscore_avg_f': 0.5434643030166626,\n",
              " 'bertscore_std_p': 0.04310934618115425,\n",
              " 'bertscore_std_r': 0.048223260790109634,\n",
              " 'bertscore_std_f': 0.033570773899555206}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# FULL DATASET - calculate rouge and bertscore\n",
        "rouge_results = calculate_mid_rouge(targets, generated_longt5)\n",
        "display(rouge_results)\n",
        "\n",
        "bertscore_results = calculate_mean_bertscore(targets, generated_longt5, \"microsoft/deberta-xlarge-mnli\")\n",
        "display(bertscore_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>candidate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28514886</td>\n",
              "      <td>The 5 nuclease assays were subsequently used ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18842808</td>\n",
              "      <td>GM fibers reduced total cholesterol ( TC ) con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24297836</td>\n",
              "      <td>The purpose of this study was 1 ) to evaluate ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32367221</td>\n",
              "      <td>Pain on kneeling, KT-1000 measured side to sid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25038833</td>\n",
              "      <td>RESULTS Results of the Name-Face Association T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  review_id                                          candidate\n",
              "0  28514886  The 5 nuclease assays were subsequently used ...\n",
              "1  18842808  GM fibers reduced total cholesterol ( TC ) con...\n",
              "2  24297836  The purpose of this study was 1 ) to evaluate ...\n",
              "3  32367221  Pain on kneeling, KT-1000 measured side to sid...\n",
              "4  25038833  RESULTS Results of the Name-Face Association T..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Do the same for Pegasus\n",
        "\n",
        "df_pegasus = pd.read_csv(\"PEGASUS_LARGE/val-prediction.csv\", index_col=0).reset_index(drop=True)\n",
        "df_pegasus.rename(columns={\"Summary\": \"candidate\"}, inplace=True)\n",
        "df_pegasus['review_id'] = df_pegasus['review_id'].astype(str)\n",
        "display(df_pegasus.head())\n",
        "\n",
        "# organize into dicts for rouge and bertscore\n",
        "generated_pegasus = {row['review_id']: row['candidate'] for _, row in df_pegasus.iterrows()}\n",
        "# check to see if all docids are present and unique\n",
        "assert set(generated_pegasus.keys()) == set(targets.keys())\n",
        "assert len(generated_pegasus) == len(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_pegasus.candidate.str.len().hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing ROUGE scores...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'rouge': {'rouge1': AggregateScore(low=Score(precision=0.23188510954639052, recall=0.16099073832364824, fmeasure=0.17069165533548553), mid=Score(precision=0.23636549568618445, recall=0.16508845641785155, fmeasure=0.17369981891498523), high=Score(precision=0.2410069773924332, recall=0.16849743182924395, fmeasure=0.17653612736981214)),\n",
              "  'rouge2': AggregateScore(low=Score(precision=0.025609972888597017, recall=0.016841790228365836, fmeasure=0.018114094286240737), mid=Score(precision=0.027286249022990428, recall=0.01787230488805157, fmeasure=0.01910065539440901), high=Score(precision=0.028971208429477726, recall=0.01883083674581007, fmeasure=0.020115374285278053)),\n",
              "  'rougeL': AggregateScore(low=Score(precision=0.14984277944496277, recall=0.10096691095688277, fmeasure=0.10783642394171626), mid=Score(precision=0.1529523009446699, recall=0.10302738727799489, fmeasure=0.10937489929608912), high=Score(precision=0.15617329592365214, recall=0.10519244319098883, fmeasure=0.11108952315261846)),\n",
              "  'rougeLsum': AggregateScore(low=Score(precision=0.16282568580513515, recall=0.11368947175779581, fmeasure=0.11980467336529034), mid=Score(precision=0.1662381470581819, recall=0.116408103310772, fmeasure=0.12170440561740219), high=Score(precision=0.1695010123743512, recall=0.1192908546567098, fmeasure=0.12380964331683568))},\n",
              " 'rouge1': 0.17369981891498523,\n",
              " 'rouge2': 0.01910065539440901,\n",
              " 'rougeL': 0.10937489929608912,\n",
              " 'rougeLsum': 0.12170440561740219}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing BERTscore...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'bertscore_avg_p': 0.4978368282318115,\n",
              " 'bertscore_avg_r': 0.5536131858825684,\n",
              " 'bertscore_avg_f': 0.5221330523490906,\n",
              " 'bertscore_std_p': 0.05015239864587784,\n",
              " 'bertscore_std_r': 0.057531993836164474,\n",
              " 'bertscore_std_f': 0.042330335825681686}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# FULL DATASET - calculate rouge and bertscore\n",
        "rouge_results = calculate_mid_rouge(targets, generated_pegasus)\n",
        "display(rouge_results)\n",
        "\n",
        "bertscore_results = calculate_mean_bertscore(targets, generated_pegasus, \"microsoft/deberta-xlarge-mnli\")\n",
        "display(bertscore_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delta Evidence Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this once to get EI model params\n",
        "!cd evaluator/ && wget https://ai2-s2-ms2.s3-us-west-2.amazonaws.com/evidence_inference_models.zip  # For Linux\n",
        "# !cd evaluator/ && curl -O https://ai2-s2-ms2.s3-us-west-2.amazonaws.com/evidence_inference_models.zip  # For MacOS if there's no wget\n",
        "!cd evaluator/ && unzip -q evidence_inference_models.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delta Evidence Inference\n",
        "# From MSLR repo\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from typing import Dict\n",
        "from importlib import reload\n",
        "import random\n",
        "\n",
        "from evaluator import evaluator\n",
        "\n",
        "\n",
        "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# also consider mps\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    torch.cuda.set_device(0)\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "\n",
        "def calculate_evidence_inference_divergence(\n",
        "        targets: Dict[str, Dict],\n",
        "        generated: Dict[str, str],\n",
        "        ei_param_file: str,\n",
        "        ei_model_dir: str,\n",
        "        ei_use_unconditional: bool = False\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Calculate Evidence Inference Divergence\n",
        "    :param targets: dict of docid -> {'target': target_text , 'preface': preface_text}\n",
        "    :param generated: dict of docid -> generated_text\n",
        "    :param ei_param_file: path to json file containing EI model parameters\n",
        "    :param ei_model_dir:\n",
        "    :param ei_use_unconditional:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    print(\"Computing Delta Evidence Inference scores...\")\n",
        "    docids = list(targets.keys())\n",
        "    target_texts = [targets[docid]['target'] for docid in docids]\n",
        "    preface_texts = [targets[docid]['preface'] for docid in docids]\n",
        "    generated_texts = [generated.get(docid, '') for docid in docids]\n",
        "\n",
        "    generated_texts = list(map(evaluator.clean, generated_texts))\n",
        "    target_texts = list(map(evaluator.clean, target_texts))\n",
        "\n",
        "    # evidence inference scoring\n",
        "    with open(ei_param_file, 'r') as inf:\n",
        "        params = json.loads(inf.read())\n",
        "    _, evidence_inference_classifier, _, _, _, evidence_inference_tokenizer = evaluator.initialize_models(params)\n",
        "    if ei_use_unconditional:\n",
        "        classifier_file = os.path.join(\n",
        "            ei_model_dir,\n",
        "            'unconditioned_evidence_classifier',\n",
        "            'unconditioned_evidence_classifier.pt'\n",
        "        )\n",
        "    else:\n",
        "        classifier_file = os.path.join(\n",
        "            ei_model_dir, 'evidence_classifier', 'evidence_classifier.pt'\n",
        "        )\n",
        "\n",
        "    # pooler parameters are added by default in an older transformers, so we have to ignore that those are uninitialized.\n",
        "    evidence_inference_classifier.load_state_dict(\n",
        "        torch.load(classifier_file, map_location=device), strict=False\n",
        "    )\n",
        "    if torch.cuda.is_available():\n",
        "        evidence_inference_classifier.cuda()\n",
        "    elif torch.backends.mps.is_available():\n",
        "        evidence_inference_classifier.to(device)\n",
        "\n",
        "    entailment_results = evaluator.entailment_scores(\n",
        "        evidence_inference_classifier, evidence_inference_tokenizer,\n",
        "        generated_texts, target_texts, preface_texts,\n",
        "        use_ios=ei_use_unconditional\n",
        "    )\n",
        "\n",
        "    return entailment_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing Delta Evidence Inference scores...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'average'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.19373307094613526"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'std'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.30078610414331475"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'uniform_preds'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.46051702656047766"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'f1_score'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'significantly decreased': {'precision': 0.0,\n",
              "  'recall': 0.0,\n",
              "  'f1-score': 0.0,\n",
              "  'support': 0.0},\n",
              " 'no significant difference': {'precision': 0.8888888888888888,\n",
              "  'recall': 1.0,\n",
              "  'f1-score': 0.9411764705882353,\n",
              "  'support': 8.0},\n",
              " 'significantly increased': {'precision': 1.0,\n",
              "  'recall': 0.5,\n",
              "  'f1-score': 0.6666666666666666,\n",
              "  'support': 2.0},\n",
              " 'micro avg': {'precision': 0.9,\n",
              "  'recall': 0.9,\n",
              "  'f1-score': 0.9,\n",
              "  'support': 10.0},\n",
              " 'macro avg': {'precision': 0.6296296296296297,\n",
              "  'recall': 0.5,\n",
              "  'f1-score': 0.5359477124183006,\n",
              "  'support': 10.0},\n",
              " 'weighted avg': {'precision': 0.9111111111111111,\n",
              "  'recall': 0.9,\n",
              "  'f1-score': 0.8862745098039216,\n",
              "  'support': 10.0}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>target</th>\n",
              "      <th>generated</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>0.315579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>0.315579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>significant improvements are found</td>\n",
              "      <td>significant improvements are found</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>0.315579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>significant improvements are found</td>\n",
              "      <td>no significant results are found</td>\n",
              "      <td>0.990595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>treatment is definitely not helpful</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   docid                               target  \\\n",
              "0      0     no significant results are found   \n",
              "1      1  treatment is definitely not helpful   \n",
              "2      2  treatment is definitely not helpful   \n",
              "3      3  treatment is definitely not helpful   \n",
              "4      4     no significant results are found   \n",
              "5      5   significant improvements are found   \n",
              "6      6  treatment is definitely not helpful   \n",
              "7      7   significant improvements are found   \n",
              "8      8  treatment is definitely not helpful   \n",
              "9      9  treatment is definitely not helpful   \n",
              "\n",
              "                             generated     score  \n",
              "0     no significant results are found  0.000000  \n",
              "1     no significant results are found  0.315579  \n",
              "2  treatment is definitely not helpful  0.000000  \n",
              "3     no significant results are found  0.315579  \n",
              "4     no significant results are found  0.000000  \n",
              "5   significant improvements are found  0.000000  \n",
              "6     no significant results are found  0.315579  \n",
              "7     no significant results are found  0.990595  \n",
              "8  treatment is definitely not helpful  0.000000  \n",
              "9  treatment is definitely not helpful  0.000000  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test usage on toy examples\n",
        "reload(evaluator)\n",
        "\n",
        "some_targets = [\"significant improvements are found\", \"treatment is definitely not helpful\", \"no significant results are found\"]\n",
        "a_generic_preface = \"studying this is important\"\n",
        "\n",
        "# modify targets_toy to include preface (key \"background\", value \"this is a test\")\n",
        "num_examples = 10\n",
        "\n",
        "targets_toy_2 = {\n",
        "    doc_key: {\n",
        "        \"target\": random.choice(some_targets),\n",
        "        \"preface\": a_generic_preface,\n",
        "    } for doc_key in range(num_examples)\n",
        "}\n",
        "generated_toy_2 = {\n",
        "    doc_key: random.choice(some_targets) for doc_key in range(num_examples)\n",
        "}\n",
        "\n",
        "# test usage\n",
        "results_toy = calculate_evidence_inference_divergence(\n",
        "    targets_toy_2,\n",
        "    generated_toy_2,\n",
        "    \"evaluator/bert_pipeline_8samples.json\",\n",
        "    \"evaluator/evidence_inference_models\",\n",
        ")\n",
        "# print everything except the raw scores\n",
        "for key, val in results_toy.items():\n",
        "    if key != \"scores\":\n",
        "        display(key, val)\n",
        "\n",
        "# Compare scores and target-generated pairs in a dataframe\n",
        "df_toy = pd.DataFrame({\n",
        "    \"docid\": list(targets_toy_2.keys()),\n",
        "    \"target\": [targets_toy_2[docid][\"target\"] for docid in targets_toy_2.keys()],\n",
        "    \"generated\": [generated_toy_2[docid] for docid in generated_toy_2.keys()],\n",
        "    \"score\": list(results_toy[\"scores\"]),\n",
        "})\n",
        "display(df_toy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing Delta Evidence Inference scores...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'average'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.5432441385412898"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'std'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.39463136145671507"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'uniform_preds'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "0.5406478590360975"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'f1_score'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'significantly decreased': {'precision': 0.09401709401709402,\n",
              "  'recall': 0.1981981981981982,\n",
              "  'f1-score': 0.127536231884058,\n",
              "  'support': 111.0},\n",
              " 'no significant difference': {'precision': 0.639599555061179,\n",
              "  'recall': 0.47364085667215816,\n",
              "  'f1-score': 0.5442498816848084,\n",
              "  'support': 1214.0},\n",
              " 'significantly increased': {'precision': 0.375,\n",
              "  'recall': 0.47844827586206895,\n",
              "  'f1-score': 0.42045454545454547,\n",
              "  'support': 696.0},\n",
              " 'accuracy': 0.46016823354774866,\n",
              " 'macro avg': {'precision': 0.369538883026091,\n",
              "  'recall': 0.3834291102441418,\n",
              "  'f1-score': 0.3640802196744706,\n",
              "  'support': 2021.0},\n",
              " 'weighted avg': {'precision': 0.518510518198995,\n",
              "  'recall': 0.46016823354774866,\n",
              "  'f1-score': 0.4787294615244193,\n",
              "  'support': 2021.0}}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>target</th>\n",
              "      <th>generated</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>28668150</td>\n",
              "      <td>( S ) Few studies of medical therapies for end...</td>\n",
              "      <td>In this study, the effects of continuous or cy...</td>\n",
              "      <td>0.019503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>28616252</td>\n",
              "      <td>Our case study successfully enabled us to addr...</td>\n",
              "      <td>This paper focuses on pilot studies, or \"feasi...</td>\n",
              "      <td>0.504117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>30921478</td>\n",
              "      <td>Two primary outcomes of efficacy and acceptabi...</td>\n",
              "      <td>A double blind trial of a combination of alpra...</td>\n",
              "      <td>0.006196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>10796152</td>\n",
              "      <td>REVIEW ER 'S CONCLUSIONS Iodine supplementatio...</td>\n",
              "      <td>In this study, the effects of reduced maternal...</td>\n",
              "      <td>0.485056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>26897342</td>\n",
              "      <td>Among children , these interventions demonstra...</td>\n",
              "      <td>The Switch program is a novel, evidence-based ...</td>\n",
              "      <td>0.983839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>28898559</td>\n",
              "      <td>Physical activity did not change at 6 months ,...</td>\n",
              "      <td>In this study, we examine the efficacy of a lo...</td>\n",
              "      <td>0.846085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>29279934</td>\n",
              "      <td>Subgroup analyses showed that these results we...</td>\n",
              "      <td>This study focuses on the effects of four-mont...</td>\n",
              "      <td>0.110708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>979</th>\n",
              "      <td>30985692</td>\n",
              "      <td>Results : This systematic review will provide ...</td>\n",
              "      <td>In this study, the combined efficaciousness of...</td>\n",
              "      <td>0.452037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1760</th>\n",
              "      <td>26081915</td>\n",
              "      <td>The findings support the effects of BAs on sat...</td>\n",
              "      <td>Gastric bypass is an effective treatment for T...</td>\n",
              "      <td>0.983107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>25978537</td>\n",
              "      <td>Reflecting public health interest in the poten...</td>\n",
              "      <td>In this study, we examine the effects of a six...</td>\n",
              "      <td>0.088469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         docid                                             target  \\\n",
              "1376  28668150  ( S ) Few studies of medical therapies for end...   \n",
              "15    28616252  Our case study successfully enabled us to addr...   \n",
              "329   30921478  Two primary outcomes of efficacy and acceptabi...   \n",
              "76    10796152  REVIEW ER 'S CONCLUSIONS Iodine supplementatio...   \n",
              "77    26897342  Among children , these interventions demonstra...   \n",
              "727   28898559  Physical activity did not change at 6 months ,...   \n",
              "515   29279934  Subgroup analyses showed that these results we...   \n",
              "979   30985692  Results : This systematic review will provide ...   \n",
              "1760  26081915  The findings support the effects of BAs on sat...   \n",
              "1549  25978537  Reflecting public health interest in the poten...   \n",
              "\n",
              "                                              generated     score  \n",
              "1376  In this study, the effects of continuous or cy...  0.019503  \n",
              "15    This paper focuses on pilot studies, or \"feasi...  0.504117  \n",
              "329   A double blind trial of a combination of alpra...  0.006196  \n",
              "76    In this study, the effects of reduced maternal...  0.485056  \n",
              "77    The Switch program is a novel, evidence-based ...  0.983839  \n",
              "727   In this study, we examine the efficacy of a lo...  0.846085  \n",
              "515   This study focuses on the effects of four-mont...  0.110708  \n",
              "979   In this study, the combined efficaciousness of...  0.452037  \n",
              "1760  Gastric bypass is an effective treatment for T...  0.983107  \n",
              "1549  In this study, we examine the effects of a six...  0.088469  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test on X sample docs\n",
        "generated_candidates_to_use = generated_longt5\n",
        "# num_examples = 100\n",
        "num_examples = len(generated_candidates_to_use)  # to get all examples\n",
        "\n",
        "targets_x_sample = {\n",
        "    doc_key: {\n",
        "        \"target\": targets[doc_key][\"target\"],\n",
        "        \"preface\": targets[doc_key][\"background\"],\n",
        "    } for doc_key in list(targets.keys())[:num_examples]\n",
        "}\n",
        "generated_x_sample = {\n",
        "    doc_key: generated_candidates_to_use[doc_key] for doc_key in targets_x_sample.keys()\n",
        "}\n",
        "results_x_sample = calculate_evidence_inference_divergence(\n",
        "    targets_x_sample,\n",
        "    generated_x_sample,\n",
        "    \"evaluator/bert_pipeline_8samples.json\",\n",
        "    \"evaluator/evidence_inference_models\",\n",
        ")\n",
        "\n",
        "# print everything except the raw scores\n",
        "for key, val in results_x_sample.items():\n",
        "    if key != \"scores\":\n",
        "        display(key, val)\n",
        "\n",
        "# Compare scores and target-generated pairs in a dataframe\n",
        "df_x_sample = pd.DataFrame({\n",
        "    \"docid\": list(targets_x_sample.keys()),\n",
        "    \"target\": [targets_x_sample[docid][\"target\"] for docid in targets_x_sample.keys()],\n",
        "    \"generated\": [generated_x_sample[docid] for docid in generated_x_sample.keys()],\n",
        "    \"score\": list(results_x_sample[\"scores\"]),\n",
        "})\n",
        "display(df_x_sample.sample(10))\n",
        "\n",
        "# save results to csv\n",
        "df_x_sample.to_csv(\"evaluator/evidence_inference_results_longt5.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Highest score: (higher is bad)\n",
            "[{'docid': '25076495',\n",
            "  'generated': \"The Nurses' Health Study, a large cohort study of women aged \"\n",
            "               '52-77 years, records the consumption of walnuts in relation to '\n",
            "               'risk of type two diabetes. In this paper, we report that there '\n",
            "               'is a significant lower risk of Type 2 disease in women who '\n",
            "               'consume more than 1 serving per day. Women who do not '\n",
            "               'frequently consume walnuts are also associated with an '\n",
            "               'increased risk of developing type 2 disease. We conclude that '\n",
            "               'higher nuts have a protective effect on both blood lipid and '\n",
            "               'body weight because they improve insulin sensitivity. A diet '\n",
            "               'rich in fat but low in carbohydrates has been shown to be '\n",
            "               'effective in improving many modifiably important '\n",
            "               'cardiovascular risk factors. Almond was found to be superior '\n",
            "               'to other dietary approaches in improving fasting blood '\n",
            "               'glucose, Hb1c, and trigglyceride levels. This suggests that '\n",
            "               'almonds may be beneficial for patients with Type 2 Diabetes.',\n",
            "  'score': 0.9970147662947663,\n",
            "  'target': 'No significant treatment effects were observed for fasting '\n",
            "            'insulin and HOMA-IR , however the direction of effect favoured '\n",
            "            'tree nuts .\\n'\n",
            "            'Pooled analyses show that tree nuts improve glycemic control in '\n",
            "            'individuals with type 2 diabetes , supporting their inclusion in '\n",
            "            'a healthy diet .'}]\n",
            "Lowest score: (lower is good)\n",
            "[{'docid': '32367221',\n",
            "  'generated': 'The first four months after ACL-reconstruction are described '\n",
            "               'in this paper. After two weeks, patients undergo a series of '\n",
            "               'exercises to improve their knee function. At the end of these '\n",
            "               'studies, there is little difference in pain and symptoms '\n",
            "               'between the two groupings. In contrast, both groups have '\n",
            "               'similar pain at 4 months. Both groups also report higher '\n",
            "               'sports activity scores than those in the other group. This '\n",
            "               'study concludes that neither type of autograft can be used for '\n",
            "               'ACL reconstructation because of reduced harvest site symptoms '\n",
            "               'and high injury rates. However, both types provide good long- '\n",
            "               'term subjective and objective outcome. Short-term results show '\n",
            "               'no differences in functional outcome or quality of life when '\n",
            "               'compared with one another. Seventeen years later, no '\n",
            "               'significant differences will be seen among the two groups. '\n",
            "               'Functional outcome questions such as the modified Cincinnati '\n",
            "               'knee Rating system and the International knee Documentation '\n",
            "               \"Committee are used to assess patient's functional and health \"\n",
            "               'status after knee surgical procedures. These surveys indicate '\n",
            "               'that all patients with complicated knee problems receive '\n",
            "               'improved functional outcomes from pre-operative measurements '\n",
            "               'through the two- year follow- up.',\n",
            "  'score': 0.0011715736671408167,\n",
            "  'target': 'The QT autograft detected comparable rate of Lachman test > 3 mm '\n",
            "            ', Pivot shift test > 3 m and instrumental laxity > 3 mm .\\n'\n",
            "            'The QT autograft showed a lower rate of autograft failure above '\n",
            "            'all .\\n'\n",
            "            'The QT autograft detected the reduced rate of AKP than the PT .\\n'\n",
            "            'Quadriceps tendon autograft may represent a feasible option for '\n",
            "            'primary ACL reconstruction .'}]\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "\n",
        "# What's actually happening?\n",
        "# find the docid with the highest score\n",
        "print(\"Highest score: (higher is bad)\")\n",
        "pprint.pprint(df_x_sample.sort_values(by=\"score\", ascending=False).head(1).to_dict(orient=\"records\"))\n",
        "\n",
        "# find the docid with the lowest score\n",
        "print(\"Lowest score: (lower is good)\")\n",
        "pprint.pprint(df_x_sample.sort_values(by=\"score\", ascending=True).head(1).to_dict(orient=\"records\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "##### Running BioBART #####\n",
            "Computing Delta Evidence Inference scores...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Wrap in a loop\n",
        "\n",
        "model_results = {}\n",
        "for model_name, generated_candidates_to_use in [\n",
        "    (\"BioBART\", generated_biobart),\n",
        "    (\"LongT5\", generated_longt5),\n",
        "    (\"Pegasus\", generated_pegasus),\n",
        "]:\n",
        "    print(f\"\\n\\n##### Running {model_name} #####\")\n",
        "    num_examples = len(generated_candidates_to_use)  # to get all examples\n",
        "\n",
        "    targets_x_sample = {\n",
        "        doc_key: {\n",
        "            \"target\": targets[doc_key][\"target\"],\n",
        "            \"preface\": targets[doc_key][\"background\"],\n",
        "        } for doc_key in list(targets.keys())[:num_examples]\n",
        "    }\n",
        "    generated_x_sample = {\n",
        "        doc_key: generated_candidates_to_use[doc_key] for doc_key in targets_x_sample.keys()\n",
        "    }\n",
        "    results_x_sample = calculate_evidence_inference_divergence(\n",
        "        targets_x_sample,\n",
        "        generated_x_sample,\n",
        "        \"evaluator/bert_pipeline_8samples.json\",\n",
        "        \"evaluator/evidence_inference_models\",\n",
        "    )\n",
        "    model_results[model_name] = {}\n",
        "    model_results[model_name][\"results\"] = results_x_sample\n",
        "\n",
        "    # print everything except the raw scores\n",
        "    for key, val in results_x_sample.items():\n",
        "        if key != \"scores\":\n",
        "            display(key, val)\n",
        "\n",
        "    # Compare scores and target-generated pairs in a dataframe\n",
        "    df_x_sample = pd.DataFrame({\n",
        "        \"docid\": list(targets_x_sample.keys()),\n",
        "        \"target\": [targets_x_sample[docid][\"target\"] for docid in targets_x_sample.keys()],\n",
        "        \"generated\": [generated_x_sample[docid] for docid in generated_x_sample.keys()],\n",
        "        \"score\": list(results_x_sample[\"scores\"]),\n",
        "    })\n",
        "    model_results[model_name][\"df\"] = df_x_sample\n",
        "    display(df_x_sample.sample(10))\n",
        "\n",
        "    # save results to csv\n",
        "    df_x_sample.to_csv(f\"evaluator/evidence_inference_results_{model_name.lower()}.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
