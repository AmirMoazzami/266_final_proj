{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6baf52d7-9b7e-477c-a1e4-161df03b3529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets sentencepiece rouge_score\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2385c429-3d90-412c-98ec-fd66c665efae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip -q install torch\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28067337-faa8-4dee-ae51-b5a6b3f56de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722f043b-9ce4-402c-a11c-f1270ab1c501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF is set to: max_split_size_mb:256\n",
      "device: cpu\n",
      "['review_id', 'pmid', 'title', 'abstract', 'target', 'background']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Memory optimization for CUDA\n",
    "max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF is set to: {os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "#when on Nvida machins \n",
    "# device = torch.device(\"cuda\")\n",
    "# print(\"device:\", device)\n",
    "\n",
    "#when you are on mac\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "# Load LongT5 Model and Tokenizer\n",
    "# model_to_use = \"google/long-t5-local-base\"\n",
    "model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "# Load validation dataset from Hugging Face datasets\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='train')\n",
    "\n",
    "\n",
    "# Prepare DataFrame for output\n",
    "# output_df = pd.DataFrame(columns=['ReviewID', 'Candidate_Summary', 'Target'])\n",
    "output_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204c07ba-5173-4625-9643-b93211736d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "      <th>background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>[22776744, 25271670, 3493740, 1863023, 1629198...</td>\n",
       "      <td>[Improved Cell Survival and Paracrine Capacity...</td>\n",
       "      <td>[Although transplantation of adult bone marrow...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "      <td>Background Despite significant progress in dru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                               pmid  \\\n",
       "0  30760312  [22776744, 25271670, 3493740, 1863023, 1629198...   \n",
       "\n",
       "                                               title  \\\n",
       "0  [Improved Cell Survival and Paracrine Capacity...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  [Although transplantation of adult bone marrow...   \n",
       "\n",
       "                                              target  \\\n",
       "0  Conclusions SC therapy is effective for PAH in...   \n",
       "\n",
       "                                          background  \n",
       "0  Background Despite significant progress in dru...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847e1ad4-db68-447e-aea8-b398f174d113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.drop(['pmid', 'title','background'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbd1db-7ebc-402a-920b-7dcd48cb28fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f767c828-6b16-4f48-b768-f32f8f392689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>[Although transplantation of adult bone marrow...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  30760312  [Although transplantation of adult bone marrow...   \n",
       "\n",
       "                                              target  \n",
       "0  Conclusions SC therapy is effective for PAH in...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c12e54a5-fb63-4a05-a808-004d72d17280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df['abstract'] = output_df['abstract'].apply(lambda x: \"\".join([f\"Study : \" + b for i,b in enumerate(x)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed340481-15b9-4fac-a86f-77e7609f56f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>Study : Although transplantation of adult bone...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19588356</td>\n",
       "      <td>Study : BACKGROUND Primary pulmonary hypertens...</td>\n",
       "      <td>There was a trend for endothelin receptor anta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23893797</td>\n",
       "      <td>Study : BACKGROUND Although improved epicardia...</td>\n",
       "      <td>This present meta- analysis suggests that stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  30760312  Study : Although transplantation of adult bone...   \n",
       "1  19588356  Study : BACKGROUND Primary pulmonary hypertens...   \n",
       "2  23893797  Study : BACKGROUND Although improved epicardia...   \n",
       "\n",
       "                                              target  \n",
       "0  Conclusions SC therapy is effective for PAH in...  \n",
       "1  There was a trend for endothelin receptor anta...  \n",
       "2  This present meta- analysis suggests that stat...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dd9d16-5424-4d9c-91b6-a7ef0dced698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14188, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c7ca174-f4b4-454f-ab6f-56e71ab98912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers -q\n",
    "# !pip uninstall transformers\n",
    "# !pip install transformers\n",
    "# !pip uninstall -y pytorch-lightning\n",
    "# !pip install pytorch-lightning==1.5.10\n",
    "# !pip install -q --upgrade simplet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb4738fb-7770-4768-b124-7db68d83eb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4112e2c1-e9de-4f14-87ad-cafc02ba47dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # Load the dataset and cut down to the first 5 for demonstration\n",
    "# # dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "# # dataset = dataset.select(range(3))  # Use select to create a subset\n",
    "\n",
    "# # Initialize BERT\n",
    "# # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# # model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# def bert_sentence_embeddings(sentences):\n",
    "#     embeddings = []\n",
    "#     for sentence in sentences:\n",
    "#         inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "#         embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "#     return np.array(embeddings)\n",
    "\n",
    "# def select_top_sentences(sentences, embeddings, n_sentences=5):\n",
    "#     if len(sentences) < n_sentences:\n",
    "#         return ' '.join(sentences)\n",
    "#     kmeans = KMeans(n_clusters=n_sentences, n_init=10)\n",
    "#     kmeans.fit(embeddings)\n",
    "#     top_sentences =[]\n",
    "#     i = 0\n",
    "#     while len(top_sentences) < n_sentences:\n",
    "#         top_sentence_indices = np.argmin(\n",
    "#         np.linalg.norm(embeddings[:, np.newaxis] - kmeans.cluster_centers_[i], axis=2), axis=0)\n",
    "#         top_sentences.append(sentences[top_sentence_indices[0]])\n",
    "#     return ' '.join(top_sentences)\n",
    "\n",
    "# def process_row( abstract_text):\n",
    "#     # Split abstract into sentences\n",
    "#     sentences = abstract_text.split('. ')\n",
    "#     # Generate embeddings for each sentence\n",
    "#     embeddings = bert_sentence_embeddings(sentences)\n",
    "#     # Select the top sentences from these embeddings\n",
    "#     summary = select_top_sentences(sentences, embeddings)\n",
    "        \n",
    "#     return summary\n",
    "        \n",
    "\n",
    "                             \n",
    "                             \n",
    "# output_df['abstract'] = output_df['abstract'].apply(lambda x:process_row(x) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1791ca14-a2ba-4420-bb15-7e3fcf706661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>Study : Although transplantation of adult bone...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  30760312  Study : Although transplantation of adult bone...   \n",
       "\n",
       "                                              target  \n",
       "0  Conclusions SC therapy is effective for PAH in...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad472d5-5d94-41ad-9417-1318e91bbb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06773bba-a77b-479c-996d-9838e2e8a9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the dataset from a CSV file\n",
    "# dataset_path = '/mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/BioBERT_K_Means_extractive.csv'\n",
    "# summaries_dataset = pd.read_csv(dataset_path , index_col=False)\n",
    "# # Convert the dataset to a list of dictionaries\n",
    "# data_list = summaries_dataset.to_dict(orient='records')\n",
    "# summaries_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa3dc79a-6a57-458f-be8c-e30321a185c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>No adverse effects were observed . The effects...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                           abstract  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "1   18842808  No adverse effects were observed . The effects...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  \n",
       "1  The use of glucomannan did not appear to signi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first dataset\n",
    "dataset_path = '/mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/BioBERT_K_Means_extractive.csv'\n",
    "summaries_dataset = pd.read_csv(dataset_path, index_col=False)\n",
    "\n",
    "# Rename the 'summary' column to 'abstract'\n",
    "summaries_dataset.rename(columns={'summary': 'abstract'}, inplace=True)\n",
    "\n",
    "# Convert the 'review_id' column in summaries_dataset to integer (if it's not already)\n",
    "summaries_dataset['review_id'] = summaries_dataset['review_id'].astype(int)\n",
    "\n",
    "# Load the second dataset\n",
    "# (Assuming you have already loaded this dataset as 'output_df' in your previous steps)\n",
    "\n",
    "# Convert the 'review_id' column in output_df to integer (if it's not already)\n",
    "output_df['review_id'] = output_df['review_id'].astype(int)\n",
    "\n",
    "# Merge the two datasets based on 'review_id'\n",
    "merged_dataset = pd.merge(output_df, summaries_dataset[['review_id', 'abstract']], on='review_id', how='left')\n",
    "# merged_dataset.head(2)\n",
    "# merged_dataset.shape[0]\n",
    "# Replace the 'abstract' column in output_df with the one from summaries_dataset\n",
    "output_df['abstract'] = merged_dataset['abstract_y']\n",
    "output_df.head(2)\n",
    "\n",
    "# Now output_df will have the updated abstracts from summaries_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93795d07-ba9f-4ba0-87da-666e2d24a9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.rename(columns={\"target\":\"target_text\", \"abstract\":\"source_text\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04db8e34-06fe-42f6-8484-e3f2c513a4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>Study : Although transplantation of adult bone...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                        source_text  \\\n",
       "0  30760312  Study : Although transplantation of adult bone...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Conclusions SC therapy is effective for PAH in...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31a80d25-9352-4852-8164-be8882e8b86d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14188, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8de3d8c-92ff-42f7-b4d2-0e4972e72c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 20:33:59.723696: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-29 20:33:59.955360: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Load LongT5 Model and Tokenizer\n",
    "# model_to_use = \"google/long-t5-local-base\"\n",
    "# model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "# longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "# longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "from simplet5 import SimpleT5\n",
    "model=SimpleT5()\n",
    "model.from_pretrained(model_type=\"longt5\",model_name=\"pszemraj/long-t5-tglobal-base-16384-book-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919a104-c929-4dee-a117-1ac965a19cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type longt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at pszemraj/long-t5-tglobal-base-16384-book-summary and are newly initialized: ['encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.k.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.k.weight', 'encoder.block.11.layer.0.SelfAttention.o.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.6.layer.0.SelfAttention.o.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 247 M \n",
      "-----------------------------------------------------\n",
      "247 M     Trainable params\n",
      "0         Non-trainable params\n",
      "247 M     Total params\n",
      "990.311   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|███████▉  | 5675/7094 [1:50:36<27:39,  1.17s/it, loss=2.83, v_num=260027, train_loss_step=3.330]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 5685/7094 [1:50:39<27:25,  1.17s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:08,  2.11it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 5695/7094 [1:50:43<27:12,  1.17s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:30,  2.22it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 5705/7094 [1:50:48<26:58,  1.17s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:18,  2.24it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5715/7094 [1:50:52<26:45,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:09,  2.26it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5725/7094 [1:50:56<26:31,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:04,  2.26it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5735/7094 [1:51:01<26:18,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   4%|▍         | 60/1419 [00:26<09:59,  2.27it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5745/7094 [1:51:05<26:05,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:54,  2.27it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5755/7094 [1:51:10<25:51,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:49,  2.27it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 5765/7094 [1:51:14<25:38,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:44,  2.27it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 5775/7094 [1:51:18<25:25,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:40,  2.27it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5785/7094 [1:51:23<25:12,  1.16s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   8%|▊         | 110/1419 [00:48<09:36,  2.27it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5795/7094 [1:51:27<24:59,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:32,  2.27it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5805/7094 [1:51:32<24:45,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:26,  2.27it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5815/7094 [1:51:36<24:32,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:23,  2.27it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5825/7094 [1:51:40<24:19,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:19,  2.27it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5835/7094 [1:51:45<24:06,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  11%|█▏        | 160/1419 [01:10<09:16,  2.26it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5845/7094 [1:51:49<23:53,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:11,  2.26it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5855/7094 [1:51:54<23:40,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  13%|█▎        | 180/1419 [01:19<09:06,  2.27it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5865/7094 [1:51:58<23:27,  1.15s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:02,  2.27it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5875/7094 [1:52:02<23:14,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<08:56,  2.27it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5885/7094 [1:52:07<23:02,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  15%|█▍        | 210/1419 [01:32<08:54,  2.26it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5895/7094 [1:52:11<22:49,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:48,  2.27it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5905/7094 [1:52:16<22:36,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  16%|█▌        | 230/1419 [01:41<08:45,  2.26it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5915/7094 [1:52:20<22:23,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:40,  2.27it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 5925/7094 [1:52:25<22:10,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  18%|█▊        | 250/1419 [01:50<08:35,  2.27it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 5935/7094 [1:52:29<21:58,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  18%|█▊        | 260/1419 [01:54<08:30,  2.27it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5945/7094 [1:52:33<21:45,  1.14s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:26,  2.27it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5955/7094 [1:52:38<21:32,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  20%|█▉        | 280/1419 [02:03<08:21,  2.27it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5965/7094 [1:52:42<21:19,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:16,  2.27it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5975/7094 [1:52:47<21:07,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  21%|██        | 300/1419 [02:12<08:12,  2.27it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5985/7094 [1:52:51<20:54,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  22%|██▏       | 310/1419 [02:16<08:08,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 5995/7094 [1:52:55<20:42,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  23%|██▎       | 320/1419 [02:21<08:04,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 6005/7094 [1:53:00<20:29,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  23%|██▎       | 330/1419 [02:25<07:59,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 6015/7094 [1:53:04<20:17,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:55,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 6025/7094 [1:53:09<20:04,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  25%|██▍       | 350/1419 [02:34<07:51,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6035/7094 [1:53:13<19:52,  1.13s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:46,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6045/7094 [1:53:17<19:39,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  26%|██▌       | 370/1419 [02:43<07:42,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6055/7094 [1:53:22<19:27,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  27%|██▋       | 380/1419 [02:47<07:36,  2.27it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6065/7094 [1:53:26<19:14,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  27%|██▋       | 390/1419 [02:52<07:33,  2.27it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6075/7094 [1:53:31<19:02,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  28%|██▊       | 400/1419 [02:56<07:29,  2.27it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6085/7094 [1:53:35<18:50,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  29%|██▉       | 410/1419 [03:01<07:25,  2.27it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6095/7094 [1:53:39<18:37,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  30%|██▉       | 420/1419 [03:05<07:20,  2.27it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6105/7094 [1:53:44<18:25,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  30%|███       | 430/1419 [03:09<07:15,  2.27it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6115/7094 [1:53:48<18:13,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  31%|███       | 440/1419 [03:14<07:12,  2.26it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▋ | 6125/7094 [1:53:53<18:01,  1.12s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  32%|███▏      | 450/1419 [03:18<07:07,  2.27it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▋ | 6135/7094 [1:53:57<17:48,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  32%|███▏      | 460/1419 [03:23<07:03,  2.26it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6145/7094 [1:54:01<17:36,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  33%|███▎      | 470/1419 [03:27<06:58,  2.27it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6155/7094 [1:54:06<17:24,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  34%|███▍      | 480/1419 [03:31<06:53,  2.27it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6165/7094 [1:54:10<17:12,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  35%|███▍      | 490/1419 [03:36<06:49,  2.27it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6175/7094 [1:54:15<17:00,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  35%|███▌      | 500/1419 [03:40<06:45,  2.27it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6185/7094 [1:54:19<16:48,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  36%|███▌      | 510/1419 [03:45<06:40,  2.27it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6195/7094 [1:54:24<16:36,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  37%|███▋      | 520/1419 [03:49<06:35,  2.27it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6205/7094 [1:54:28<16:24,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  37%|███▋      | 530/1419 [03:53<06:31,  2.27it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6215/7094 [1:54:32<16:12,  1.11s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  38%|███▊      | 540/1419 [03:58<06:27,  2.27it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6225/7094 [1:54:37<16:00,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  39%|███▉      | 550/1419 [04:02<06:23,  2.27it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6235/7094 [1:54:41<15:48,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  39%|███▉      | 560/1419 [04:07<06:19,  2.26it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6245/7094 [1:54:46<15:36,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  40%|████      | 570/1419 [04:11<06:14,  2.27it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6255/7094 [1:54:50<15:24,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  41%|████      | 580/1419 [04:16<06:10,  2.26it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6265/7094 [1:54:54<15:12,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  42%|████▏     | 590/1419 [04:20<06:05,  2.27it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6275/7094 [1:54:59<15:00,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  42%|████▏     | 600/1419 [04:24<06:01,  2.27it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 6285/7094 [1:55:03<14:48,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  43%|████▎     | 610/1419 [04:29<05:57,  2.26it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 6295/7094 [1:55:08<14:36,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  44%|████▎     | 620/1419 [04:33<05:52,  2.27it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6305/7094 [1:55:12<14:25,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  44%|████▍     | 630/1419 [04:38<05:47,  2.27it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6315/7094 [1:55:16<14:13,  1.10s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  45%|████▌     | 640/1419 [04:42<05:42,  2.27it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6325/7094 [1:55:21<14:01,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  46%|████▌     | 650/1419 [04:46<05:39,  2.27it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6335/7094 [1:55:25<13:49,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  47%|████▋     | 660/1419 [04:51<05:35,  2.27it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6345/7094 [1:55:30<13:38,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  47%|████▋     | 670/1419 [04:55<05:30,  2.27it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 6355/7094 [1:55:34<13:26,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  48%|████▊     | 680/1419 [05:00<05:25,  2.27it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 6365/7094 [1:55:38<13:14,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  49%|████▊     | 690/1419 [05:04<05:20,  2.27it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 6375/7094 [1:55:43<13:03,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  49%|████▉     | 700/1419 [05:08<05:16,  2.27it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6385/7094 [1:55:47<12:51,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  50%|█████     | 710/1419 [05:13<05:11,  2.27it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6395/7094 [1:55:52<12:39,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  51%|█████     | 720/1419 [05:17<05:08,  2.27it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6405/7094 [1:55:56<12:28,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:22<05:03,  2.27it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6415/7094 [1:56:00<12:16,  1.09s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:26<04:59,  2.27it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6425/7094 [1:56:05<12:05,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:30<04:54,  2.27it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6435/7094 [1:56:09<11:53,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:35<04:50,  2.27it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6445/7094 [1:56:14<11:42,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:39<04:45,  2.27it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6455/7094 [1:56:18<11:30,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:44<04:41,  2.27it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6465/7094 [1:56:23<11:19,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:48<04:37,  2.27it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 6475/7094 [1:56:27<11:07,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:52<04:32,  2.27it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 6485/7094 [1:56:31<10:56,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:57<04:28,  2.27it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6495/7094 [1:56:36<10:45,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:01<04:23,  2.27it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6505/7094 [1:56:40<10:33,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:06<04:19,  2.27it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6515/7094 [1:56:45<10:22,  1.08s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:10<04:15,  2.27it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6525/7094 [1:56:49<10:11,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:14<04:10,  2.27it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6535/7094 [1:56:53<09:59,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  61%|██████    | 860/1419 [06:19<04:06,  2.27it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6545/7094 [1:56:58<09:48,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:23<04:02,  2.27it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6555/7094 [1:57:02<09:37,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:28<03:58,  2.26it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6565/7094 [1:57:07<09:26,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:32<03:53,  2.27it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6575/7094 [1:57:11<09:15,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:37<03:48,  2.27it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6585/7094 [1:57:15<09:03,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:41<03:44,  2.27it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6595/7094 [1:57:20<08:52,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:45<03:39,  2.27it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6605/7094 [1:57:24<08:41,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:50<03:35,  2.27it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6615/7094 [1:57:29<08:30,  1.07s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:54<03:31,  2.27it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6625/7094 [1:57:33<08:19,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  67%|██████▋   | 950/1419 [06:59<03:26,  2.27it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 6635/7094 [1:57:37<08:08,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:03<03:21,  2.27it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 6645/7094 [1:57:42<07:57,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:07<03:17,  2.27it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6655/7094 [1:57:46<07:46,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:12<03:13,  2.27it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6665/7094 [1:57:51<07:35,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:16<03:09,  2.27it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6675/7094 [1:57:55<07:24,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  70%|███████   | 1000/1419 [07:21<03:04,  2.26it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6685/7094 [1:58:00<07:13,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  71%|███████   | 1010/1419 [07:25<03:00,  2.27it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6695/7094 [1:58:04<07:02,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:29<02:56,  2.27it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6705/7094 [1:58:08<06:51,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:34<02:51,  2.26it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6715/7094 [1:58:13<06:40,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:38<02:47,  2.26it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6725/7094 [1:58:17<06:29,  1.06s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:43<02:42,  2.27it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6735/7094 [1:58:22<06:18,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:47<02:38,  2.26it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 6745/7094 [1:58:26<06:07,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:52<02:34,  2.27it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 6755/7094 [1:58:30<05:56,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:56<02:29,  2.27it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 6765/7094 [1:58:35<05:46,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:00<02:25,  2.26it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6775/7094 [1:58:39<05:35,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:05<02:21,  2.26it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6785/7094 [1:58:44<05:24,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:09<02:16,  2.26it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6795/7094 [1:58:48<05:13,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:14<02:11,  2.27it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6805/7094 [1:58:52<05:02,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:18<02:07,  2.27it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6815/7094 [1:58:57<04:52,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  80%|████████  | 1140/1419 [08:22<02:03,  2.27it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6825/7094 [1:59:01<04:41,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  81%|████████  | 1150/1419 [08:27<01:58,  2.27it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 6835/7094 [1:59:06<04:30,  1.05s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:31<01:54,  2.27it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 6845/7094 [1:59:10<04:20,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:36<01:49,  2.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6855/7094 [1:59:15<04:09,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:40<01:45,  2.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6865/7094 [1:59:19<03:58,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:44<01:40,  2.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6875/7094 [1:59:23<03:48,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:49<01:36,  2.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6885/7094 [1:59:28<03:37,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:53<01:31,  2.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6895/7094 [1:59:32<03:27,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  86%|████████▌ | 1220/1419 [08:58<01:27,  2.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6905/7094 [1:59:37<03:16,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:02<01:23,  2.27it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6915/7094 [1:59:41<03:05,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:07<01:18,  2.27it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6925/7094 [1:59:45<02:55,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:11<01:14,  2.27it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6935/7094 [1:59:50<02:44,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:15<01:09,  2.27it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6945/7094 [1:59:54<02:34,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:20<01:05,  2.27it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6955/7094 [1:59:59<02:23,  1.04s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:24<01:01,  2.27it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6965/7094 [2:00:03<02:13,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:29<00:57,  2.26it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6975/7094 [2:00:07<02:02,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:33<00:52,  2.27it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6985/7094 [2:00:12<01:52,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:37<00:48,  2.27it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 6995/7094 [2:00:16<01:42,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:42<00:43,  2.27it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 7005/7094 [2:00:21<01:31,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:46<00:39,  2.27it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7015/7094 [2:00:25<01:21,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:51<00:34,  2.27it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7025/7094 [2:00:29<01:11,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  95%|█████████▌| 1350/1419 [09:55<00:30,  2.27it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7035/7094 [2:00:34<01:00,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  96%|█████████▌| 1360/1419 [09:59<00:25,  2.27it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7045/7094 [2:00:38<00:50,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:04<00:21,  2.28it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7055/7094 [2:00:43<00:40,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:08<00:17,  2.26it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 7065/7094 [2:00:47<00:29,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:13<00:12,  2.27it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 7075/7094 [2:00:51<00:19,  1.03s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:17<00:08,  2.27it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 7085/7094 [2:00:56<00:09,  1.02s/it, loss=2.83, v_num=260027, train_loss_step=3.330]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:21<00:03,  2.27it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:24<00:01,  2.27it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 7094/7094 [2:01:02<00:00,  1.02s/it, loss=2.83, v_num=260027, train_loss_step=3.330, val_loss_step=2.910, val_loss_epoch=2.690]\n",
      "Epoch 1:  80%|███████▉  | 5675/7094 [1:50:33<27:38,  1.17s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 5685/7094 [1:50:36<27:24,  1.17s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:22,  2.07it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 5695/7094 [1:50:41<27:11,  1.17s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:36,  2.20it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 5705/7094 [1:50:45<26:57,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:19,  2.24it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5715/7094 [1:50:49<26:44,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:10,  2.26it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5725/7094 [1:50:54<26:31,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:04,  2.27it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5735/7094 [1:50:58<26:17,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   4%|▍         | 60/1419 [00:26<09:59,  2.27it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5745/7094 [1:51:03<26:04,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:55,  2.26it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5755/7094 [1:51:07<25:51,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:50,  2.27it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 5765/7094 [1:51:11<25:38,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:44,  2.27it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 5775/7094 [1:51:16<25:24,  1.16s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:40,  2.27it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5785/7094 [1:51:20<25:11,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   8%|▊         | 110/1419 [00:48<09:36,  2.27it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5795/7094 [1:51:25<24:58,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:31,  2.27it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5805/7094 [1:51:29<24:45,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:27,  2.27it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5815/7094 [1:51:33<24:32,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:22,  2.27it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5825/7094 [1:51:38<24:19,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:19,  2.27it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5835/7094 [1:51:42<24:06,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  11%|█▏        | 160/1419 [01:10<09:13,  2.27it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5845/7094 [1:51:47<23:53,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:09,  2.27it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5855/7094 [1:51:51<23:40,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  13%|█▎        | 180/1419 [01:19<09:04,  2.28it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5865/7094 [1:51:55<23:27,  1.15s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:01,  2.27it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5875/7094 [1:52:00<23:14,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<08:57,  2.27it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5885/7094 [1:52:04<23:01,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:53,  2.27it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5895/7094 [1:52:09<22:48,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:49,  2.27it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5905/7094 [1:52:13<22:35,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  16%|█▌        | 230/1419 [01:41<08:43,  2.27it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5915/7094 [1:52:18<22:23,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:39,  2.27it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 5925/7094 [1:52:22<22:10,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  18%|█▊        | 250/1419 [01:50<08:34,  2.27it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 5935/7094 [1:52:26<21:57,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:29,  2.27it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5945/7094 [1:52:31<21:44,  1.14s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:25,  2.27it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5955/7094 [1:52:35<21:32,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  20%|█▉        | 280/1419 [02:03<08:21,  2.27it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5965/7094 [1:52:40<21:19,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:17,  2.27it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5975/7094 [1:52:44<21:06,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  21%|██        | 300/1419 [02:12<08:13,  2.27it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5985/7094 [1:52:48<20:54,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  22%|██▏       | 310/1419 [02:17<08:08,  2.27it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 5995/7094 [1:52:53<20:41,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  23%|██▎       | 320/1419 [02:21<08:04,  2.27it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 6005/7094 [1:52:57<20:29,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  23%|██▎       | 330/1419 [02:25<08:03,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 6015/7094 [1:53:02<20:16,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:56,  2.26it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 6025/7094 [1:53:06<20:04,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  25%|██▍       | 350/1419 [02:34<07:51,  2.27it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6035/7094 [1:53:10<19:51,  1.13s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:46,  2.27it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6045/7094 [1:53:15<19:39,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  26%|██▌       | 370/1419 [02:43<07:42,  2.27it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6055/7094 [1:53:19<19:26,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  27%|██▋       | 380/1419 [02:47<07:37,  2.27it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6065/7094 [1:53:24<19:14,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  27%|██▋       | 390/1419 [02:52<07:33,  2.27it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6075/7094 [1:53:28<19:02,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  28%|██▊       | 400/1419 [02:56<07:29,  2.27it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6085/7094 [1:53:32<18:49,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  29%|██▉       | 410/1419 [03:01<07:25,  2.27it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6095/7094 [1:53:37<18:37,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  30%|██▉       | 420/1419 [03:05<07:20,  2.27it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6105/7094 [1:53:41<18:25,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  30%|███       | 430/1419 [03:09<07:16,  2.27it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6115/7094 [1:53:46<18:12,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  31%|███       | 440/1419 [03:14<07:11,  2.27it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 6125/7094 [1:53:50<18:00,  1.12s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  32%|███▏      | 450/1419 [03:18<07:06,  2.27it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 6135/7094 [1:53:55<17:48,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  32%|███▏      | 460/1419 [03:23<07:02,  2.27it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6145/7094 [1:53:59<17:36,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  33%|███▎      | 470/1419 [03:27<06:57,  2.27it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6155/7094 [1:54:03<17:24,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  34%|███▍      | 480/1419 [03:32<06:55,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6165/7094 [1:54:08<17:11,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  35%|███▍      | 490/1419 [03:36<06:50,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6175/7094 [1:54:12<16:59,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  35%|███▌      | 500/1419 [03:40<06:44,  2.27it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6185/7094 [1:54:17<16:47,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  36%|███▌      | 510/1419 [03:45<06:40,  2.27it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6195/7094 [1:54:21<16:35,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  37%|███▋      | 520/1419 [03:49<06:35,  2.27it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6205/7094 [1:54:25<16:23,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  37%|███▋      | 530/1419 [03:54<06:31,  2.27it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6215/7094 [1:54:30<16:11,  1.11s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  38%|███▊      | 540/1419 [03:58<06:26,  2.27it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6225/7094 [1:54:34<15:59,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  39%|███▉      | 550/1419 [04:02<06:22,  2.27it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6235/7094 [1:54:39<15:47,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  39%|███▉      | 560/1419 [04:07<06:18,  2.27it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6245/7094 [1:54:43<15:35,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  40%|████      | 570/1419 [04:11<06:14,  2.27it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6255/7094 [1:54:47<15:23,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  41%|████      | 580/1419 [04:16<06:10,  2.26it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6265/7094 [1:54:52<15:12,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  42%|████▏     | 590/1419 [04:20<06:05,  2.27it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6275/7094 [1:54:56<15:00,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  42%|████▏     | 600/1419 [04:24<06:01,  2.27it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 6285/7094 [1:55:01<14:48,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  43%|████▎     | 610/1419 [04:29<05:56,  2.27it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 6295/7094 [1:55:05<14:36,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  44%|████▎     | 620/1419 [04:33<05:51,  2.27it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6305/7094 [1:55:09<14:24,  1.10s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  44%|████▍     | 630/1419 [04:38<05:48,  2.26it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6315/7094 [1:55:14<14:12,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  45%|████▌     | 640/1419 [04:42<05:43,  2.27it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6325/7094 [1:55:18<14:01,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  46%|████▌     | 650/1419 [04:46<05:39,  2.26it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6335/7094 [1:55:23<13:49,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  47%|████▋     | 660/1419 [04:51<05:34,  2.27it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6345/7094 [1:55:27<13:37,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  47%|████▋     | 670/1419 [04:55<05:30,  2.26it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 6355/7094 [1:55:32<13:26,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  48%|████▊     | 680/1419 [05:00<05:25,  2.27it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 6365/7094 [1:55:36<13:14,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  49%|████▊     | 690/1419 [05:04<05:20,  2.27it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 6375/7094 [1:55:40<13:02,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  49%|████▉     | 700/1419 [05:09<05:16,  2.27it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6385/7094 [1:55:45<12:51,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  50%|█████     | 710/1419 [05:13<05:12,  2.27it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6395/7094 [1:55:49<12:39,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  51%|█████     | 720/1419 [05:17<05:07,  2.27it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6405/7094 [1:55:54<12:28,  1.09s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:22<05:02,  2.27it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6415/7094 [1:55:58<12:16,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:26<04:58,  2.27it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6425/7094 [1:56:02<12:05,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:31<04:55,  2.27it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6435/7094 [1:56:07<11:53,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:35<04:50,  2.27it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6445/7094 [1:56:11<11:42,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:39<04:45,  2.27it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6455/7094 [1:56:16<11:30,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:44<04:41,  2.27it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6465/7094 [1:56:20<11:19,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:48<04:36,  2.27it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 6475/7094 [1:56:24<11:07,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:53<04:32,  2.27it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 6485/7094 [1:56:29<10:56,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:57<04:27,  2.28it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6495/7094 [1:56:33<10:44,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:01<04:22,  2.28it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6505/7094 [1:56:38<10:33,  1.08s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:06<04:19,  2.27it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6515/7094 [1:56:42<10:22,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:10<04:14,  2.27it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6525/7094 [1:56:46<10:11,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:15<04:10,  2.27it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6535/7094 [1:56:51<09:59,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  61%|██████    | 860/1419 [06:19<04:05,  2.27it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6545/7094 [1:56:55<09:48,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:23<04:01,  2.27it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6555/7094 [1:57:00<09:37,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:28<03:56,  2.28it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6565/7094 [1:57:04<09:26,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:32<03:52,  2.27it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6575/7094 [1:57:08<09:14,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:37<03:48,  2.27it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6585/7094 [1:57:13<09:03,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:41<03:44,  2.27it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6595/7094 [1:57:17<08:52,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:45<03:40,  2.27it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6605/7094 [1:57:22<08:41,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:50<03:35,  2.27it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6615/7094 [1:57:26<08:30,  1.07s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:54<03:31,  2.27it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6625/7094 [1:57:30<08:19,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  67%|██████▋   | 950/1419 [06:59<03:26,  2.27it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 6635/7094 [1:57:35<08:08,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:03<03:22,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 6645/7094 [1:57:39<07:57,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:07<03:18,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6655/7094 [1:57:44<07:45,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:12<03:14,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6665/7094 [1:57:48<07:34,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:16<03:09,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6675/7094 [1:57:52<07:23,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  70%|███████   | 1000/1419 [07:21<03:05,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6685/7094 [1:57:57<07:13,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  71%|███████   | 1010/1419 [07:25<03:01,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6695/7094 [1:58:01<07:02,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:30<02:56,  2.26it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6705/7094 [1:58:06<06:51,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:34<02:51,  2.26it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6715/7094 [1:58:10<06:40,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:38<02:47,  2.27it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6725/7094 [1:58:15<06:29,  1.06s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:43<02:42,  2.26it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6735/7094 [1:58:19<06:18,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:47<02:38,  2.27it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 6745/7094 [1:58:23<06:07,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:52<02:33,  2.27it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 6755/7094 [1:58:28<05:56,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:56<02:29,  2.27it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 6765/7094 [1:58:32<05:45,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:00<02:24,  2.27it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6775/7094 [1:58:37<05:35,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:05<02:20,  2.27it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6785/7094 [1:58:41<05:24,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:09<02:16,  2.26it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6795/7094 [1:58:45<05:13,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:14<02:11,  2.27it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6805/7094 [1:58:50<05:02,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:18<02:07,  2.27it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6815/7094 [1:58:54<04:52,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  80%|████████  | 1140/1419 [08:22<02:02,  2.27it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6825/7094 [1:58:59<04:41,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  81%|████████  | 1150/1419 [08:27<01:58,  2.27it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 6835/7094 [1:59:03<04:30,  1.05s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:31<01:54,  2.27it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 6845/7094 [1:59:07<04:20,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:36<01:49,  2.27it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6855/7094 [1:59:12<04:09,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:40<01:44,  2.28it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6865/7094 [1:59:16<03:58,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:44<01:40,  2.27it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6875/7094 [1:59:21<03:48,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:49<01:36,  2.27it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6885/7094 [1:59:25<03:37,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:53<01:32,  2.26it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6895/7094 [1:59:29<03:26,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  86%|████████▌ | 1220/1419 [08:58<01:28,  2.26it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6905/7094 [1:59:34<03:16,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:02<01:23,  2.27it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6915/7094 [1:59:38<03:05,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:06<01:18,  2.27it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6925/7094 [1:59:43<02:55,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:11<01:14,  2.26it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6935/7094 [1:59:47<02:44,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:15<01:10,  2.26it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6945/7094 [1:59:52<02:34,  1.04s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:20<01:05,  2.26it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6955/7094 [1:59:56<02:23,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:24<01:01,  2.27it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6965/7094 [2:00:00<02:13,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:29<00:56,  2.27it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6975/7094 [2:00:05<02:02,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:33<00:52,  2.27it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6985/7094 [2:00:09<01:52,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:37<00:48,  2.26it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 6995/7094 [2:00:14<01:42,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:42<00:43,  2.27it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 7005/7094 [2:00:18<01:31,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:46<00:39,  2.27it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7015/7094 [2:00:22<01:21,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:51<00:34,  2.27it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7025/7094 [2:00:27<01:10,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  95%|█████████▌| 1350/1419 [09:55<00:30,  2.27it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7035/7094 [2:00:31<01:00,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  96%|█████████▌| 1360/1419 [09:59<00:25,  2.27it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7045/7094 [2:00:36<00:50,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:04<00:21,  2.28it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7055/7094 [2:00:40<00:40,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:08<00:17,  2.27it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 7065/7094 [2:00:44<00:29,  1.03s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:13<00:12,  2.27it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 7075/7094 [2:00:49<00:19,  1.02s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:17<00:08,  2.27it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 7085/7094 [2:00:53<00:09,  1.02s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.690, train_loss_epoch=3.160]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:21<00:03,  2.27it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:24<00:01,  2.27it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 7094/7094 [2:01:00<00:00,  1.02s/it, loss=2.75, v_num=260027, train_loss_step=3.300, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=3.160]\n",
      "Epoch 2:  80%|███████▉  | 5675/7094 [1:50:34<27:39,  1.17s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 5685/7094 [1:50:37<27:25,  1.17s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:14,  2.09it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 5695/7094 [1:50:41<27:11,  1.17s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:31,  2.21it/s]\u001b[A\n",
      "Epoch 2:  80%|████████  | 5705/7094 [1:50:46<26:58,  1.17s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:19,  2.24it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 5715/7094 [1:50:50<26:44,  1.16s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:10,  2.26it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 5725/7094 [1:50:55<26:31,  1.16s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:07,  2.25it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 5735/7094 [1:50:59<26:18,  1.16s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   4%|▍         | 60/1419 [00:26<10:00,  2.26it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 5745/7094 [1:51:04<26:04,  1.16s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:54,  2.27it/s]\u001b[A\n",
      "Epoch 2:  81%|████████  | 5755/7094 [1:51:08<25:51,  1.16s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:49,  2.27it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 5765/7094 [1:51:12<25:38,  1.16s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:44,  2.27it/s]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 5775/7094 [1:51:17<25:25,  1.16s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:40,  2.27it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 5785/7094 [1:51:21<25:11,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   8%|▊         | 110/1419 [00:48<09:36,  2.27it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 5795/7094 [1:51:26<24:58,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:32,  2.27it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 5805/7094 [1:51:30<24:45,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:27,  2.27it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 5815/7094 [1:51:34<24:32,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:23,  2.27it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 5825/7094 [1:51:39<24:19,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:19,  2.27it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 5835/7094 [1:51:43<24:06,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  11%|█▏        | 160/1419 [01:10<09:13,  2.27it/s]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 5845/7094 [1:51:48<23:53,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:09,  2.27it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 5855/7094 [1:51:52<23:40,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  13%|█▎        | 180/1419 [01:19<09:05,  2.27it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 5865/7094 [1:51:56<23:27,  1.15s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:01,  2.27it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 5875/7094 [1:52:01<23:14,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<08:58,  2.26it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 5885/7094 [1:52:05<23:01,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:56,  2.26it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 5895/7094 [1:52:10<22:48,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:50,  2.26it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 5905/7094 [1:52:14<22:36,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  16%|█▌        | 230/1419 [01:41<08:43,  2.27it/s]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 5915/7094 [1:52:18<22:23,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:39,  2.27it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 5925/7094 [1:52:23<22:10,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  18%|█▊        | 250/1419 [01:50<08:35,  2.27it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 5935/7094 [1:52:27<21:57,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:30,  2.27it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 5945/7094 [1:52:32<21:44,  1.14s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:26,  2.27it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 5955/7094 [1:52:36<21:32,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  20%|█▉        | 280/1419 [02:03<08:22,  2.27it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 5965/7094 [1:52:40<21:19,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:18,  2.26it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 5975/7094 [1:52:45<21:07,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  21%|██        | 300/1419 [02:12<08:13,  2.27it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 5985/7094 [1:52:49<20:54,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  22%|██▏       | 310/1419 [02:17<08:09,  2.26it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 5995/7094 [1:52:54<20:41,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  23%|██▎       | 320/1419 [02:21<08:04,  2.27it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 6005/7094 [1:52:58<20:29,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  23%|██▎       | 330/1419 [02:25<08:01,  2.26it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 6015/7094 [1:53:03<20:16,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:56,  2.26it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 6025/7094 [1:53:07<20:04,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  25%|██▍       | 350/1419 [02:34<07:51,  2.27it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 6035/7094 [1:53:11<19:51,  1.13s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:47,  2.27it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 6045/7094 [1:53:16<19:39,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  26%|██▌       | 370/1419 [02:43<07:42,  2.27it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 6055/7094 [1:53:20<19:26,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  27%|██▋       | 380/1419 [02:48<07:39,  2.26it/s]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 6065/7094 [1:53:25<19:14,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  27%|██▋       | 390/1419 [02:52<07:35,  2.26it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 6075/7094 [1:53:29<19:02,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  28%|██▊       | 400/1419 [02:56<07:30,  2.26it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 6085/7094 [1:53:33<18:49,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  29%|██▉       | 410/1419 [03:01<07:25,  2.27it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 6095/7094 [1:53:38<18:37,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  30%|██▉       | 420/1419 [03:05<07:20,  2.27it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 6105/7094 [1:53:42<18:25,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  30%|███       | 430/1419 [03:10<07:15,  2.27it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 6115/7094 [1:53:47<18:13,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  31%|███       | 440/1419 [03:14<07:11,  2.27it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 6125/7094 [1:53:51<18:00,  1.12s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  32%|███▏      | 450/1419 [03:18<07:08,  2.26it/s]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 6135/7094 [1:53:56<17:48,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  32%|███▏      | 460/1419 [03:23<07:03,  2.27it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 6145/7094 [1:54:00<17:36,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  33%|███▎      | 470/1419 [03:27<07:00,  2.26it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 6155/7094 [1:54:04<17:24,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  34%|███▍      | 480/1419 [03:32<06:55,  2.26it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 6165/7094 [1:54:09<17:12,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  35%|███▍      | 490/1419 [03:36<06:51,  2.26it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 6175/7094 [1:54:13<17:00,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  35%|███▌      | 500/1419 [03:41<06:46,  2.26it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 6185/7094 [1:54:18<16:47,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  36%|███▌      | 510/1419 [03:45<06:42,  2.26it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 6195/7094 [1:54:22<16:35,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  37%|███▋      | 520/1419 [03:49<06:37,  2.26it/s]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 6205/7094 [1:54:26<16:23,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  37%|███▋      | 530/1419 [03:54<06:32,  2.27it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 6215/7094 [1:54:31<16:11,  1.11s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  38%|███▊      | 540/1419 [03:58<06:28,  2.27it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 6225/7094 [1:54:35<15:59,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  39%|███▉      | 550/1419 [04:03<06:22,  2.27it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 6235/7094 [1:54:40<15:47,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  39%|███▉      | 560/1419 [04:07<06:18,  2.27it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 6245/7094 [1:54:44<15:35,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  40%|████      | 570/1419 [04:11<06:13,  2.27it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 6255/7094 [1:54:48<15:24,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  41%|████      | 580/1419 [04:16<06:08,  2.28it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 6265/7094 [1:54:53<15:12,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  42%|████▏     | 590/1419 [04:20<06:04,  2.28it/s]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 6275/7094 [1:54:57<15:00,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  42%|████▏     | 600/1419 [04:25<06:00,  2.27it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 6285/7094 [1:55:02<14:48,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  43%|████▎     | 610/1419 [04:29<05:57,  2.27it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 6295/7094 [1:55:06<14:36,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  44%|████▎     | 620/1419 [04:33<05:52,  2.26it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 6305/7094 [1:55:11<14:24,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  44%|████▍     | 630/1419 [04:38<05:47,  2.27it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 6315/7094 [1:55:15<14:13,  1.10s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  45%|████▌     | 640/1419 [04:42<05:43,  2.27it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 6325/7094 [1:55:19<14:01,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  46%|████▌     | 650/1419 [04:47<05:39,  2.27it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 6335/7094 [1:55:24<13:49,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  47%|████▋     | 660/1419 [04:51<05:35,  2.26it/s]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 6345/7094 [1:55:28<13:37,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  47%|████▋     | 670/1419 [04:55<05:30,  2.27it/s]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 6355/7094 [1:55:33<13:26,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  48%|████▊     | 680/1419 [05:00<05:26,  2.26it/s]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 6365/7094 [1:55:37<13:14,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  49%|████▊     | 690/1419 [05:04<05:22,  2.26it/s]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 6375/7094 [1:55:41<13:02,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  49%|████▉     | 700/1419 [05:09<05:17,  2.27it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 6385/7094 [1:55:46<12:51,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  50%|█████     | 710/1419 [05:13<05:12,  2.27it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 6395/7094 [1:55:50<12:39,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  51%|█████     | 720/1419 [05:18<05:09,  2.26it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 6405/7094 [1:55:55<12:28,  1.09s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:22<05:03,  2.27it/s]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 6415/7094 [1:55:59<12:16,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:26<04:58,  2.27it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 6425/7094 [1:56:03<12:05,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:31<04:55,  2.26it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 6435/7094 [1:56:08<11:53,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:35<04:50,  2.27it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 6445/7094 [1:56:12<11:42,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:40<04:46,  2.27it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 6455/7094 [1:56:17<11:30,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:44<04:41,  2.27it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 6465/7094 [1:56:21<11:19,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:48<04:37,  2.26it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 6475/7094 [1:56:26<11:07,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:53<04:32,  2.27it/s]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 6485/7094 [1:56:30<10:56,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:57<04:28,  2.27it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 6495/7094 [1:56:34<10:45,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:02<04:24,  2.27it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 6505/7094 [1:56:39<10:33,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:06<04:19,  2.27it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 6515/7094 [1:56:43<10:22,  1.08s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:10<04:15,  2.27it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 6525/7094 [1:56:48<10:11,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:15<04:10,  2.27it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 6535/7094 [1:56:52<09:59,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  61%|██████    | 860/1419 [06:19<04:06,  2.27it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 6545/7094 [1:56:56<09:48,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:24<04:01,  2.27it/s]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 6555/7094 [1:57:01<09:37,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:28<03:57,  2.27it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 6565/7094 [1:57:05<09:26,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:32<03:52,  2.27it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 6575/7094 [1:57:10<09:14,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:37<03:48,  2.27it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 6585/7094 [1:57:14<09:03,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:41<03:44,  2.27it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 6595/7094 [1:57:18<08:52,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:46<03:39,  2.27it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 6605/7094 [1:57:23<08:41,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:50<03:35,  2.27it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 6615/7094 [1:57:27<08:30,  1.07s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:54<03:30,  2.27it/s]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 6625/7094 [1:57:32<08:19,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  67%|██████▋   | 950/1419 [06:59<03:26,  2.27it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 6635/7094 [1:57:36<08:08,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:03<03:22,  2.26it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 6645/7094 [1:57:40<07:57,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:08<03:18,  2.27it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 6655/7094 [1:57:45<07:46,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:12<03:14,  2.26it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 6665/7094 [1:57:49<07:35,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:17<03:09,  2.26it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 6675/7094 [1:57:54<07:24,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  70%|███████   | 1000/1419 [07:21<03:04,  2.27it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 6685/7094 [1:57:58<07:13,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  71%|███████   | 1010/1419 [07:25<03:00,  2.27it/s]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 6695/7094 [1:58:02<07:02,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:30<02:55,  2.27it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 6705/7094 [1:58:07<06:51,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:34<02:52,  2.26it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 6715/7094 [1:58:11<06:40,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:39<02:47,  2.27it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 6725/7094 [1:58:16<06:29,  1.06s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:43<02:43,  2.26it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 6735/7094 [1:58:20<06:18,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:47<02:38,  2.27it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 6745/7094 [1:58:25<06:07,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:52<02:34,  2.26it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 6755/7094 [1:58:29<05:56,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:56<02:29,  2.26it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 6765/7094 [1:58:33<05:45,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:01<02:25,  2.27it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 6775/7094 [1:58:38<05:35,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:05<02:20,  2.27it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 6785/7094 [1:58:42<05:24,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:10<02:16,  2.27it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 6795/7094 [1:58:47<05:13,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:14<02:11,  2.27it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 6805/7094 [1:58:51<05:02,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:18<02:07,  2.27it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 6815/7094 [1:58:55<04:52,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  80%|████████  | 1140/1419 [08:23<02:03,  2.27it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 6825/7094 [1:59:00<04:41,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  81%|████████  | 1150/1419 [08:27<01:58,  2.27it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 6835/7094 [1:59:04<04:30,  1.05s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:32<01:54,  2.26it/s]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 6845/7094 [1:59:09<04:20,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:36<01:49,  2.27it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 6855/7094 [1:59:13<04:09,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:40<01:45,  2.27it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 6865/7094 [1:59:18<03:58,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:45<01:40,  2.27it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 6875/7094 [1:59:22<03:48,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:49<01:36,  2.27it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 6885/7094 [1:59:26<03:37,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:54<01:32,  2.26it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 6895/7094 [1:59:31<03:26,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  86%|████████▌ | 1220/1419 [08:58<01:27,  2.27it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 6905/7094 [1:59:35<03:16,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:02<01:23,  2.26it/s]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 6915/7094 [1:59:40<03:05,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:07<01:18,  2.27it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 6925/7094 [1:59:44<02:55,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:11<01:14,  2.27it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 6935/7094 [1:59:48<02:44,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:16<01:10,  2.26it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 6945/7094 [1:59:53<02:34,  1.04s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:20<01:05,  2.27it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 6955/7094 [1:59:57<02:23,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:25<01:01,  2.27it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 6965/7094 [2:00:02<02:13,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:29<00:56,  2.27it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 6975/7094 [2:00:06<02:02,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:33<00:52,  2.27it/s]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 6985/7094 [2:00:10<01:52,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:38<00:48,  2.26it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 6995/7094 [2:00:15<01:42,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:42<00:43,  2.27it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 7005/7094 [2:00:19<01:31,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:47<00:39,  2.27it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 7015/7094 [2:00:24<01:21,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:51<00:34,  2.27it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 7025/7094 [2:00:28<01:10,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  95%|█████████▌| 1350/1419 [09:55<00:30,  2.27it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 7035/7094 [2:00:32<01:00,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  96%|█████████▌| 1360/1419 [10:00<00:25,  2.27it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 7045/7094 [2:00:37<00:50,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:04<00:21,  2.26it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 7055/7094 [2:00:41<00:40,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:09<00:17,  2.26it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 7065/7094 [2:00:46<00:29,  1.03s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:13<00:12,  2.26it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 7075/7094 [2:00:50<00:19,  1.02s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:17<00:08,  2.26it/s]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 7085/7094 [2:00:55<00:09,  1.02s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.910, val_loss_epoch=2.610, train_loss_epoch=2.800]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:22<00:03,  2.26it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:24<00:01,  2.26it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 7094/7094 [2:01:01<00:00,  1.02s/it, loss=2.61, v_num=260027, train_loss_step=2.990, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.800]\n",
      "Epoch 3:  80%|███████▉  | 5675/7094 [1:50:45<27:41,  1.17s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 5685/7094 [1:50:48<27:27,  1.17s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:14,  2.09it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 5695/7094 [1:50:52<27:14,  1.17s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:34,  2.20it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 5705/7094 [1:50:57<27:00,  1.17s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:20,  2.24it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5715/7094 [1:51:01<26:47,  1.17s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:10,  2.26it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5725/7094 [1:51:05<26:34,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:04,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5735/7094 [1:51:10<26:20,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   4%|▍         | 60/1419 [00:26<09:59,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5745/7094 [1:51:14<26:07,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:53,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5755/7094 [1:51:19<25:54,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:49,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 5765/7094 [1:51:23<25:40,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:44,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 5775/7094 [1:51:27<25:27,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:41,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5785/7094 [1:51:32<25:14,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   8%|▊         | 110/1419 [00:48<09:36,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5795/7094 [1:51:36<25:01,  1.16s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:35,  2.26it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5805/7094 [1:51:41<24:48,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:30,  2.26it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5815/7094 [1:51:45<24:34,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:25,  2.26it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5825/7094 [1:51:50<24:21,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:20,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5835/7094 [1:51:54<24:08,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  11%|█▏        | 160/1419 [01:10<09:14,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5845/7094 [1:51:58<23:55,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:11,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5855/7094 [1:52:03<23:42,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  13%|█▎        | 180/1419 [01:19<09:06,  2.27it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5865/7094 [1:52:07<23:29,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:03,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5875/7094 [1:52:12<23:16,  1.15s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<08:58,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5885/7094 [1:52:16<23:03,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:54,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5895/7094 [1:52:20<22:51,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:49,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5905/7094 [1:52:25<22:38,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  16%|█▌        | 230/1419 [01:41<08:44,  2.27it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5915/7094 [1:52:29<22:25,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:40,  2.27it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 5925/7094 [1:52:34<22:12,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  18%|█▊        | 250/1419 [01:50<08:35,  2.27it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 5935/7094 [1:52:38<21:59,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:33,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5945/7094 [1:52:43<21:47,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:28,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5955/7094 [1:52:47<21:34,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  20%|█▉        | 280/1419 [02:04<08:23,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5965/7094 [1:52:51<21:21,  1.14s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:18,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5975/7094 [1:52:56<21:09,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  21%|██        | 300/1419 [02:12<08:14,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5985/7094 [1:53:00<20:56,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  22%|██▏       | 310/1419 [02:17<08:10,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 5995/7094 [1:53:05<20:43,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  23%|██▎       | 320/1419 [02:21<08:06,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 6005/7094 [1:53:09<20:31,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  23%|██▎       | 330/1419 [02:26<08:01,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 6015/7094 [1:53:13<20:18,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:55,  2.27it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 6025/7094 [1:53:18<20:06,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  25%|██▍       | 350/1419 [02:34<07:52,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6035/7094 [1:53:22<19:53,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:47,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6045/7094 [1:53:27<19:41,  1.13s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  26%|██▌       | 370/1419 [02:43<07:43,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6055/7094 [1:53:31<19:28,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  27%|██▋       | 380/1419 [02:48<07:38,  2.27it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6065/7094 [1:53:36<19:16,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  27%|██▋       | 390/1419 [02:52<07:33,  2.27it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6075/7094 [1:53:40<19:04,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  28%|██▊       | 400/1419 [02:57<07:30,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6085/7094 [1:53:44<18:51,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  29%|██▉       | 410/1419 [03:01<07:26,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6095/7094 [1:53:49<18:39,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  30%|██▉       | 420/1419 [03:05<07:21,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6105/7094 [1:53:53<18:27,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  30%|███       | 430/1419 [03:10<07:16,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6115/7094 [1:53:58<18:14,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  31%|███       | 440/1419 [03:14<07:12,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 6125/7094 [1:54:02<18:02,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  32%|███▏      | 450/1419 [03:19<07:07,  2.27it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 6135/7094 [1:54:07<17:50,  1.12s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  32%|███▏      | 460/1419 [03:23<07:03,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6145/7094 [1:54:11<17:38,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  33%|███▎      | 470/1419 [03:27<06:59,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6155/7094 [1:54:15<17:25,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  34%|███▍      | 480/1419 [03:32<06:54,  2.27it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6165/7094 [1:54:20<17:13,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  35%|███▍      | 490/1419 [03:36<06:50,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6175/7094 [1:54:24<17:01,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  35%|███▌      | 500/1419 [03:41<06:45,  2.27it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6185/7094 [1:54:29<16:49,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  36%|███▌      | 510/1419 [03:45<06:41,  2.27it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6195/7094 [1:54:33<16:37,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  37%|███▋      | 520/1419 [03:50<06:38,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6205/7094 [1:54:37<16:25,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  37%|███▋      | 530/1419 [03:54<06:32,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6215/7094 [1:54:42<16:13,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  38%|███▊      | 540/1419 [03:58<06:28,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6225/7094 [1:54:46<16:01,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  39%|███▉      | 550/1419 [04:03<06:24,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6235/7094 [1:54:51<15:49,  1.11s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  39%|███▉      | 560/1419 [04:07<06:19,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6245/7094 [1:54:55<15:37,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  40%|████      | 570/1419 [04:12<06:15,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6255/7094 [1:55:00<15:25,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  41%|████      | 580/1419 [04:16<06:10,  2.27it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6265/7094 [1:55:04<15:13,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  42%|████▏     | 590/1419 [04:21<06:06,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6275/7094 [1:55:08<15:01,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  42%|████▏     | 600/1419 [04:25<06:01,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 6285/7094 [1:55:13<14:49,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  43%|████▎     | 610/1419 [04:29<05:57,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 6295/7094 [1:55:17<14:38,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  44%|████▎     | 620/1419 [04:34<05:53,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6305/7094 [1:55:22<14:26,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  44%|████▍     | 630/1419 [04:38<05:48,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6315/7094 [1:55:26<14:14,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  45%|████▌     | 640/1419 [04:43<05:44,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6325/7094 [1:55:31<14:02,  1.10s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  46%|████▌     | 650/1419 [04:47<05:39,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6335/7094 [1:55:35<13:50,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  47%|████▋     | 660/1419 [04:51<05:36,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6345/7094 [1:55:39<13:39,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  47%|████▋     | 670/1419 [04:56<05:31,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 6355/7094 [1:55:44<13:27,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  48%|████▊     | 680/1419 [05:00<05:26,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 6365/7094 [1:55:48<13:15,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  49%|████▊     | 690/1419 [05:05<05:22,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 6375/7094 [1:55:53<13:04,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  49%|████▉     | 700/1419 [05:09<05:18,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6385/7094 [1:55:57<12:52,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  50%|█████     | 710/1419 [05:14<05:13,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6395/7094 [1:56:01<12:40,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  51%|█████     | 720/1419 [05:18<05:08,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6405/7094 [1:56:06<12:29,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:22<05:04,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6415/7094 [1:56:10<12:17,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:27<04:59,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6425/7094 [1:56:15<12:06,  1.09s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:31<04:56,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6435/7094 [1:56:19<11:54,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:36<04:51,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6445/7094 [1:56:24<11:43,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:40<04:46,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6455/7094 [1:56:28<11:31,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:45<04:42,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6465/7094 [1:56:32<11:20,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:49<04:37,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 6475/7094 [1:56:37<11:08,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:53<04:33,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 6485/7094 [1:56:41<10:57,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:58<04:28,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6495/7094 [1:56:46<10:46,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:02<04:23,  2.27it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6505/7094 [1:56:50<10:34,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:07<04:20,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6515/7094 [1:56:54<10:23,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:11<04:15,  2.27it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6525/7094 [1:56:59<10:12,  1.08s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:15<04:12,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6535/7094 [1:57:03<10:00,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  61%|██████    | 860/1419 [06:20<04:07,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6545/7094 [1:57:08<09:49,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:24<04:02,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6555/7094 [1:57:12<09:38,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:29<03:58,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6565/7094 [1:57:17<09:27,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:33<03:53,  2.27it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6575/7094 [1:57:21<09:15,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:38<03:49,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6585/7094 [1:57:25<09:04,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:42<03:44,  2.27it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6595/7094 [1:57:30<08:53,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:46<03:40,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6605/7094 [1:57:34<08:42,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:51<03:35,  2.27it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6615/7094 [1:57:39<08:31,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:55<03:32,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6625/7094 [1:57:43<08:20,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  67%|██████▋   | 950/1419 [07:00<03:27,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 6635/7094 [1:57:48<08:08,  1.07s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:04<03:22,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 6645/7094 [1:57:52<07:57,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:09<03:18,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6655/7094 [1:57:56<07:46,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:13<03:13,  2.27it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6665/7094 [1:58:01<07:35,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:17<03:09,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6675/7094 [1:58:05<07:24,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  70%|███████   | 1000/1419 [07:22<03:04,  2.27it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6685/7094 [1:58:10<07:13,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  71%|███████   | 1010/1419 [07:26<03:00,  2.27it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6695/7094 [1:58:14<07:02,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:31<02:56,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6705/7094 [1:58:18<06:51,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:35<02:51,  2.27it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6715/7094 [1:58:23<06:40,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:39<02:47,  2.27it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6725/7094 [1:58:27<06:30,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:44<02:42,  2.27it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6735/7094 [1:58:32<06:19,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:48<02:38,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 6745/7094 [1:58:36<06:08,  1.06s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:53<02:34,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 6755/7094 [1:58:41<05:57,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:57<02:29,  2.27it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 6765/7094 [1:58:45<05:46,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:01<02:25,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6775/7094 [1:58:49<05:35,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:06<02:20,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6785/7094 [1:58:54<05:24,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:10<02:16,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6795/7094 [1:58:58<05:14,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:15<02:11,  2.27it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6805/7094 [1:59:03<05:03,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:19<02:07,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6815/7094 [1:59:07<04:52,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  80%|████████  | 1140/1419 [08:24<02:03,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6825/7094 [1:59:11<04:41,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  81%|████████  | 1150/1419 [08:28<01:58,  2.27it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 6835/7094 [1:59:16<04:31,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:32<01:54,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 6845/7094 [1:59:20<04:20,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:37<01:50,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6855/7094 [1:59:25<04:09,  1.05s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:41<01:45,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6865/7094 [1:59:29<03:59,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:46<01:41,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6875/7094 [1:59:34<03:48,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:50<01:36,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6885/7094 [1:59:38<03:37,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:55<01:32,  2.27it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6895/7094 [1:59:42<03:27,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  86%|████████▌ | 1220/1419 [08:59<01:27,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6905/7094 [1:59:47<03:16,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:03<01:23,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6915/7094 [1:59:51<03:06,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:08<01:19,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6925/7094 [1:59:56<02:55,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:12<01:14,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6935/7094 [2:00:00<02:45,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:17<01:10,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6945/7094 [2:00:04<02:34,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:21<01:05,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6955/7094 [2:00:09<02:24,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:25<01:01,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6965/7094 [2:00:13<02:13,  1.04s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:30<00:57,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6975/7094 [2:00:18<02:03,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:34<00:52,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6985/7094 [2:00:22<01:52,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:39<00:48,  2.27it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 6995/7094 [2:00:27<01:42,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:43<00:43,  2.26it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 7005/7094 [2:00:31<01:31,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:48<00:39,  2.27it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 7015/7094 [2:00:35<01:21,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:52<00:34,  2.27it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 7025/7094 [2:00:40<01:11,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  95%|█████████▌| 1350/1419 [09:56<00:30,  2.27it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 7035/7094 [2:00:44<01:00,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  96%|█████████▌| 1360/1419 [10:01<00:26,  2.27it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 7045/7094 [2:00:49<00:50,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:05<00:21,  2.26it/s]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 7055/7094 [2:00:53<00:40,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:10<00:17,  2.27it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 7065/7094 [2:00:57<00:29,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:14<00:12,  2.26it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 7075/7094 [2:01:02<00:19,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:18<00:08,  2.26it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 7085/7094 [2:01:06<00:09,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.590, train_loss_epoch=2.640]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:23<00:03,  2.26it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:25<00:01,  2.26it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 7094/7094 [2:01:13<00:00,  1.03s/it, loss=2.5, v_num=260027, train_loss_step=2.920, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.640]\n",
      "Epoch 4:  37%|███▋      | 2600/7094 [50:50<1:27:52,  1.17s/it, loss=2.32, v_num=260027, train_loss_step=2.040, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:  80%|███████▉  | 5675/7094 [1:51:02<27:45,  1.17s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 5685/7094 [1:51:05<27:31,  1.17s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:10,  2.10it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 5695/7094 [1:51:09<27:18,  1.17s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:33,  2.21it/s]\u001b[A\n",
      "Epoch 4:  80%|████████  | 5705/7094 [1:51:14<27:04,  1.17s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:19,  2.24it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 5715/7094 [1:51:18<26:51,  1.17s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:12,  2.25it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 5725/7094 [1:51:22<26:38,  1.17s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:04,  2.26it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 5735/7094 [1:51:27<26:24,  1.17s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   4%|▍         | 60/1419 [00:26<10:00,  2.26it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 5745/7094 [1:51:31<26:11,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:56,  2.26it/s]\u001b[A\n",
      "Epoch 4:  81%|████████  | 5755/7094 [1:51:36<25:57,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:51,  2.26it/s]\u001b[A\n",
      "Epoch 4:  81%|████████▏ | 5765/7094 [1:51:40<25:44,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:47,  2.26it/s]\u001b[A\n",
      "Epoch 4:  81%|████████▏ | 5775/7094 [1:51:44<25:31,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:42,  2.27it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 5785/7094 [1:51:49<25:18,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   8%|▊         | 110/1419 [00:48<09:37,  2.27it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 5795/7094 [1:51:53<25:04,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:33,  2.27it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 5805/7094 [1:51:58<24:51,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:28,  2.27it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 5815/7094 [1:52:02<24:38,  1.16s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:25,  2.26it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 5825/7094 [1:52:07<24:25,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:22,  2.26it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 5835/7094 [1:52:11<24:12,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  11%|█▏        | 160/1419 [01:11<09:15,  2.27it/s]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 5845/7094 [1:52:15<23:59,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:12,  2.26it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 5855/7094 [1:52:20<23:46,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  13%|█▎        | 180/1419 [01:19<09:07,  2.26it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 5865/7094 [1:52:24<23:33,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:03,  2.26it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 5875/7094 [1:52:29<23:20,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<08:59,  2.26it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 5885/7094 [1:52:33<23:07,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:55,  2.26it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 5895/7094 [1:52:38<22:54,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:50,  2.26it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 5905/7094 [1:52:42<22:41,  1.15s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  16%|█▌        | 230/1419 [01:42<08:45,  2.26it/s]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 5915/7094 [1:52:46<22:28,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:42,  2.26it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▎ | 5925/7094 [1:52:51<22:15,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  18%|█▊        | 250/1419 [01:50<08:36,  2.26it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▎ | 5935/7094 [1:52:55<22:03,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:33,  2.26it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 5945/7094 [1:53:00<21:50,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:28,  2.26it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 5955/7094 [1:53:04<21:37,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  20%|█▉        | 280/1419 [02:04<08:22,  2.27it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 5965/7094 [1:53:08<21:24,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:18,  2.26it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 5975/7094 [1:53:13<21:12,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  21%|██        | 300/1419 [02:12<08:13,  2.27it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 5985/7094 [1:53:17<20:59,  1.14s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  22%|██▏       | 310/1419 [02:17<08:10,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▍ | 5995/7094 [1:53:22<20:46,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  23%|██▎       | 320/1419 [02:21<08:05,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▍ | 6005/7094 [1:53:26<20:34,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  23%|██▎       | 330/1419 [02:26<08:01,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▍ | 6015/7094 [1:53:31<20:21,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:56,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▍ | 6025/7094 [1:53:35<20:09,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  25%|██▍       | 350/1419 [02:35<07:51,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 6035/7094 [1:53:39<19:56,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:48,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 6045/7094 [1:53:44<19:44,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  26%|██▌       | 370/1419 [02:43<07:43,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 6055/7094 [1:53:48<19:31,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  27%|██▋       | 380/1419 [02:48<07:38,  2.26it/s]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 6065/7094 [1:53:53<19:19,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  27%|██▋       | 390/1419 [02:52<07:34,  2.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 6075/7094 [1:53:57<19:06,  1.13s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  28%|██▊       | 400/1419 [02:57<07:30,  2.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 6085/7094 [1:54:02<18:54,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  29%|██▉       | 410/1419 [03:01<07:25,  2.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 6095/7094 [1:54:06<18:42,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  30%|██▉       | 420/1419 [03:06<07:21,  2.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 6105/7094 [1:54:10<18:29,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  30%|███       | 430/1419 [03:10<07:18,  2.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 6115/7094 [1:54:15<18:17,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  31%|███       | 440/1419 [03:14<07:12,  2.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 6125/7094 [1:54:19<18:05,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  32%|███▏      | 450/1419 [03:19<07:09,  2.26it/s]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 6135/7094 [1:54:24<17:52,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  32%|███▏      | 460/1419 [03:23<07:04,  2.26it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 6145/7094 [1:54:28<17:40,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  33%|███▎      | 470/1419 [03:28<06:59,  2.26it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 6155/7094 [1:54:32<17:28,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  34%|███▍      | 480/1419 [03:32<06:54,  2.27it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 6165/7094 [1:54:37<17:16,  1.12s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  35%|███▍      | 490/1419 [03:37<06:50,  2.26it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 6175/7094 [1:54:41<17:04,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  35%|███▌      | 500/1419 [03:41<06:46,  2.26it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 6185/7094 [1:54:46<16:52,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  36%|███▌      | 510/1419 [03:45<06:42,  2.26it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 6195/7094 [1:54:50<16:39,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  37%|███▋      | 520/1419 [03:50<06:38,  2.26it/s]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 6205/7094 [1:54:55<16:27,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  37%|███▋      | 530/1419 [03:54<06:32,  2.26it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 6215/7094 [1:54:59<16:15,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  38%|███▊      | 540/1419 [03:59<06:28,  2.26it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 6225/7094 [1:55:03<16:03,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  39%|███▉      | 550/1419 [04:03<06:24,  2.26it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 6235/7094 [1:55:08<15:51,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  39%|███▉      | 560/1419 [04:07<06:19,  2.26it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 6245/7094 [1:55:12<15:39,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  40%|████      | 570/1419 [04:12<06:14,  2.26it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 6255/7094 [1:55:17<15:27,  1.11s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  41%|████      | 580/1419 [04:16<06:11,  2.26it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 6265/7094 [1:55:21<15:15,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  42%|████▏     | 590/1419 [04:21<06:06,  2.26it/s]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 6275/7094 [1:55:26<15:03,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  42%|████▏     | 600/1419 [04:25<06:01,  2.26it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 6285/7094 [1:55:30<14:52,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  43%|████▎     | 610/1419 [04:30<05:58,  2.26it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 6295/7094 [1:55:34<14:40,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  44%|████▎     | 620/1419 [04:34<05:53,  2.26it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 6305/7094 [1:55:39<14:28,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  44%|████▍     | 630/1419 [04:38<05:48,  2.26it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 6315/7094 [1:55:43<14:16,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  45%|████▌     | 640/1419 [04:43<05:45,  2.25it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 6325/7094 [1:55:48<14:04,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  46%|████▌     | 650/1419 [04:47<05:39,  2.26it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 6335/7094 [1:55:52<13:52,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  47%|████▋     | 660/1419 [04:52<05:35,  2.26it/s]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 6345/7094 [1:55:56<13:41,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  47%|████▋     | 670/1419 [04:56<05:31,  2.26it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 6355/7094 [1:56:01<13:29,  1.10s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  48%|████▊     | 680/1419 [05:01<05:26,  2.27it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 6365/7094 [1:56:05<13:17,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  49%|████▊     | 690/1419 [05:05<05:22,  2.26it/s]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 6375/7094 [1:56:10<13:06,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  49%|████▉     | 700/1419 [05:09<05:17,  2.26it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 6385/7094 [1:56:14<12:54,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  50%|█████     | 710/1419 [05:14<05:13,  2.26it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 6395/7094 [1:56:19<12:42,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  51%|█████     | 720/1419 [05:18<05:08,  2.27it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 6405/7094 [1:56:23<12:31,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:23<05:05,  2.26it/s]\u001b[A\n",
      "Epoch 4:  90%|█████████ | 6415/7094 [1:56:27<12:19,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:27<05:00,  2.26it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 6425/7094 [1:56:32<12:08,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:31<04:56,  2.26it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 6435/7094 [1:56:36<11:56,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:36<04:51,  2.26it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 6445/7094 [1:56:41<11:45,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:40<04:46,  2.26it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 6455/7094 [1:56:45<11:33,  1.09s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:45<04:43,  2.26it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 6465/7094 [1:56:50<11:22,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:49<04:38,  2.26it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████▏| 6475/7094 [1:56:54<11:10,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:54<04:35,  2.25it/s]\u001b[A\n",
      "Epoch 4:  91%|█████████▏| 6485/7094 [1:56:58<10:59,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:58<04:29,  2.26it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 6495/7094 [1:57:03<10:47,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:02<04:24,  2.27it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 6505/7094 [1:57:07<10:36,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:07<04:20,  2.26it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 6515/7094 [1:57:12<10:24,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:11<04:15,  2.27it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 6525/7094 [1:57:16<10:13,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:16<04:11,  2.27it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 6535/7094 [1:57:20<10:02,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  61%|██████    | 860/1419 [06:20<04:06,  2.26it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 6545/7094 [1:57:25<09:50,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:25<04:02,  2.26it/s]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 6555/7094 [1:57:29<09:39,  1.08s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:29<03:58,  2.26it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 6565/7094 [1:57:34<09:28,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:33<03:54,  2.26it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 6575/7094 [1:57:38<09:17,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:38<03:49,  2.26it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 6585/7094 [1:57:43<09:05,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:42<03:45,  2.26it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 6595/7094 [1:57:47<08:54,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:47<03:40,  2.26it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 6605/7094 [1:57:51<08:43,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:51<03:36,  2.26it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 6615/7094 [1:57:56<08:32,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:55<03:31,  2.26it/s]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 6625/7094 [1:58:00<08:21,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  67%|██████▋   | 950/1419 [07:00<03:27,  2.26it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▎| 6635/7094 [1:58:05<08:10,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:04<03:22,  2.26it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▎| 6645/7094 [1:58:09<07:59,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:09<03:18,  2.26it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 6655/7094 [1:58:14<07:47,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:13<03:13,  2.26it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 6665/7094 [1:58:18<07:36,  1.07s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:18<03:09,  2.26it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 6675/7094 [1:58:22<07:25,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  70%|███████   | 1000/1419 [07:22<03:04,  2.27it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 6685/7094 [1:58:27<07:14,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  71%|███████   | 1010/1419 [07:26<03:00,  2.26it/s]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 6695/7094 [1:58:31<07:03,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:31<02:56,  2.26it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 6705/7094 [1:58:36<06:52,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:35<02:51,  2.27it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 6715/7094 [1:58:40<06:41,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:40<02:47,  2.26it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 6725/7094 [1:58:44<06:30,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:44<02:43,  2.26it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 6735/7094 [1:58:49<06:20,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:49<02:38,  2.26it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 6745/7094 [1:58:53<06:09,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:53<02:34,  2.26it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 6755/7094 [1:58:58<05:58,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:57<02:29,  2.27it/s]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 6765/7094 [1:59:02<05:47,  1.06s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:02<02:26,  2.25it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 6775/7094 [1:59:07<05:36,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:06<02:21,  2.26it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 6785/7094 [1:59:11<05:25,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:11<02:17,  2.26it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 6795/7094 [1:59:15<05:14,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:15<02:12,  2.26it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 6805/7094 [1:59:20<05:04,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:20<02:07,  2.26it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 6815/7094 [1:59:24<04:53,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  80%|████████  | 1140/1419 [08:24<02:03,  2.26it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 6825/7094 [1:59:29<04:42,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  81%|████████  | 1150/1419 [08:28<01:58,  2.26it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▋| 6835/7094 [1:59:33<04:31,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:33<01:54,  2.27it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▋| 6845/7094 [1:59:38<04:21,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:37<01:50,  2.26it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 6855/7094 [1:59:42<04:10,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:42<01:45,  2.26it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 6865/7094 [1:59:46<03:59,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:46<01:41,  2.27it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 6875/7094 [1:59:51<03:49,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:50<01:36,  2.26it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 6885/7094 [1:59:55<03:38,  1.05s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:55<01:32,  2.26it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 6895/7094 [2:00:00<03:27,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  86%|████████▌ | 1220/1419 [08:59<01:27,  2.26it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 6905/7094 [2:00:04<03:17,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:04<01:23,  2.26it/s]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 6915/7094 [2:00:08<03:06,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:08<01:19,  2.26it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 6925/7094 [2:00:13<02:56,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:13<01:14,  2.26it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 6935/7094 [2:00:17<02:45,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:17<01:10,  2.26it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 6945/7094 [2:00:22<02:34,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:21<01:06,  2.25it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 6955/7094 [2:00:26<02:24,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:26<01:01,  2.26it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 6965/7094 [2:00:31<02:13,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:30<00:57,  2.26it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 6975/7094 [2:00:35<02:03,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:35<00:52,  2.26it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 6985/7094 [2:00:39<01:52,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:39<00:48,  2.26it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 6995/7094 [2:00:44<01:42,  1.04s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:44<00:43,  2.26it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 7005/7094 [2:00:48<01:32,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:48<00:39,  2.26it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 7015/7094 [2:00:53<01:21,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:52<00:34,  2.26it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 7025/7094 [2:00:57<01:11,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  95%|█████████▌| 1350/1419 [09:57<00:30,  2.26it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 7035/7094 [2:01:02<01:00,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  96%|█████████▌| 1360/1419 [10:01<00:26,  2.26it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 7045/7094 [2:01:06<00:50,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:06<00:21,  2.26it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 7055/7094 [2:01:10<00:40,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:10<00:17,  2.27it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 7065/7094 [2:01:15<00:29,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:14<00:12,  2.27it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 7075/7094 [2:01:19<00:19,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:19<00:08,  2.27it/s]\u001b[A\n",
      "Epoch 4: 100%|█████████▉| 7085/7094 [2:01:24<00:09,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.860, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:23<00:03,  2.26it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:25<00:01,  2.26it/s]\u001b[A\n",
      "Epoch 4: 100%|██████████| 7094/7094 [2:01:30<00:00,  1.03s/it, loss=2.34, v_num=260027, train_loss_step=2.480, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.500]\n",
      "Epoch 5:  80%|███████▉  | 5675/7094 [1:51:06<27:46,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 5685/7094 [1:51:08<27:32,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:22,  2.06it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 5695/7094 [1:51:13<27:19,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:36,  2.20it/s]\u001b[A\n",
      "Epoch 5:  80%|████████  | 5705/7094 [1:51:17<27:05,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:20,  2.24it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 5715/7094 [1:51:22<26:52,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:15,  2.24it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 5725/7094 [1:51:26<26:38,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:08,  2.25it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 5735/7094 [1:51:30<26:25,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   4%|▍         | 60/1419 [00:27<10:01,  2.26it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 5745/7094 [1:51:35<26:12,  1.17s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:56,  2.26it/s]\u001b[A\n",
      "Epoch 5:  81%|████████  | 5755/7094 [1:51:39<25:58,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:51,  2.27it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 5765/7094 [1:51:44<25:45,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:45,  2.27it/s]\u001b[A\n",
      "Epoch 5:  81%|████████▏ | 5775/7094 [1:51:48<25:32,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:42,  2.27it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 5785/7094 [1:51:53<25:18,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   8%|▊         | 110/1419 [00:49<09:38,  2.26it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 5795/7094 [1:51:57<25:05,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:33,  2.26it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 5805/7094 [1:52:01<24:52,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:29,  2.26it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 5815/7094 [1:52:06<24:39,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:25,  2.26it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 5825/7094 [1:52:10<24:26,  1.16s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:21,  2.26it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 5835/7094 [1:52:15<24:13,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  11%|█▏        | 160/1419 [01:11<09:16,  2.26it/s]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 5845/7094 [1:52:19<24:00,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:11,  2.26it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 5855/7094 [1:52:24<23:47,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  13%|█▎        | 180/1419 [01:20<09:08,  2.26it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 5865/7094 [1:52:28<23:34,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:02,  2.26it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 5875/7094 [1:52:32<23:21,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<08:58,  2.26it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 5885/7094 [1:52:37<23:08,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:54,  2.26it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 5895/7094 [1:52:41<22:55,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:49,  2.26it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 5905/7094 [1:52:46<22:42,  1.15s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  16%|█▌        | 230/1419 [01:42<08:44,  2.27it/s]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 5915/7094 [1:52:50<22:29,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:41,  2.26it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▎ | 5925/7094 [1:52:54<22:16,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  18%|█▊        | 250/1419 [01:51<08:38,  2.26it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▎ | 5935/7094 [1:52:59<22:03,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:32,  2.26it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 5945/7094 [1:53:03<21:51,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:27,  2.26it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 5955/7094 [1:53:08<21:38,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  20%|█▉        | 280/1419 [02:04<08:22,  2.27it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 5965/7094 [1:53:12<21:25,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:18,  2.27it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 5975/7094 [1:53:17<21:12,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  21%|██        | 300/1419 [02:13<08:15,  2.26it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 5985/7094 [1:53:21<21:00,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  22%|██▏       | 310/1419 [02:17<08:10,  2.26it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 5995/7094 [1:53:25<20:47,  1.14s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  23%|██▎       | 320/1419 [02:21<08:05,  2.26it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 6005/7094 [1:53:30<20:35,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  23%|██▎       | 330/1419 [02:26<08:00,  2.26it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 6015/7094 [1:53:34<20:22,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:56,  2.26it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▍ | 6025/7094 [1:53:39<20:09,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  25%|██▍       | 350/1419 [02:35<07:51,  2.27it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 6035/7094 [1:53:43<19:57,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:47,  2.27it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 6045/7094 [1:53:47<19:44,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  26%|██▌       | 370/1419 [02:43<07:43,  2.26it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 6055/7094 [1:53:52<19:32,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  27%|██▋       | 380/1419 [02:48<07:38,  2.26it/s]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 6065/7094 [1:53:56<19:19,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  27%|██▋       | 390/1419 [02:52<07:35,  2.26it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 6075/7094 [1:54:01<19:07,  1.13s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  28%|██▊       | 400/1419 [02:57<07:30,  2.26it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 6085/7094 [1:54:05<18:55,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  29%|██▉       | 410/1419 [03:01<07:26,  2.26it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 6095/7094 [1:54:10<18:42,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  30%|██▉       | 420/1419 [03:06<07:21,  2.26it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 6105/7094 [1:54:14<18:30,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  30%|███       | 430/1419 [03:10<07:16,  2.26it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 6115/7094 [1:54:18<18:18,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  31%|███       | 440/1419 [03:14<07:12,  2.26it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 6125/7094 [1:54:23<18:05,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  32%|███▏      | 450/1419 [03:19<07:08,  2.26it/s]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 6135/7094 [1:54:27<17:53,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  32%|███▏      | 460/1419 [03:23<07:05,  2.25it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 6145/7094 [1:54:32<17:41,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  33%|███▎      | 470/1419 [03:28<07:00,  2.26it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 6155/7094 [1:54:36<17:29,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  34%|███▍      | 480/1419 [03:32<06:56,  2.26it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 6165/7094 [1:54:41<17:16,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  35%|███▍      | 490/1419 [03:37<06:50,  2.26it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 6175/7094 [1:54:45<17:04,  1.12s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  35%|███▌      | 500/1419 [03:41<06:46,  2.26it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 6185/7094 [1:54:49<16:52,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  36%|███▌      | 510/1419 [03:45<06:41,  2.26it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 6195/7094 [1:54:54<16:40,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  37%|███▋      | 520/1419 [03:50<06:37,  2.26it/s]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 6205/7094 [1:54:58<16:28,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  37%|███▋      | 530/1419 [03:54<06:33,  2.26it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 6215/7094 [1:55:03<16:16,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  38%|███▊      | 540/1419 [03:59<06:27,  2.27it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 6225/7094 [1:55:07<16:04,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  39%|███▉      | 550/1419 [04:03<06:24,  2.26it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 6235/7094 [1:55:11<15:52,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  39%|███▉      | 560/1419 [04:08<06:19,  2.27it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 6245/7094 [1:55:16<15:40,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  40%|████      | 570/1419 [04:12<06:14,  2.27it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 6255/7094 [1:55:20<15:28,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  41%|████      | 580/1419 [04:16<06:10,  2.26it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 6265/7094 [1:55:25<15:16,  1.11s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  42%|████▏     | 590/1419 [04:21<06:05,  2.27it/s]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 6275/7094 [1:55:29<15:04,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  42%|████▏     | 600/1419 [04:25<06:01,  2.27it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 6285/7094 [1:55:34<14:52,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  43%|████▎     | 610/1419 [04:30<05:57,  2.26it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 6295/7094 [1:55:38<14:40,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  44%|████▎     | 620/1419 [04:34<05:53,  2.26it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 6305/7094 [1:55:42<14:28,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  44%|████▍     | 630/1419 [04:38<05:48,  2.26it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 6315/7094 [1:55:47<14:16,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  45%|████▌     | 640/1419 [04:43<05:44,  2.26it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 6325/7094 [1:55:51<14:05,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  46%|████▌     | 650/1419 [04:47<05:41,  2.25it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 6335/7094 [1:55:56<13:53,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  47%|████▋     | 660/1419 [04:52<05:35,  2.26it/s]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 6345/7094 [1:56:00<13:41,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  47%|████▋     | 670/1419 [04:56<05:31,  2.26it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 6355/7094 [1:56:04<13:29,  1.10s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  48%|████▊     | 680/1419 [05:01<05:26,  2.27it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 6365/7094 [1:56:09<13:18,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  49%|████▊     | 690/1419 [05:05<05:22,  2.26it/s]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 6375/7094 [1:56:13<13:06,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  49%|████▉     | 700/1419 [05:09<05:17,  2.26it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 6385/7094 [1:56:18<12:54,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  50%|█████     | 710/1419 [05:14<05:13,  2.26it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 6395/7094 [1:56:22<12:43,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  51%|█████     | 720/1419 [05:18<05:09,  2.26it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 6405/7094 [1:56:27<12:31,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:23<05:04,  2.26it/s]\u001b[A\n",
      "Epoch 5:  90%|█████████ | 6415/7094 [1:56:31<12:20,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:27<05:00,  2.26it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 6425/7094 [1:56:35<12:08,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:32<04:57,  2.25it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 6435/7094 [1:56:40<11:56,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:36<04:51,  2.26it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 6445/7094 [1:56:44<11:45,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:40<04:47,  2.26it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 6455/7094 [1:56:49<11:33,  1.09s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:45<04:42,  2.26it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 6465/7094 [1:56:53<11:22,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:49<04:38,  2.26it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████▏| 6475/7094 [1:56:58<11:10,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:54<04:33,  2.26it/s]\u001b[A\n",
      "Epoch 5:  91%|█████████▏| 6485/7094 [1:57:02<10:59,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:58<04:29,  2.26it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 6495/7094 [1:57:06<10:48,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:02<04:24,  2.26it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 6505/7094 [1:57:11<10:36,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:07<04:20,  2.26it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 6515/7094 [1:57:15<10:25,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:11<04:15,  2.27it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 6525/7094 [1:57:20<10:13,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:16<04:10,  2.27it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 6535/7094 [1:57:24<10:02,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  61%|██████    | 860/1419 [06:20<04:06,  2.27it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 6545/7094 [1:57:28<09:51,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:25<04:02,  2.27it/s]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 6555/7094 [1:57:33<09:39,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:29<03:58,  2.26it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 6565/7094 [1:57:37<09:28,  1.08s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:33<03:53,  2.26it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 6575/7094 [1:57:42<09:17,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:38<03:49,  2.26it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 6585/7094 [1:57:46<09:06,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:42<03:44,  2.26it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 6595/7094 [1:57:51<08:55,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:47<03:40,  2.26it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 6605/7094 [1:57:55<08:43,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:51<03:36,  2.26it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 6615/7094 [1:57:59<08:32,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:55<03:31,  2.26it/s]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 6625/7094 [1:58:04<08:21,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  67%|██████▋   | 950/1419 [07:00<03:26,  2.27it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▎| 6635/7094 [1:58:08<08:10,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:04<03:22,  2.27it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▎| 6645/7094 [1:58:13<07:59,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:09<03:18,  2.26it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 6655/7094 [1:58:17<07:48,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:13<03:14,  2.26it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 6665/7094 [1:58:22<07:37,  1.07s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:18<03:09,  2.26it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 6675/7094 [1:58:26<07:26,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  70%|███████   | 1000/1419 [07:22<03:06,  2.25it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 6685/7094 [1:58:30<07:15,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  71%|███████   | 1010/1419 [07:26<03:01,  2.26it/s]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 6695/7094 [1:58:35<07:04,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:31<02:56,  2.27it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 6705/7094 [1:58:39<06:53,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:35<02:51,  2.26it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 6715/7094 [1:58:44<06:42,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:40<02:47,  2.26it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 6725/7094 [1:58:48<06:31,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:44<02:43,  2.25it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 6735/7094 [1:58:52<06:20,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:49<02:38,  2.26it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 6745/7094 [1:58:57<06:09,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:53<02:34,  2.26it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 6755/7094 [1:59:01<05:58,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:57<02:29,  2.27it/s]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 6765/7094 [1:59:06<05:47,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:02<02:25,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 6775/7094 [1:59:10<05:36,  1.06s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:06<02:20,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 6785/7094 [1:59:15<05:25,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:11<02:16,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 6795/7094 [1:59:19<05:15,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:15<02:12,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 6805/7094 [1:59:23<05:04,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:19<02:07,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 6815/7094 [1:59:28<04:53,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  80%|████████  | 1140/1419 [08:24<02:03,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 6825/7094 [1:59:32<04:42,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  81%|████████  | 1150/1419 [08:28<01:58,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▋| 6835/7094 [1:59:37<04:31,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:33<01:54,  2.26it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▋| 6845/7094 [1:59:41<04:21,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:37<01:49,  2.26it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 6855/7094 [1:59:46<04:10,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:42<01:45,  2.26it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 6865/7094 [1:59:50<03:59,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:46<01:41,  2.26it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 6875/7094 [1:59:54<03:49,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:50<01:36,  2.27it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 6885/7094 [1:59:59<03:38,  1.05s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:55<01:32,  2.26it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 6895/7094 [2:00:03<03:27,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  86%|████████▌ | 1220/1419 [08:59<01:27,  2.27it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 6905/7094 [2:00:08<03:17,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:04<01:23,  2.25it/s]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 6915/7094 [2:00:12<03:06,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:08<01:19,  2.26it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 6925/7094 [2:00:16<02:56,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:13<01:14,  2.26it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 6935/7094 [2:00:21<02:45,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:17<01:10,  2.26it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 6945/7094 [2:00:25<02:35,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:21<01:06,  2.25it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 6955/7094 [2:00:30<02:24,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:26<01:01,  2.26it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 6965/7094 [2:00:34<02:13,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:30<00:57,  2.26it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 6975/7094 [2:00:39<02:03,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:35<00:52,  2.26it/s]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 6985/7094 [2:00:43<01:53,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:39<00:48,  2.27it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 6995/7094 [2:00:47<01:42,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:44<00:43,  2.26it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 7005/7094 [2:00:52<01:32,  1.04s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:48<00:39,  2.26it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 7015/7094 [2:00:56<01:21,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:52<00:34,  2.26it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 7025/7094 [2:01:01<01:11,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  95%|█████████▌| 1350/1419 [09:57<00:30,  2.26it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 7035/7094 [2:01:05<01:00,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  96%|█████████▌| 1360/1419 [10:01<00:26,  2.26it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 7045/7094 [2:01:10<00:50,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:06<00:21,  2.26it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 7055/7094 [2:01:14<00:40,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:10<00:17,  2.27it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 7065/7094 [2:01:18<00:29,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:14<00:12,  2.26it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 7075/7094 [2:01:23<00:19,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:19<00:08,  2.26it/s]\u001b[A\n",
      "Epoch 5: 100%|█████████▉| 7085/7094 [2:01:27<00:09,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.870, val_loss_epoch=2.570, train_loss_epoch=2.380]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:23<00:03,  2.26it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:26<00:01,  2.26it/s]\u001b[A\n",
      "Epoch 5: 100%|██████████| 7094/7094 [2:01:34<00:00,  1.03s/it, loss=2.26, v_num=260027, train_loss_step=2.530, val_loss_step=2.900, val_loss_epoch=2.580, train_loss_epoch=2.380]\n",
      "Epoch 6:  21%|██        | 1460/7094 [28:36<1:50:25,  1.18s/it, loss=2.3, v_num=260027, train_loss_step=2.310, val_loss_step=2.900, val_loss_epoch=2.580, train_loss_epoch=2.280] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:  21%|██        | 1500/7094 [29:23<1:49:36,  1.18s/it, loss=2.09, v_num=260027, train_loss_step=2.710, val_loss_step=2.920, val_loss_epoch=2.620, train_loss_epoch=2.110]"
     ]
    }
   ],
   "source": [
    "# model.train(train_df=output_df,\n",
    "#             eval_df=output_df, \n",
    "#             source_max_token_len=2048, \n",
    "#             target_max_token_len=1024, \n",
    "#             batch_size=2, max_epochs=5, use_gpu=True)\n",
    "# Split the data into training and evaluation sets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simplet5 import SimpleT5\n",
    "# Initialize SimpleT5\n",
    "model = SimpleT5()\n",
    "model.from_pretrained(model_type=\"t5\", model_name=\"pszemraj/long-t5-tglobal-base-16384-book-summary\")\n",
    "\n",
    "train_df, eval_df = train_test_split(output_df, test_size=0.2)\n",
    "model.train(train_df=train_df,\n",
    "            eval_df=eval_df, \n",
    "            source_max_token_len=2048, \n",
    "            target_max_token_len=1024, \n",
    "            batch_size=2, \n",
    "            max_epochs=10, \n",
    "            use_gpu=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03c4ad0a-ff95-4fe0-b384-c304d26018bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        source_text  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e607171c-c4f9-47e6-8aa6-1cce1f533d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['In conclusion, this meta- analysis suggests that the use of SSCs may be associated with an increase in mean arterial pressure and a decrease in mean heart rate.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(output_df['source_text'][0])\n",
    "\n",
    "model.load_model(\"t5\",\"outputs/simplet5-epoch-9-train-loss-1.9464-val-loss-2.6663\", use_gpu=True)\n",
    "\n",
    "text_to_summarize=output_df['source_text'][0]\n",
    "model.predict(text_to_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47424548-dcb2-4ea7-abab-a30e07a8cd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14188, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0188b54f-dd71-4c50-aff8-a845d6e75a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>Study : Although transplantation of adult bone...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                        source_text  \\\n",
       "0  30760312  Study : Although transplantation of adult bone...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Conclusions SC therapy is effective for PAH in...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85b4bbf-311f-4115-9d94-d6c36d484c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF is set to: max_split_size_mb:256\n",
      "device: cuda\n",
      "['review_id', 'pmid', 'title', 'abstract', 'target', 'background']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Memory optimization for CUDA\n",
    "max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF is set to: {os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# when on Nvida machins \n",
    "device = torch.device(\"cuda\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# #when you are on mac\n",
    "# device = torch.device(\"cpu\")\n",
    "# print(\"device:\", device)\n",
    "\n",
    "\n",
    "# Load LongT5 Model and Tokenizer\n",
    "# model_to_use = \"google/long-t5-local-base\"\n",
    "model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "# Load validation dataset from Hugging Face datasets\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "\n",
    "\n",
    "# Prepare DataFrame for output\n",
    "# output_df = pd.DataFrame(columns=['ReviewID', 'Candidate_Summary', 'Target'])\n",
    "output_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71c6750-be25-41c2-a891-f0e4600d1c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "output_df.drop(['pmid', 'title','background'], axis = 1, inplace = True) \n",
    "output_df['abstract'] = output_df['abstract'].apply(lambda x: \"\".join([f\"Study : \" + b for i,b in enumerate(x)]) )\n",
    "output_df.rename(columns={\"target\":\"target_text\", \"abstract\":\"source_text\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c23355-aa9e-4af9-a662-564e75de1831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abeccdba-f338-4c74-a085-ad6a11bd2329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Study : ABSTRACT A healthy intestinal microbio...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                        source_text  \\\n",
       "0  28514886  Study : ABSTRACT A healthy intestinal microbio...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb51703-7cbe-48dc-b890-c9caa7c2e0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from simplet5 import SimpleT5\n",
    "\n",
    "# # Load your trained model\n",
    "# model = SimpleT5()\n",
    "# model.load_model(\"t5\", \"outputs/simplet5-epoch-9-train-loss-1.9464-val-loss-2.6663\", use_gpu=True)\n",
    "\n",
    "# # Assuming 'output_df' is already loaded and has columns 'review_id', 'source_text', and 'target_text'\n",
    "# batch_size = 1\n",
    "\n",
    "# # Initialize an empty DataFrame for the summaries\n",
    "# summary_df = pd.DataFrame()\n",
    "\n",
    "# # Process data in batches and generate summaries\n",
    "# for i in range(0, len(output_df), batch_size):\n",
    "#     batch_abstracts = output_df['source_text'][i: i + batch_size]\n",
    "#     batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "#     batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "#     # Generate summaries\n",
    "#     batch_summaries = [model.predict(abstract) for abstract in batch_abstracts]\n",
    "\n",
    "#     # Create a temporary DataFrame and append it to the summary DataFrame\n",
    "#     temp_df = pd.DataFrame({\n",
    "#         'ReviewID': batch_review_ids,\n",
    "#         'Candidate_Summary': batch_summaries,\n",
    "#         'Target': batch_targets\n",
    "#     })\n",
    "#     summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "# # Save the summary DataFrame to a CSV file\n",
    "# summary_df.to_csv('model_evaluation_output.csv', index=False)\n",
    "\n",
    "# # Display the summary DataFrame (optional)\n",
    "# display(summary_df)\n",
    "\n",
    "# # Examine a single review example (optional)\n",
    "# review_row = 5\n",
    "# print(\"CANDIDATE\")\n",
    "# print(summary_df.loc[review_row, \"Candidate_Summary\"])\n",
    "# print(\"TARGET\")\n",
    "# print(summary_df.loc[review_row, \"Target\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768cf72-b57a-4e6f-bf80-820f7dada389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26b8a964-42f2-4da4-ac0f-aa4b0008fbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewID</th>\n",
       "      <th>Candidate_Summary</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>[Bifibidibium is the most common intestinal an...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>[Glucose-lowering kinesia was associated with ...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24297836</td>\n",
       "      <td>[Conclusions : The findings of this review sug...</td>\n",
       "      <td>Ensuring that the characteristics of the histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32367221</td>\n",
       "      <td>[Postoperative autograft tendon graft reconstr...</td>\n",
       "      <td>The QT autograft detected comparable rate of L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25038833</td>\n",
       "      <td>[Oxytocin is an effective and safe narcotic fo...</td>\n",
       "      <td>medicines with anti-cholinergic properties hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>19776504</td>\n",
       "      <td>[There is insufficient evidence to determine w...</td>\n",
       "      <td>This systematic review with meta- analysis fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>27505198</td>\n",
       "      <td>[The majority of studies showed that dietary t...</td>\n",
       "      <td>A wide range of techniques have been evaluated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>25251296</td>\n",
       "      <td>[Conclusions : This systematic review and meta...</td>\n",
       "      <td>First , during anorexia nervosa adolescent fem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>23235652</td>\n",
       "      <td>[There is insufficient evidence to support the...</td>\n",
       "      <td>There is no convincing evidence that zinc supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>30058911</td>\n",
       "      <td>[Despite the heterogeneity of the epidemiology...</td>\n",
       "      <td>We argue that despite inconsistencies in the d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2021 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ReviewID                                  Candidate_Summary  \\\n",
       "0     28514886  [Bifibidibium is the most common intestinal an...   \n",
       "1     18842808  [Glucose-lowering kinesia was associated with ...   \n",
       "2     24297836  [Conclusions : The findings of this review sug...   \n",
       "3     32367221  [Postoperative autograft tendon graft reconstr...   \n",
       "4     25038833  [Oxytocin is an effective and safe narcotic fo...   \n",
       "...        ...                                                ...   \n",
       "2016  19776504  [There is insufficient evidence to determine w...   \n",
       "2017  27505198  [The majority of studies showed that dietary t...   \n",
       "2018  25251296  [Conclusions : This systematic review and meta...   \n",
       "2019  23235652  [There is insufficient evidence to support the...   \n",
       "2020  30058911  [Despite the heterogeneity of the epidemiology...   \n",
       "\n",
       "                                                 Target  \n",
       "0     Current evidence from systematic review and me...  \n",
       "1     The use of glucomannan did not appear to signi...  \n",
       "2     Ensuring that the characteristics of the histo...  \n",
       "3     The QT autograft detected comparable rate of L...  \n",
       "4     medicines with anti-cholinergic properties hav...  \n",
       "...                                                 ...  \n",
       "2016  This systematic review with meta- analysis fou...  \n",
       "2017  A wide range of techniques have been evaluated...  \n",
       "2018  First , during anorexia nervosa adolescent fem...  \n",
       "2019  There is no convincing evidence that zinc supp...  \n",
       "2020  We argue that despite inconsistencies in the d...  \n",
       "\n",
       "[2021 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from simplet5 import SimpleT5\n",
    "# import torch\n",
    "# import gc\n",
    "\n",
    "# # Load your trained model\n",
    "# model = SimpleT5()\n",
    "# model.load_model(\"t5\", \"outputs/simplet5-epoch-9-train-loss-1.9464-val-loss-2.6663\", use_gpu=True)\n",
    "\n",
    "# # Assuming 'output_df' is already loaded\n",
    "# batch_size = 1\n",
    "# summary_df = pd.DataFrame()\n",
    "\n",
    "# for i in range(0, len(output_df), batch_size):\n",
    "#     batch_abstracts = output_df['source_text'][i: i + batch_size]\n",
    "#     batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "#     batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "#     # Generate summaries\n",
    "#     batch_summaries = [model.predict(abstract) for abstract in batch_abstracts]\n",
    "\n",
    "#     temp_df = pd.DataFrame({\n",
    "#         'ReviewID': batch_review_ids,\n",
    "#         'Candidate_Summary': batch_summaries,\n",
    "#         'Target': batch_targets\n",
    "#     })\n",
    "#     summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "#     # Memory cleanup\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     # Memory cleanup\n",
    "#     # del inputs\n",
    "#     # del summary_ids\n",
    "#     # del batch_summaries\n",
    "#     # gc.collect()\n",
    "#     # torch.cuda.empty_cache()\n",
    "\n",
    "# summary_df.to_csv('model_evaluation_output.csv', index=False)\n",
    "# display(summary_df)\n",
    "import pandas as pd\n",
    "from simplet5 import SimpleT5\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Load your trained model\n",
    "model = SimpleT5()\n",
    "model.load_model(\"t5\", \"outputs/simplet5-epoch-9-train-loss-1.9464-val-loss-2.6663\", use_gpu=True)\n",
    "\n",
    "# Assuming 'output_df' is already loaded\n",
    "batch_size = 1\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(output_df), batch_size):\n",
    "    # Truncate source text to a reasonable length\n",
    "    batch_abstracts = output_df['source_text'][i: i + batch_size].str[:512]  # Adjust as needed\n",
    "    batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "    batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "    # Generate summaries with optimized parameters\n",
    "    batch_summaries = [model.predict(abstract, max_length=1280) for abstract in batch_abstracts]\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'ReviewID': batch_review_ids,\n",
    "        'Candidate_Summary': batch_summaries,\n",
    "        'Target': batch_targets\n",
    "    })\n",
    "    summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "summary_df.to_csv('model_evaluation_output_epoch-9-train-loss-1.9464-val-loss-2.6663.csv', index=False)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b32997b-ca6f-4764-a34d-301b77d02c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print (\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbfa078-9ca0-4c02-817c-77344c607e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                       \n",
    "        \n",
    "#         # Combine the summaries from each abstract\n",
    "#         combined_summary += summary + ' '\n",
    "\n",
    "#     return {\"review_id\": review_id, \"summary\": combined_summary.strip()}\n",
    "\n",
    "# Apply the function to each element of the dataset\n",
    "# summaries_dataset = dataset.map(process_row)\n",
    "\n",
    "# # Convert to pandas DataFrame\n",
    "# df = pd.DataFrame(summaries_dataset)\n",
    "# df = df[['review_id', 'summary']]\n",
    "# # Save to CSV\n",
    "# csv_file_path = 'test.csv'  # Update with your desired file path\n",
    "# df.to_csv(csv_file_path, index=True)\n",
    "\n",
    "# print(f\"Saved summaries to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2216ee1-7af6-4e00-b894-c18ba2e65d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
