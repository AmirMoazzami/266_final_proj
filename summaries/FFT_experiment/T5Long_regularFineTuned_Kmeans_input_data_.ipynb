{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6baf52d7-9b7e-477c-a1e4-161df03b3529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "707c87e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets sentencepiece rouge_score\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2385c429-3d90-412c-98ec-fd66c665efae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip -q install torch\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28067337-faa8-4dee-ae51-b5a6b3f56de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722f043b-9ce4-402c-a11c-f1270ab1c501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF is set to: max_split_size_mb:256\n",
      "device: cpu\n",
      "['review_id', 'pmid', 'title', 'abstract', 'target', 'background']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Memory optimization for CUDA\n",
    "max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF is set to: {os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "#when on Nvida machins \n",
    "# device = torch.device(\"cuda\")\n",
    "# print(\"device:\", device)\n",
    "\n",
    "#when you are on mac\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "# Load LongT5 Model and Tokenizer\n",
    "# model_to_use = \"google/long-t5-local-base\"\n",
    "model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "# Load validation dataset from Hugging Face datasets\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='train')\n",
    "\n",
    "\n",
    "# Prepare DataFrame for output\n",
    "# output_df = pd.DataFrame(columns=['ReviewID', 'Candidate_Summary', 'Target'])\n",
    "output_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204c07ba-5173-4625-9643-b93211736d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "      <th>background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>[22776744, 25271670, 3493740, 1863023, 1629198...</td>\n",
       "      <td>[Improved Cell Survival and Paracrine Capacity...</td>\n",
       "      <td>[Although transplantation of adult bone marrow...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "      <td>Background Despite significant progress in dru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                               pmid  \\\n",
       "0  30760312  [22776744, 25271670, 3493740, 1863023, 1629198...   \n",
       "\n",
       "                                               title  \\\n",
       "0  [Improved Cell Survival and Paracrine Capacity...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  [Although transplantation of adult bone marrow...   \n",
       "\n",
       "                                              target  \\\n",
       "0  Conclusions SC therapy is effective for PAH in...   \n",
       "\n",
       "                                          background  \n",
       "0  Background Despite significant progress in dru...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847e1ad4-db68-447e-aea8-b398f174d113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.drop(['pmid', 'title','background'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbd1db-7ebc-402a-920b-7dcd48cb28fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f767c828-6b16-4f48-b768-f32f8f392689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>[Although transplantation of adult bone marrow...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  30760312  [Although transplantation of adult bone marrow...   \n",
       "\n",
       "                                              target  \n",
       "0  Conclusions SC therapy is effective for PAH in...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12e54a5-fb63-4a05-a808-004d72d17280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df['abstract'] = output_df['abstract'].apply(lambda x: \"\".join([f\"Study : \" + b for i,b in enumerate(x)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed340481-15b9-4fac-a86f-77e7609f56f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>Study : Although transplantation of adult bone...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19588356</td>\n",
       "      <td>Study : BACKGROUND Primary pulmonary hypertens...</td>\n",
       "      <td>There was a trend for endothelin receptor anta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23893797</td>\n",
       "      <td>Study : BACKGROUND Although improved epicardia...</td>\n",
       "      <td>This present meta- analysis suggests that stat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  30760312  Study : Although transplantation of adult bone...   \n",
       "1  19588356  Study : BACKGROUND Primary pulmonary hypertens...   \n",
       "2  23893797  Study : BACKGROUND Although improved epicardia...   \n",
       "\n",
       "                                              target  \n",
       "0  Conclusions SC therapy is effective for PAH in...  \n",
       "1  There was a trend for endothelin receptor anta...  \n",
       "2  This present meta- analysis suggests that stat...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48dd9d16-5424-4d9c-91b6-a7ef0dced698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14188, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c7ca174-f4b4-454f-ab6f-56e71ab98912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers -q\n",
    "# !pip uninstall transformers\n",
    "# !pip install transformers\n",
    "# !pip uninstall -y pytorch-lightning\n",
    "# !pip install pytorch-lightning==1.5.10\n",
    "# !pip install -q --upgrade simplet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4738fb-7770-4768-b124-7db68d83eb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4112e2c1-e9de-4f14-87ad-cafc02ba47dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # Load the dataset and cut down to the first 5 for demonstration\n",
    "# # dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "# # dataset = dataset.select(range(3))  # Use select to create a subset\n",
    "\n",
    "# # Initialize BERT\n",
    "# # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# # model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# def bert_sentence_embeddings(sentences):\n",
    "#     embeddings = []\n",
    "#     for sentence in sentences:\n",
    "#         inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "#         embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "#     return np.array(embeddings)\n",
    "\n",
    "# def select_top_sentences(sentences, embeddings, n_sentences=5):\n",
    "#     if len(sentences) < n_sentences:\n",
    "#         return ' '.join(sentences)\n",
    "#     kmeans = KMeans(n_clusters=n_sentences, n_init=10)\n",
    "#     kmeans.fit(embeddings)\n",
    "#     top_sentences =[]\n",
    "#     i = 0\n",
    "#     while len(top_sentences) < n_sentences:\n",
    "#         top_sentence_indices = np.argmin(\n",
    "#         np.linalg.norm(embeddings[:, np.newaxis] - kmeans.cluster_centers_[i], axis=2), axis=0)\n",
    "#         top_sentences.append(sentences[top_sentence_indices[0]])\n",
    "#     return ' '.join(top_sentences)\n",
    "\n",
    "# def process_row( abstract_text):\n",
    "#     # Split abstract into sentences\n",
    "#     sentences = abstract_text.split('. ')\n",
    "#     # Generate embeddings for each sentence\n",
    "#     embeddings = bert_sentence_embeddings(sentences)\n",
    "#     # Select the top sentences from these embeddings\n",
    "#     summary = select_top_sentences(sentences, embeddings)\n",
    "        \n",
    "#     return summary\n",
    "        \n",
    "\n",
    "                             \n",
    "                             \n",
    "# output_df['abstract'] = output_df['abstract'].apply(lambda x:process_row(x) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1791ca14-a2ba-4420-bb15-7e3fcf706661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>Study : Although transplantation of adult bone...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  30760312  Study : Although transplantation of adult bone...   \n",
       "\n",
       "                                              target  \n",
       "0  Conclusions SC therapy is effective for PAH in...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad472d5-5d94-41ad-9417-1318e91bbb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06773bba-a77b-479c-996d-9838e2e8a9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the dataset from a CSV file\n",
    "# dataset_path = '/mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/BioBERT_K_Means_extractive.csv'\n",
    "# summaries_dataset = pd.read_csv(dataset_path , index_col=False)\n",
    "# # Convert the dataset to a list of dictionaries\n",
    "# data_list = summaries_dataset.to_dict(orient='records')\n",
    "# summaries_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3dc79a-6a57-458f-be8c-e30321a185c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>At 1 week posttransplantation , the number of ...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19588356</td>\n",
       "      <td>The changes in mean pulmonary-artery pressure ...</td>\n",
       "      <td>There was a trend for endothelin receptor anta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                           abstract  \\\n",
       "0   30760312  At 1 week posttransplantation , the number of ...   \n",
       "1   19588356  The changes in mean pulmonary-artery pressure ...   \n",
       "\n",
       "                                              target  \n",
       "0  Conclusions SC therapy is effective for PAH in...  \n",
       "1  There was a trend for endothelin receptor anta...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first dataset\n",
    "dataset_path = '/mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/embeding_1.csv'\n",
    "summaries_dataset = pd.read_csv(dataset_path, index_col=False)\n",
    "\n",
    "# Rename the 'summary' column to 'abstract'\n",
    "summaries_dataset.rename(columns={'summary': 'abstract'}, inplace=True)\n",
    "\n",
    "# Convert the 'review_id' column in summaries_dataset to integer (if it's not already)\n",
    "summaries_dataset['review_id'] = summaries_dataset['review_id'].astype(int)\n",
    "\n",
    "# Load the second dataset\n",
    "# (Assuming you have already loaded this dataset as 'output_df' in your previous steps)\n",
    "\n",
    "# Convert the 'review_id' column in output_df to integer (if it's not already)\n",
    "output_df['review_id'] = output_df['review_id'].astype(int)\n",
    "\n",
    "# Merge the two datasets based on 'review_id'\n",
    "merged_dataset = pd.merge(output_df, summaries_dataset[['review_id', 'abstract']], on='review_id', how='left')\n",
    "# merged_dataset.head(2)\n",
    "# merged_dataset.shape[0]\n",
    "# Replace the 'abstract' column in output_df with the one from summaries_dataset\n",
    "output_df['abstract'] = merged_dataset['abstract_y']\n",
    "output_df.head(2)\n",
    "\n",
    "# Now output_df will have the updated abstracts from summaries_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93795d07-ba9f-4ba0-87da-666e2d24a9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.rename(columns={\"target\":\"target_text\", \"abstract\":\"source_text\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04db8e34-06fe-42f6-8484-e3f2c513a4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30760312</td>\n",
       "      <td>At 1 week posttransplantation , the number of ...</td>\n",
       "      <td>Conclusions SC therapy is effective for PAH in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        source_text  \\\n",
       "0   30760312  At 1 week posttransplantation , the number of ...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Conclusions SC therapy is effective for PAH in...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a80d25-9352-4852-8164-be8882e8b86d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14188, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8de3d8c-92ff-42f7-b4d2-0e4972e72c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 16:34:11.937221: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-01 16:34:12.158546: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Load LongT5 Model and Tokenizer\n",
    "# model_to_use = \"google/long-t5-local-base\"\n",
    "# model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "# longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "# longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "from simplet5 import SimpleT5\n",
    "model=SimpleT5()\n",
    "model.from_pretrained(model_type=\"longt5\",model_name=\"pszemraj/long-t5-tglobal-base-16384-book-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919a104-c929-4dee-a117-1ac965a19cab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type longt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at pszemraj/long-t5-tglobal-base-16384-book-summary and are newly initialized: ['encoder.block.6.layer.0.SelfAttention.o.weight', 'encoder.block.2.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.k.weight', 'encoder.block.9.layer.0.SelfAttention.o.weight', 'encoder.block.3.layer.0.SelfAttention.k.weight', 'encoder.block.8.layer.0.SelfAttention.o.weight', 'encoder.block.11.layer.0.SelfAttention.q.weight', 'encoder.block.6.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.k.weight', 'encoder.block.7.layer.0.SelfAttention.v.weight', 'encoder.block.8.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.k.weight', 'encoder.block.6.layer.0.SelfAttention.k.weight', 'encoder.block.2.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'encoder.block.9.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.q.weight', 'encoder.block.9.layer.0.SelfAttention.v.weight', 'encoder.block.9.layer.0.SelfAttention.q.weight', 'encoder.block.11.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.k.weight', 'encoder.block.5.layer.0.SelfAttention.k.weight', 'encoder.block.3.layer.0.SelfAttention.v.weight', 'encoder.block.1.layer.0.SelfAttention.q.weight', 'encoder.block.5.layer.0.SelfAttention.o.weight', 'encoder.block.6.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.0.SelfAttention.o.weight', 'encoder.block.4.layer.0.SelfAttention.q.weight', 'encoder.block.8.layer.0.SelfAttention.q.weight', 'encoder.block.1.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.o.weight', 'encoder.block.11.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.q.weight', 'encoder.block.10.layer.0.SelfAttention.v.weight', 'encoder.block.4.layer.0.SelfAttention.v.weight', 'encoder.block.3.layer.0.SelfAttention.o.weight', 'encoder.block.1.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.0.SelfAttention.k.weight', 'encoder.block.0.layer.0.SelfAttention.v.weight', 'encoder.block.7.layer.0.SelfAttention.o.weight', 'encoder.block.10.layer.0.SelfAttention.q.weight', 'encoder.block.2.layer.0.SelfAttention.v.weight', 'encoder.block.5.layer.0.SelfAttention.v.weight', 'encoder.block.0.layer.0.SelfAttention.q.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 247 M \n",
      "-----------------------------------------------------\n",
      "247 M     Trainable params\n",
      "0         Non-trainable params\n",
      "247 M     Total params\n",
      "990.311   Total estimated model params size (MB)\n",
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/lightning_logs/version_260027/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  80%|███████▉  | 5675/7094 [1:51:24<27:51,  1.18s/it, loss=2.89, v_num=260027, train_loss_step=2.720]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 5685/7094 [1:51:27<27:37,  1.18s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:22,  2.07it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 5695/7094 [1:51:31<27:23,  1.18s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:41,  2.18it/s]\u001b[A\n",
      "Epoch 0:  80%|████████  | 5705/7094 [1:51:36<27:10,  1.17s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:23,  2.23it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5715/7094 [1:51:40<26:56,  1.17s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:16,  2.24it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5725/7094 [1:51:45<26:43,  1.17s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:08,  2.25it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5735/7094 [1:51:49<26:29,  1.17s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   4%|▍         | 60/1419 [00:27<10:03,  2.25it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5745/7094 [1:51:54<26:16,  1.17s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:59,  2.25it/s]\u001b[A\n",
      "Epoch 0:  81%|████████  | 5755/7094 [1:51:58<26:03,  1.17s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:54,  2.25it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 5765/7094 [1:52:02<25:49,  1.17s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:49,  2.25it/s]\u001b[A\n",
      "Epoch 0:  81%|████████▏ | 5775/7094 [1:52:07<25:36,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:44,  2.26it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5785/7094 [1:52:11<25:23,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   8%|▊         | 110/1419 [00:49<09:41,  2.25it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5795/7094 [1:52:16<25:09,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:35,  2.26it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5805/7094 [1:52:20<24:56,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:   9%|▉         | 130/1419 [00:58<09:33,  2.25it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5815/7094 [1:52:25<24:43,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:28,  2.25it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5825/7094 [1:52:29<24:30,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  11%|█         | 150/1419 [01:07<09:24,  2.25it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5835/7094 [1:52:34<24:17,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  11%|█▏        | 160/1419 [01:11<09:18,  2.25it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 5845/7094 [1:52:38<24:04,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:14,  2.25it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5855/7094 [1:52:42<23:51,  1.16s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  13%|█▎        | 180/1419 [01:20<09:10,  2.25it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5865/7094 [1:52:47<23:38,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:05,  2.25it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5875/7094 [1:52:51<23:25,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  14%|█▍        | 200/1419 [01:29<09:03,  2.24it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5885/7094 [1:52:56<23:12,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:57,  2.25it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5895/7094 [1:53:00<22:59,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  16%|█▌        | 220/1419 [01:38<08:53,  2.25it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5905/7094 [1:53:05<22:46,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  16%|█▌        | 230/1419 [01:42<08:48,  2.25it/s]\u001b[A\n",
      "Epoch 0:  83%|████████▎ | 5915/7094 [1:53:09<22:33,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  17%|█▋        | 240/1419 [01:47<08:43,  2.25it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 5925/7094 [1:53:14<22:20,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  18%|█▊        | 250/1419 [01:51<08:38,  2.25it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▎ | 5935/7094 [1:53:18<22:07,  1.15s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:33,  2.25it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5945/7094 [1:53:22<21:54,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  19%|█▉        | 270/1419 [02:00<08:30,  2.25it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5955/7094 [1:53:27<21:42,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  20%|█▉        | 280/1419 [02:04<08:26,  2.25it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5965/7094 [1:53:31<21:29,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  20%|██        | 290/1419 [02:09<08:21,  2.25it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5975/7094 [1:53:36<21:16,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  21%|██        | 300/1419 [02:13<08:16,  2.25it/s]\u001b[A\n",
      "Epoch 0:  84%|████████▍ | 5985/7094 [1:53:40<21:03,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  22%|██▏       | 310/1419 [02:18<08:14,  2.24it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 5995/7094 [1:53:45<20:51,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  23%|██▎       | 320/1419 [02:22<08:09,  2.24it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 6005/7094 [1:53:49<20:38,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  23%|██▎       | 330/1419 [02:27<08:05,  2.24it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 6015/7094 [1:53:54<20:25,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  24%|██▍       | 340/1419 [02:31<08:01,  2.24it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▍ | 6025/7094 [1:53:58<20:13,  1.14s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  25%|██▍       | 350/1419 [02:36<07:54,  2.25it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6035/7094 [1:54:02<20:00,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  25%|██▌       | 360/1419 [02:40<07:51,  2.25it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6045/7094 [1:54:07<19:48,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  26%|██▌       | 370/1419 [02:44<07:46,  2.25it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6055/7094 [1:54:11<19:35,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  27%|██▋       | 380/1419 [02:49<07:40,  2.25it/s]\u001b[A\n",
      "Epoch 0:  85%|████████▌ | 6065/7094 [1:54:16<19:23,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  27%|██▋       | 390/1419 [02:53<07:37,  2.25it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6075/7094 [1:54:20<19:10,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  28%|██▊       | 400/1419 [02:58<07:32,  2.25it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6085/7094 [1:54:25<18:58,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  29%|██▉       | 410/1419 [03:02<07:28,  2.25it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6095/7094 [1:54:29<18:45,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  30%|██▉       | 420/1419 [03:07<07:24,  2.25it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6105/7094 [1:54:34<18:33,  1.13s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  30%|███       | 430/1419 [03:11<07:19,  2.25it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▌ | 6115/7094 [1:54:38<18:21,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  31%|███       | 440/1419 [03:16<07:15,  2.25it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▋ | 6125/7094 [1:54:43<18:08,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  32%|███▏      | 450/1419 [03:20<07:10,  2.25it/s]\u001b[A\n",
      "Epoch 0:  86%|████████▋ | 6135/7094 [1:54:47<17:56,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  32%|███▏      | 460/1419 [03:24<07:06,  2.25it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6145/7094 [1:54:51<17:44,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  33%|███▎      | 470/1419 [03:29<07:02,  2.25it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6155/7094 [1:54:56<17:32,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  34%|███▍      | 480/1419 [03:33<06:58,  2.24it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6165/7094 [1:55:00<17:19,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  35%|███▍      | 490/1419 [03:38<06:53,  2.25it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6175/7094 [1:55:05<17:07,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  35%|███▌      | 500/1419 [03:42<06:49,  2.24it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6185/7094 [1:55:09<16:55,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  36%|███▌      | 510/1419 [03:47<06:43,  2.25it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6195/7094 [1:55:14<16:43,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  37%|███▋      | 520/1419 [03:51<06:39,  2.25it/s]\u001b[A\n",
      "Epoch 0:  87%|████████▋ | 6205/7094 [1:55:18<16:31,  1.12s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  37%|███▋      | 530/1419 [03:56<06:34,  2.25it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6215/7094 [1:55:23<16:19,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  38%|███▊      | 540/1419 [04:00<06:29,  2.26it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6225/7094 [1:55:27<16:07,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  39%|███▉      | 550/1419 [04:04<06:25,  2.25it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6235/7094 [1:55:31<15:55,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  39%|███▉      | 560/1419 [04:09<06:22,  2.25it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6245/7094 [1:55:36<15:42,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  40%|████      | 570/1419 [04:13<06:17,  2.25it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6255/7094 [1:55:40<15:30,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  41%|████      | 580/1419 [04:18<06:13,  2.25it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6265/7094 [1:55:45<15:19,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  42%|████▏     | 590/1419 [04:22<06:08,  2.25it/s]\u001b[A\n",
      "Epoch 0:  88%|████████▊ | 6275/7094 [1:55:49<15:07,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  42%|████▏     | 600/1419 [04:27<06:05,  2.24it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 6285/7094 [1:55:54<14:55,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  43%|████▎     | 610/1419 [04:31<06:00,  2.24it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▊ | 6295/7094 [1:55:58<14:43,  1.11s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  44%|████▎     | 620/1419 [04:36<05:56,  2.24it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6305/7094 [1:56:03<14:31,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  44%|████▍     | 630/1419 [04:40<05:51,  2.25it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6315/7094 [1:56:07<14:19,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  45%|████▌     | 640/1419 [04:45<05:47,  2.24it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6325/7094 [1:56:11<14:07,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  46%|████▌     | 650/1419 [04:49<05:42,  2.25it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6335/7094 [1:56:16<13:55,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  47%|████▋     | 660/1419 [04:53<05:38,  2.24it/s]\u001b[A\n",
      "Epoch 0:  89%|████████▉ | 6345/7094 [1:56:20<13:44,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  47%|████▋     | 670/1419 [04:58<05:33,  2.24it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 6355/7094 [1:56:25<13:32,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  48%|████▊     | 680/1419 [05:02<05:29,  2.24it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 6365/7094 [1:56:29<13:20,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  49%|████▊     | 690/1419 [05:07<05:23,  2.25it/s]\u001b[A\n",
      "Epoch 0:  90%|████████▉ | 6375/7094 [1:56:34<13:08,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  49%|████▉     | 700/1419 [05:11<05:19,  2.25it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6385/7094 [1:56:38<12:57,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  50%|█████     | 710/1419 [05:16<05:14,  2.25it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6395/7094 [1:56:43<12:45,  1.10s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  51%|█████     | 720/1419 [05:20<05:10,  2.25it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6405/7094 [1:56:47<12:33,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:25<05:06,  2.25it/s]\u001b[A\n",
      "Epoch 0:  90%|█████████ | 6415/7094 [1:56:52<12:22,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:29<05:01,  2.25it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6425/7094 [1:56:56<12:10,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:33<04:58,  2.24it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6435/7094 [1:57:00<11:59,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:38<04:53,  2.25it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6445/7094 [1:57:05<11:47,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:42<04:49,  2.24it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6455/7094 [1:57:09<11:35,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:47<04:44,  2.25it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████ | 6465/7094 [1:57:14<11:24,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:51<04:39,  2.25it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 6475/7094 [1:57:18<11:12,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:56<04:35,  2.25it/s]\u001b[A\n",
      "Epoch 0:  91%|█████████▏| 6485/7094 [1:57:23<11:01,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  57%|█████▋    | 810/1419 [06:00<04:30,  2.25it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6495/7094 [1:57:27<10:49,  1.09s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:05<04:26,  2.25it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6505/7094 [1:57:32<10:38,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:09<04:22,  2.24it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6515/7094 [1:57:36<10:27,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:14<04:18,  2.24it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6525/7094 [1:57:41<10:15,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:18<04:13,  2.24it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6535/7094 [1:57:45<10:04,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  61%|██████    | 860/1419 [06:22<04:08,  2.25it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6545/7094 [1:57:49<09:53,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:27<04:04,  2.25it/s]\u001b[A\n",
      "Epoch 0:  92%|█████████▏| 6555/7094 [1:57:54<09:41,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:31<03:58,  2.26it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6565/7094 [1:57:58<09:30,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:36<03:54,  2.25it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6575/7094 [1:58:03<09:19,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:40<03:50,  2.25it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6585/7094 [1:58:07<09:07,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:45<03:46,  2.25it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6595/7094 [1:58:12<08:56,  1.08s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:49<03:41,  2.25it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6605/7094 [1:58:16<08:45,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:54<03:38,  2.24it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6615/7094 [1:58:21<08:34,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:58<03:33,  2.25it/s]\u001b[A\n",
      "Epoch 0:  93%|█████████▎| 6625/7094 [1:58:25<08:23,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  67%|██████▋   | 950/1419 [07:02<03:28,  2.25it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 6635/7094 [1:58:29<08:11,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:07<03:23,  2.25it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▎| 6645/7094 [1:58:34<08:00,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:11<03:19,  2.25it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6655/7094 [1:58:38<07:49,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:16<03:14,  2.25it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6665/7094 [1:58:43<07:38,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:20<03:10,  2.25it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6675/7094 [1:58:47<07:27,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  70%|███████   | 1000/1419 [07:25<03:05,  2.26it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6685/7094 [1:58:52<07:16,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  71%|███████   | 1010/1419 [07:29<03:01,  2.25it/s]\u001b[A\n",
      "Epoch 0:  94%|█████████▍| 6695/7094 [1:58:56<07:05,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:33<02:57,  2.25it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6705/7094 [1:59:00<06:54,  1.07s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:38<02:53,  2.24it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6715/7094 [1:59:05<06:43,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:42<02:48,  2.25it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6725/7094 [1:59:09<06:32,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:47<02:44,  2.25it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▍| 6735/7094 [1:59:14<06:21,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:51<02:39,  2.25it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 6745/7094 [1:59:18<06:10,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:56<02:35,  2.25it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 6755/7094 [1:59:23<05:59,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  76%|███████▌  | 1080/1419 [08:00<02:31,  2.24it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 6765/7094 [1:59:27<05:48,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:05<02:26,  2.25it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6775/7094 [1:59:32<05:37,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:09<02:21,  2.25it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6785/7094 [1:59:36<05:26,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:14<02:17,  2.25it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6795/7094 [1:59:41<05:15,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:18<02:13,  2.25it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6805/7094 [1:59:45<05:05,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:22<02:08,  2.25it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6815/7094 [1:59:49<04:54,  1.06s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  80%|████████  | 1140/1419 [08:27<02:03,  2.25it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▌| 6825/7094 [1:59:54<04:43,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  81%|████████  | 1150/1419 [08:31<02:00,  2.24it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 6835/7094 [1:59:58<04:32,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:36<01:55,  2.25it/s]\u001b[A\n",
      "Epoch 0:  96%|█████████▋| 6845/7094 [2:00:03<04:22,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:40<01:50,  2.25it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6855/7094 [2:00:07<04:11,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:45<01:46,  2.25it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6865/7094 [2:00:12<04:00,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:49<01:41,  2.25it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6875/7094 [2:00:16<03:49,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:54<01:37,  2.25it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6885/7094 [2:00:21<03:39,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:58<01:33,  2.25it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6895/7094 [2:00:25<03:28,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  86%|████████▌ | 1220/1419 [09:02<01:28,  2.24it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6905/7094 [2:00:29<03:17,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:07<01:24,  2.24it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 6915/7094 [2:00:34<03:07,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:11<01:19,  2.24it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6925/7094 [2:00:38<02:56,  1.05s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:16<01:15,  2.24it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6935/7094 [2:00:43<02:46,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:20<01:10,  2.24it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6945/7094 [2:00:47<02:35,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:25<01:06,  2.25it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6955/7094 [2:00:52<02:24,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:29<01:01,  2.25it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6965/7094 [2:00:56<02:14,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:34<00:57,  2.26it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6975/7094 [2:01:01<02:03,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:38<00:52,  2.26it/s]\u001b[A\n",
      "Epoch 0:  98%|█████████▊| 6985/7094 [2:01:05<01:53,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:42<00:48,  2.25it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 6995/7094 [2:01:09<01:42,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:47<00:43,  2.25it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▊| 7005/7094 [2:01:14<01:32,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:51<00:39,  2.25it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7015/7094 [2:01:18<01:21,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:56<00:35,  2.25it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7025/7094 [2:01:23<01:11,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  95%|█████████▌| 1350/1419 [10:00<00:30,  2.25it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7035/7094 [2:01:27<01:01,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  96%|█████████▌| 1360/1419 [10:05<00:26,  2.25it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7045/7094 [2:01:32<00:50,  1.04s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:09<00:21,  2.25it/s]\u001b[A\n",
      "Epoch 0:  99%|█████████▉| 7055/7094 [2:01:36<00:40,  1.03s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:14<00:17,  2.25it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 7065/7094 [2:01:41<00:29,  1.03s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:18<00:12,  2.25it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 7075/7094 [2:01:45<00:19,  1.03s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:22<00:08,  2.25it/s]\u001b[A\n",
      "Epoch 0: 100%|█████████▉| 7085/7094 [2:01:49<00:09,  1.03s/it, loss=2.89, v_num=260027, train_loss_step=2.720]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:27<00:03,  2.25it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:29<00:01,  2.25it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 7094/7094 [2:01:56<00:00,  1.03s/it, loss=2.89, v_num=260027, train_loss_step=2.720, val_loss_step=2.710, val_loss_epoch=2.650]\n",
      "Epoch 1:  11%|█         | 790/7094 [15:30<2:03:41,  1.18s/it, loss=2.8, v_num=260027, train_loss_step=3.020, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  80%|███████▉  | 5675/7094 [1:51:10<27:48,  1.18s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 5685/7094 [1:51:13<27:33,  1.17s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:11,  2.10it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 5695/7094 [1:51:17<27:20,  1.17s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:36,  2.20it/s]\u001b[A\n",
      "Epoch 1:  80%|████████  | 5705/7094 [1:51:22<27:06,  1.17s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:21,  2.24it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5715/7094 [1:51:26<26:53,  1.17s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:13,  2.25it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5725/7094 [1:51:31<26:40,  1.17s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:06,  2.26it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5735/7094 [1:51:35<26:26,  1.17s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   4%|▍         | 60/1419 [00:26<10:01,  2.26it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5745/7094 [1:51:40<26:13,  1.17s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:57,  2.26it/s]\u001b[A\n",
      "Epoch 1:  81%|████████  | 5755/7094 [1:51:44<25:59,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:52,  2.26it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 5765/7094 [1:51:48<25:46,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:47,  2.26it/s]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 5775/7094 [1:51:53<25:33,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:43,  2.26it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5785/7094 [1:51:57<25:20,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   8%|▊         | 110/1419 [00:49<09:39,  2.26it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5795/7094 [1:52:02<25:06,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:35,  2.26it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5805/7094 [1:52:06<24:53,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:30,  2.26it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5815/7094 [1:52:11<24:40,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:26,  2.26it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5825/7094 [1:52:15<24:27,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:21,  2.26it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5835/7094 [1:52:19<24:14,  1.16s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  11%|█▏        | 160/1419 [01:11<09:18,  2.26it/s]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 5845/7094 [1:52:24<24:01,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:11,  2.26it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5855/7094 [1:52:28<23:48,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  13%|█▎        | 180/1419 [01:20<09:08,  2.26it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5865/7094 [1:52:33<23:35,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:02,  2.26it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5875/7094 [1:52:37<23:22,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<08:58,  2.26it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5885/7094 [1:52:41<23:09,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:55,  2.26it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5895/7094 [1:52:46<22:56,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:51,  2.26it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5905/7094 [1:52:50<22:43,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  16%|█▌        | 230/1419 [01:42<08:46,  2.26it/s]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 5915/7094 [1:52:55<22:30,  1.15s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:42,  2.26it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 5925/7094 [1:52:59<22:17,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  18%|█▊        | 250/1419 [01:51<08:37,  2.26it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 5935/7094 [1:53:04<22:04,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:33,  2.26it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5945/7094 [1:53:08<21:52,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:28,  2.26it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5955/7094 [1:53:13<21:39,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  20%|█▉        | 280/1419 [02:04<08:23,  2.26it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5965/7094 [1:53:17<21:26,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:19,  2.26it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5975/7094 [1:53:21<21:13,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  21%|██        | 300/1419 [02:13<08:15,  2.26it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 5985/7094 [1:53:26<21:01,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  22%|██▏       | 310/1419 [02:17<08:10,  2.26it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 5995/7094 [1:53:30<20:48,  1.14s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  23%|██▎       | 320/1419 [02:22<08:07,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 6005/7094 [1:53:35<20:35,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  23%|██▎       | 330/1419 [02:26<08:03,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 6015/7094 [1:53:39<20:23,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:59,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 6025/7094 [1:53:44<20:10,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  25%|██▍       | 350/1419 [02:35<07:54,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6035/7094 [1:53:48<19:58,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:49,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6045/7094 [1:53:52<19:45,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  26%|██▌       | 370/1419 [02:44<07:45,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6055/7094 [1:53:57<19:33,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  27%|██▋       | 380/1419 [02:48<07:41,  2.25it/s]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 6065/7094 [1:54:01<19:20,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  27%|██▋       | 390/1419 [02:53<07:36,  2.25it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6075/7094 [1:54:06<19:08,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  28%|██▊       | 400/1419 [02:57<07:30,  2.26it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6085/7094 [1:54:10<18:55,  1.13s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  29%|██▉       | 410/1419 [03:02<07:28,  2.25it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6095/7094 [1:54:15<18:43,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  30%|██▉       | 420/1419 [03:06<07:25,  2.24it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6105/7094 [1:54:19<18:31,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  30%|███       | 430/1419 [03:10<07:20,  2.24it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 6115/7094 [1:54:24<18:18,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  31%|███       | 440/1419 [03:15<07:15,  2.25it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 6125/7094 [1:54:28<18:06,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  32%|███▏      | 450/1419 [03:19<07:09,  2.26it/s]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 6135/7094 [1:54:32<17:54,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  32%|███▏      | 460/1419 [03:24<07:05,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6145/7094 [1:54:37<17:42,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  33%|███▎      | 470/1419 [03:28<07:00,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6155/7094 [1:54:41<17:29,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  34%|███▍      | 480/1419 [03:33<06:55,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6165/7094 [1:54:46<17:17,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  35%|███▍      | 490/1419 [03:37<06:51,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6175/7094 [1:54:50<17:05,  1.12s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  35%|███▌      | 500/1419 [03:41<06:46,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6185/7094 [1:54:55<16:53,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  36%|███▌      | 510/1419 [03:46<06:42,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6195/7094 [1:54:59<16:41,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  37%|███▋      | 520/1419 [03:50<06:38,  2.26it/s]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 6205/7094 [1:55:03<16:29,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  37%|███▋      | 530/1419 [03:55<06:34,  2.26it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6215/7094 [1:55:08<16:17,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  38%|███▊      | 540/1419 [03:59<06:30,  2.25it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6225/7094 [1:55:12<16:05,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  39%|███▉      | 550/1419 [04:04<06:25,  2.26it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6235/7094 [1:55:17<15:52,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  39%|███▉      | 560/1419 [04:08<06:21,  2.25it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6245/7094 [1:55:21<15:40,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  40%|████      | 570/1419 [04:12<06:16,  2.26it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6255/7094 [1:55:26<15:29,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  41%|████      | 580/1419 [04:17<06:12,  2.26it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6265/7094 [1:55:30<15:17,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  42%|████▏     | 590/1419 [04:21<06:07,  2.25it/s]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 6275/7094 [1:55:34<15:05,  1.11s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  42%|████▏     | 600/1419 [04:26<06:02,  2.26it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 6285/7094 [1:55:39<14:53,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  43%|████▎     | 610/1419 [04:30<05:59,  2.25it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 6295/7094 [1:55:43<14:41,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  44%|████▎     | 620/1419 [04:35<05:54,  2.25it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6305/7094 [1:55:48<14:29,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  44%|████▍     | 630/1419 [04:39<05:50,  2.25it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6315/7094 [1:55:52<14:17,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  45%|████▌     | 640/1419 [04:44<05:45,  2.25it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6325/7094 [1:55:57<14:05,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  46%|████▌     | 650/1419 [04:48<05:41,  2.25it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6335/7094 [1:56:01<13:54,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  47%|████▋     | 660/1419 [04:52<05:37,  2.25it/s]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 6345/7094 [1:56:06<13:42,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  47%|████▋     | 670/1419 [04:57<05:31,  2.26it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 6355/7094 [1:56:10<13:30,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  48%|████▊     | 680/1419 [05:01<05:27,  2.26it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 6365/7094 [1:56:14<13:18,  1.10s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  49%|████▊     | 690/1419 [05:06<05:23,  2.26it/s]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 6375/7094 [1:56:19<13:07,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  49%|████▉     | 700/1419 [05:10<05:19,  2.25it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6385/7094 [1:56:23<12:55,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  50%|█████     | 710/1419 [05:15<05:13,  2.26it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6395/7094 [1:56:28<12:43,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  51%|█████     | 720/1419 [05:19<05:09,  2.26it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6405/7094 [1:56:32<12:32,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:23<05:04,  2.26it/s]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 6415/7094 [1:56:36<12:20,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:28<05:00,  2.26it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6425/7094 [1:56:41<12:09,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:32<04:56,  2.26it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6435/7094 [1:56:45<11:57,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:37<04:51,  2.26it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6445/7094 [1:56:50<11:45,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:41<04:47,  2.26it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6455/7094 [1:56:54<11:34,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:46<04:42,  2.26it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 6465/7094 [1:56:59<11:22,  1.09s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:50<04:39,  2.25it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 6475/7094 [1:57:03<11:11,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:54<04:34,  2.26it/s]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 6485/7094 [1:57:08<10:59,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:59<04:30,  2.25it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6495/7094 [1:57:12<10:48,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:03<04:25,  2.26it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6505/7094 [1:57:16<10:37,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:08<04:20,  2.26it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6515/7094 [1:57:21<10:25,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:12<04:16,  2.25it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6525/7094 [1:57:25<10:14,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:17<04:12,  2.26it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6535/7094 [1:57:30<10:03,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  61%|██████    | 860/1419 [06:21<04:09,  2.24it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6545/7094 [1:57:34<09:51,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:25<04:03,  2.25it/s]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 6555/7094 [1:57:39<09:40,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:30<03:59,  2.25it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6565/7094 [1:57:43<09:29,  1.08s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:34<03:54,  2.26it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6575/7094 [1:57:47<09:17,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:39<03:49,  2.26it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6585/7094 [1:57:52<09:06,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:43<03:45,  2.26it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6595/7094 [1:57:56<08:55,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:48<03:40,  2.26it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6605/7094 [1:58:01<08:44,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:52<03:36,  2.26it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6615/7094 [1:58:05<08:33,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:57<03:32,  2.25it/s]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 6625/7094 [1:58:10<08:21,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  67%|██████▋   | 950/1419 [07:01<03:27,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 6635/7094 [1:58:14<08:10,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:05<03:23,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 6645/7094 [1:58:18<07:59,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:10<03:18,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6655/7094 [1:58:23<07:48,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:14<03:14,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6665/7094 [1:58:27<07:37,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:19<03:09,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6675/7094 [1:58:32<07:26,  1.07s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  70%|███████   | 1000/1419 [07:23<03:05,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6685/7094 [1:58:36<07:15,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  71%|███████   | 1010/1419 [07:27<03:01,  2.26it/s]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 6695/7094 [1:58:41<07:04,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:32<02:57,  2.25it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6705/7094 [1:58:45<06:53,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:36<02:52,  2.25it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6715/7094 [1:58:49<06:42,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:41<02:48,  2.26it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6725/7094 [1:58:54<06:31,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:45<02:43,  2.26it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 6735/7094 [1:58:58<06:20,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:50<02:39,  2.26it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 6745/7094 [1:59:03<06:09,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:54<02:35,  2.25it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 6755/7094 [1:59:07<05:58,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:59<02:30,  2.25it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 6765/7094 [1:59:12<05:47,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:03<02:25,  2.25it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6775/7094 [1:59:16<05:36,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:07<02:21,  2.25it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6785/7094 [1:59:21<05:26,  1.06s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:12<02:16,  2.26it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6795/7094 [1:59:25<05:15,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:16<02:12,  2.25it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6805/7094 [1:59:29<05:04,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:21<02:07,  2.26it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6815/7094 [1:59:34<04:53,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  80%|████████  | 1140/1419 [08:25<02:03,  2.26it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 6825/7094 [1:59:38<04:42,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  81%|████████  | 1150/1419 [08:30<01:59,  2.25it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 6835/7094 [1:59:43<04:32,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:34<01:54,  2.26it/s]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 6845/7094 [1:59:47<04:21,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:38<01:50,  2.26it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6855/7094 [1:59:52<04:10,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:43<01:45,  2.26it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6865/7094 [1:59:56<04:00,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:47<01:41,  2.26it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6875/7094 [2:00:00<03:49,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:52<01:37,  2.26it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6885/7094 [2:00:05<03:38,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:56<01:32,  2.25it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6895/7094 [2:00:09<03:28,  1.05s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  86%|████████▌ | 1220/1419 [09:01<01:28,  2.25it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6905/7094 [2:00:14<03:17,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:05<01:24,  2.25it/s]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 6915/7094 [2:00:18<03:06,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:10<01:19,  2.24it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6925/7094 [2:00:23<02:56,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:14<01:15,  2.25it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6935/7094 [2:00:27<02:45,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:18<01:10,  2.25it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6945/7094 [2:00:32<02:35,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:23<01:05,  2.26it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6955/7094 [2:00:36<02:24,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  90%|█████████ | 1280/1419 [09:27<01:01,  2.26it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6965/7094 [2:00:40<02:14,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  91%|█████████ | 1290/1419 [09:32<00:57,  2.26it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6975/7094 [2:00:45<02:03,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  92%|█████████▏| 1300/1419 [09:36<00:52,  2.25it/s]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 6985/7094 [2:00:49<01:53,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  92%|█████████▏| 1310/1419 [09:41<00:48,  2.24it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 6995/7094 [2:00:54<01:42,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  93%|█████████▎| 1320/1419 [09:45<00:43,  2.25it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 7005/7094 [2:00:58<01:32,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  94%|█████████▎| 1330/1419 [09:49<00:39,  2.25it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7015/7094 [2:01:03<01:21,  1.04s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  94%|█████████▍| 1340/1419 [09:54<00:35,  2.25it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7025/7094 [2:01:07<01:11,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  95%|█████████▌| 1350/1419 [09:58<00:30,  2.25it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7035/7094 [2:01:11<01:00,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  96%|█████████▌| 1360/1419 [10:03<00:26,  2.26it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7045/7094 [2:01:16<00:50,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  97%|█████████▋| 1370/1419 [10:07<00:21,  2.26it/s]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 7055/7094 [2:01:20<00:40,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  97%|█████████▋| 1380/1419 [10:12<00:17,  2.26it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 7065/7094 [2:01:25<00:29,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  98%|█████████▊| 1390/1419 [10:16<00:12,  2.26it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 7075/7094 [2:01:29<00:19,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  99%|█████████▊| 1400/1419 [10:20<00:08,  2.26it/s]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 7085/7094 [2:01:34<00:09,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.710, val_loss_epoch=2.650, train_loss_epoch=3.160]\n",
      "Validating:  99%|█████████▉| 1410/1419 [10:25<00:03,  2.26it/s]\u001b[A\n",
      "Validating: 100%|█████████▉| 1415/1419 [10:27<00:01,  2.25it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 7094/7094 [2:01:40<00:00,  1.03s/it, loss=2.7, v_num=260027, train_loss_step=2.570, val_loss_step=2.600, val_loss_epoch=2.570, train_loss_epoch=3.160]\n",
      "Epoch 2:  59%|█████▊    | 4165/7094 [1:21:27<57:16,  1.17s/it, loss=2.65, v_num=260027, train_loss_step=2.880, val_loss_step=2.600, val_loss_epoch=2.570, train_loss_epoch=2.780]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  80%|███████▉  | 5675/7094 [1:50:48<27:42,  1.17s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]  \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/1419 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 5685/7094 [1:50:51<27:28,  1.17s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   1%|          | 10/1419 [00:04<11:11,  2.10it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 5695/7094 [1:50:55<27:15,  1.17s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   1%|▏         | 20/1419 [00:09<10:34,  2.21it/s]\u001b[A\n",
      "Epoch 3:  80%|████████  | 5705/7094 [1:51:00<27:01,  1.17s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   2%|▏         | 30/1419 [00:13<10:23,  2.23it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5715/7094 [1:51:04<26:48,  1.17s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   3%|▎         | 40/1419 [00:18<10:12,  2.25it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5725/7094 [1:51:09<26:34,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   4%|▎         | 50/1419 [00:22<10:07,  2.25it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5735/7094 [1:51:13<26:21,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   4%|▍         | 60/1419 [00:26<10:01,  2.26it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5745/7094 [1:51:18<26:08,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   5%|▍         | 70/1419 [00:31<09:55,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████  | 5755/7094 [1:51:22<25:54,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   6%|▌         | 80/1419 [00:35<09:50,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 5765/7094 [1:51:26<25:41,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   6%|▋         | 90/1419 [00:40<09:45,  2.27it/s]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 5775/7094 [1:51:31<25:28,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   7%|▋         | 100/1419 [00:44<09:41,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5785/7094 [1:51:35<25:15,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   8%|▊         | 110/1419 [00:49<09:37,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5795/7094 [1:51:40<25:01,  1.16s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   8%|▊         | 120/1419 [00:53<09:33,  2.26it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5805/7094 [1:51:44<24:48,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:   9%|▉         | 130/1419 [00:57<09:28,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5815/7094 [1:51:48<24:35,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  10%|▉         | 140/1419 [01:02<09:24,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5825/7094 [1:51:53<24:22,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  11%|█         | 150/1419 [01:06<09:20,  2.26it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5835/7094 [1:51:57<24:09,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  11%|█▏        | 160/1419 [01:11<09:14,  2.27it/s]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 5845/7094 [1:52:02<23:56,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  12%|█▏        | 170/1419 [01:15<09:10,  2.27it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5855/7094 [1:52:06<23:43,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  13%|█▎        | 180/1419 [01:19<09:07,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5865/7094 [1:52:10<23:30,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  13%|█▎        | 190/1419 [01:24<09:04,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5875/7094 [1:52:15<23:17,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  14%|█▍        | 200/1419 [01:28<09:00,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5885/7094 [1:52:19<23:04,  1.15s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  15%|█▍        | 210/1419 [01:33<08:55,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5895/7094 [1:52:24<22:51,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  16%|█▌        | 220/1419 [01:37<08:49,  2.26it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5905/7094 [1:52:28<22:38,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  16%|█▌        | 230/1419 [01:42<08:44,  2.27it/s]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 5915/7094 [1:52:33<22:26,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  17%|█▋        | 240/1419 [01:46<08:40,  2.27it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 5925/7094 [1:52:37<22:13,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  18%|█▊        | 250/1419 [01:50<08:35,  2.27it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 5935/7094 [1:52:41<22:00,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  18%|█▊        | 260/1419 [01:55<08:32,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5945/7094 [1:52:46<21:47,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  19%|█▉        | 270/1419 [01:59<08:28,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5955/7094 [1:52:50<21:35,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  20%|█▉        | 280/1419 [02:04<08:24,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5965/7094 [1:52:55<21:22,  1.14s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  20%|██        | 290/1419 [02:08<08:18,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5975/7094 [1:52:59<21:09,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  21%|██        | 300/1419 [02:12<08:15,  2.26it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 5985/7094 [1:53:04<20:57,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  22%|██▏       | 310/1419 [02:17<08:10,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 5995/7094 [1:53:08<20:44,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  23%|██▎       | 320/1419 [02:21<08:05,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 6005/7094 [1:53:12<20:31,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  23%|██▎       | 330/1419 [02:26<08:00,  2.27it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 6015/7094 [1:53:17<20:19,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  24%|██▍       | 340/1419 [02:30<07:55,  2.27it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 6025/7094 [1:53:21<20:06,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  25%|██▍       | 350/1419 [02:35<07:52,  2.26it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6035/7094 [1:53:26<19:54,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  25%|██▌       | 360/1419 [02:39<07:46,  2.27it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6045/7094 [1:53:30<19:41,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  26%|██▌       | 370/1419 [02:43<07:42,  2.27it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6055/7094 [1:53:34<19:29,  1.13s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  27%|██▋       | 380/1419 [02:48<07:37,  2.27it/s]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 6065/7094 [1:53:39<19:16,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  27%|██▋       | 390/1419 [02:52<07:33,  2.27it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6075/7094 [1:53:43<19:04,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  28%|██▊       | 400/1419 [02:57<07:29,  2.27it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6085/7094 [1:53:48<18:52,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  29%|██▉       | 410/1419 [03:01<07:27,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6095/7094 [1:53:52<18:39,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  30%|██▉       | 420/1419 [03:05<07:24,  2.25it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6105/7094 [1:53:57<18:27,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  30%|███       | 430/1419 [03:10<07:18,  2.25it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 6115/7094 [1:54:01<18:15,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  31%|███       | 440/1419 [03:14<07:14,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 6125/7094 [1:54:05<18:03,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  32%|███▏      | 450/1419 [03:19<07:09,  2.26it/s]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 6135/7094 [1:54:10<17:50,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  32%|███▏      | 460/1419 [03:23<07:05,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6145/7094 [1:54:14<17:38,  1.12s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  33%|███▎      | 470/1419 [03:28<07:00,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6155/7094 [1:54:19<17:26,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  34%|███▍      | 480/1419 [03:32<06:55,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6165/7094 [1:54:23<17:14,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  35%|███▍      | 490/1419 [03:36<06:51,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6175/7094 [1:54:28<17:02,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  35%|███▌      | 500/1419 [03:41<06:45,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6185/7094 [1:54:32<16:50,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  36%|███▌      | 510/1419 [03:45<06:42,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6195/7094 [1:54:36<16:37,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  37%|███▋      | 520/1419 [03:50<06:37,  2.26it/s]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 6205/7094 [1:54:41<16:25,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  37%|███▋      | 530/1419 [03:54<06:33,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6215/7094 [1:54:45<16:13,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  38%|███▊      | 540/1419 [03:59<06:29,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6225/7094 [1:54:50<16:01,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  39%|███▉      | 550/1419 [04:03<06:24,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6235/7094 [1:54:54<15:49,  1.11s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  39%|███▉      | 560/1419 [04:07<06:20,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6245/7094 [1:54:59<15:37,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  40%|████      | 570/1419 [04:12<06:15,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6255/7094 [1:55:03<15:25,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  41%|████      | 580/1419 [04:16<06:11,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6265/7094 [1:55:07<15:14,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  42%|████▏     | 590/1419 [04:21<06:06,  2.26it/s]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 6275/7094 [1:55:12<15:02,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  42%|████▏     | 600/1419 [04:25<06:01,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 6285/7094 [1:55:16<14:50,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  43%|████▎     | 610/1419 [04:30<05:57,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 6295/7094 [1:55:21<14:38,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  44%|████▎     | 620/1419 [04:34<05:55,  2.25it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6305/7094 [1:55:25<14:26,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  44%|████▍     | 630/1419 [04:38<05:51,  2.25it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6315/7094 [1:55:30<14:14,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  45%|████▌     | 640/1419 [04:43<05:46,  2.25it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6325/7094 [1:55:34<14:03,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  46%|████▌     | 650/1419 [04:47<05:41,  2.25it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6335/7094 [1:55:38<13:51,  1.10s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  47%|████▋     | 660/1419 [04:52<05:35,  2.26it/s]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 6345/7094 [1:55:43<13:39,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  47%|████▋     | 670/1419 [04:56<05:31,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 6355/7094 [1:55:47<13:27,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  48%|████▊     | 680/1419 [05:01<05:26,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 6365/7094 [1:55:52<13:16,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  49%|████▊     | 690/1419 [05:05<05:22,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 6375/7094 [1:55:56<13:04,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  49%|████▉     | 700/1419 [05:09<05:17,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6385/7094 [1:56:00<12:52,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  50%|█████     | 710/1419 [05:14<05:13,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6395/7094 [1:56:05<12:41,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  51%|█████     | 720/1419 [05:18<05:08,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6405/7094 [1:56:09<12:29,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  51%|█████▏    | 730/1419 [05:23<05:04,  2.26it/s]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 6415/7094 [1:56:14<12:18,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  52%|█████▏    | 740/1419 [05:27<04:59,  2.27it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6425/7094 [1:56:18<12:06,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  53%|█████▎    | 750/1419 [05:32<04:54,  2.27it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6435/7094 [1:56:23<11:55,  1.09s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  54%|█████▎    | 760/1419 [05:36<04:51,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6445/7094 [1:56:27<11:43,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  54%|█████▍    | 770/1419 [05:40<04:46,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6455/7094 [1:56:31<11:32,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  55%|█████▍    | 780/1419 [05:45<04:42,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 6465/7094 [1:56:36<11:20,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  56%|█████▌    | 790/1419 [05:49<04:38,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 6475/7094 [1:56:40<11:09,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  56%|█████▋    | 800/1419 [05:54<04:34,  2.26it/s]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 6485/7094 [1:56:45<10:57,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  57%|█████▋    | 810/1419 [05:58<04:29,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6495/7094 [1:56:49<10:46,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  58%|█████▊    | 820/1419 [06:02<04:24,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6505/7094 [1:56:54<10:35,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  58%|█████▊    | 830/1419 [06:07<04:20,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6515/7094 [1:56:58<10:23,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  59%|█████▉    | 840/1419 [06:11<04:15,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6525/7094 [1:57:02<10:12,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  60%|█████▉    | 850/1419 [06:16<04:11,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6535/7094 [1:57:07<10:01,  1.08s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  61%|██████    | 860/1419 [06:20<04:07,  2.26it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6545/7094 [1:57:11<09:49,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  61%|██████▏   | 870/1419 [06:25<04:03,  2.25it/s]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 6555/7094 [1:57:16<09:38,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  62%|██████▏   | 880/1419 [06:29<03:58,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6565/7094 [1:57:20<09:27,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  63%|██████▎   | 890/1419 [06:33<03:55,  2.25it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6575/7094 [1:57:25<09:16,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  63%|██████▎   | 900/1419 [06:38<03:50,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6585/7094 [1:57:29<09:04,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  64%|██████▍   | 910/1419 [06:42<03:45,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6595/7094 [1:57:33<08:53,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  65%|██████▍   | 920/1419 [06:47<03:40,  2.27it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6605/7094 [1:57:38<08:42,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  66%|██████▌   | 930/1419 [06:51<03:36,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6615/7094 [1:57:42<08:31,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  66%|██████▌   | 940/1419 [06:56<03:32,  2.26it/s]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 6625/7094 [1:57:47<08:20,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  67%|██████▋   | 950/1419 [07:00<03:28,  2.25it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 6635/7094 [1:57:51<08:09,  1.07s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  68%|██████▊   | 960/1419 [07:04<03:22,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 6645/7094 [1:57:56<07:58,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  68%|██████▊   | 970/1419 [07:09<03:18,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6655/7094 [1:58:00<07:47,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  69%|██████▉   | 980/1419 [07:13<03:14,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6665/7094 [1:58:04<07:36,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  70%|██████▉   | 990/1419 [07:18<03:10,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6675/7094 [1:58:09<07:25,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  70%|███████   | 1000/1419 [07:22<03:05,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6685/7094 [1:58:13<07:14,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  71%|███████   | 1010/1419 [07:27<03:00,  2.26it/s]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 6695/7094 [1:58:18<07:03,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  72%|███████▏  | 1020/1419 [07:31<02:56,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6705/7094 [1:58:22<06:52,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  73%|███████▎  | 1030/1419 [07:35<02:51,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6715/7094 [1:58:26<06:41,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  73%|███████▎  | 1040/1419 [07:40<02:47,  2.27it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6725/7094 [1:58:31<06:30,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  74%|███████▍  | 1050/1419 [07:44<02:43,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 6735/7094 [1:58:35<06:19,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  75%|███████▍  | 1060/1419 [07:49<02:38,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 6745/7094 [1:58:40<06:08,  1.06s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  75%|███████▌  | 1070/1419 [07:53<02:34,  2.25it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 6755/7094 [1:58:44<05:57,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  76%|███████▌  | 1080/1419 [07:58<02:30,  2.26it/s]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 6765/7094 [1:58:49<05:46,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  77%|███████▋  | 1090/1419 [08:02<02:25,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6775/7094 [1:58:53<05:35,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  78%|███████▊  | 1100/1419 [08:06<02:20,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6785/7094 [1:58:57<05:25,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  78%|███████▊  | 1110/1419 [08:11<02:16,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6795/7094 [1:59:02<05:14,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  79%|███████▉  | 1120/1419 [08:15<02:12,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6805/7094 [1:59:06<05:03,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  80%|███████▉  | 1130/1419 [08:20<02:08,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6815/7094 [1:59:11<04:52,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  80%|████████  | 1140/1419 [08:24<02:03,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 6825/7094 [1:59:15<04:42,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  81%|████████  | 1150/1419 [08:29<01:58,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 6835/7094 [1:59:20<04:31,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  82%|████████▏ | 1160/1419 [08:33<01:54,  2.26it/s]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 6845/7094 [1:59:24<04:20,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  82%|████████▏ | 1170/1419 [08:37<01:49,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6855/7094 [1:59:28<04:09,  1.05s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  83%|████████▎ | 1180/1419 [08:42<01:45,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6865/7094 [1:59:33<03:59,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  84%|████████▍ | 1190/1419 [08:46<01:41,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6875/7094 [1:59:37<03:48,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  85%|████████▍ | 1200/1419 [08:51<01:37,  2.25it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6885/7094 [1:59:42<03:38,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  85%|████████▌ | 1210/1419 [08:55<01:32,  2.25it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6895/7094 [1:59:46<03:27,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  86%|████████▌ | 1220/1419 [09:00<01:28,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6905/7094 [1:59:51<03:16,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  87%|████████▋ | 1230/1419 [09:04<01:23,  2.26it/s]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 6915/7094 [1:59:55<03:06,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  87%|████████▋ | 1240/1419 [09:08<01:19,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6925/7094 [1:59:59<02:55,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  88%|████████▊ | 1250/1419 [09:13<01:14,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6935/7094 [2:00:04<02:45,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  89%|████████▉ | 1260/1419 [09:17<01:10,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6945/7094 [2:00:08<02:34,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n",
      "Validating:  89%|████████▉ | 1270/1419 [09:22<01:05,  2.26it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 6955/7094 [2:00:13<02:24,  1.04s/it, loss=2.53, v_num=260027, train_loss_step=2.580, val_loss_step=2.650, val_loss_epoch=2.550, train_loss_epoch=2.610]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  52%|█████▏    | 3705/7094 [1:12:18<1:06:08,  1.17s/it, loss=2.1, v_num=260027, train_loss_step=2.320, val_loss_step=2.550, val_loss_epoch=2.540, train_loss_epoch=2.280] "
     ]
    }
   ],
   "source": [
    "# model.train(train_df=output_df,\n",
    "#             eval_df=output_df, \n",
    "#             source_max_token_len=2048, \n",
    "#             target_max_token_len=1024, \n",
    "#             batch_size=2, max_epochs=5, use_gpu=True)\n",
    "# Split the data into training and evaluation sets\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from simplet5 import SimpleT5\n",
    "# Initialize SimpleT5\n",
    "model = SimpleT5()\n",
    "model.from_pretrained(model_type=\"t5\", model_name=\"pszemraj/long-t5-tglobal-base-16384-book-summary\")\n",
    "\n",
    "train_df, eval_df = train_test_split(output_df, test_size=0.2)\n",
    "model.train(train_df=train_df,\n",
    "            eval_df=eval_df, \n",
    "            source_max_token_len=2048, \n",
    "            target_max_token_len=1024, \n",
    "            batch_size=2, \n",
    "            max_epochs=8, \n",
    "            use_gpu=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4ad0a-ff95-4fe0-b384-c304d26018bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a44a76-aa0a-490a-9343-9d36df388996",
   "metadata": {},
   "source": [
    "# infrence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc6600b-2426-4343-a20c-54d59fb335b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF is set to: max_split_size_mb:256\n",
      "device: cuda\n",
      "device: cpu\n",
      "['review_id', 'pmid', 'title', 'abstract', 'target', 'background']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Memory optimization for CUDA\n",
    "max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF is set to: {os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "#when on Nvida machins \n",
    "device = torch.device(\"cuda\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "#when you are on mac\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# Load validation dataset from Hugging Face datasets\n",
    "dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='train')\n",
    "\n",
    "\n",
    "# Prepare DataFrame for output\n",
    "# output_df = pd.DataFrame(columns=['ReviewID', 'Candidate_Summary', 'Target'])\n",
    "output_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a89389b-cd92-4eb2-94bd-68cb51d34ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.drop(['pmid', 'title','background'], axis = 1, inplace = True) \n",
    "output_df['abstract'] = output_df['abstract'].apply(lambda x: \"\".join([f\"Study : \" + b for i,b in enumerate(x)]) )\n",
    "output_df.head(3)\n",
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00623548-b054-4223-9ed6-f7834b1bd8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Study : ABSTRACT A healthy intestinal microbio...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>Study : The effects of the soluble fiber konja...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24297836</td>\n",
       "      <td>Study : The aims of this study were 1 ) to eva...</td>\n",
       "      <td>Ensuring that the characteristics of the histo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  28514886  Study : ABSTRACT A healthy intestinal microbio...   \n",
       "1  18842808  Study : The effects of the soluble fiber konja...   \n",
       "2  24297836  Study : The aims of this study were 1 ) to eva...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  \n",
       "1  The use of glucomannan did not appear to signi...  \n",
       "2  Ensuring that the characteristics of the histo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04210d4-ff11-4b5c-ae31-5c4cc6720647",
   "metadata": {},
   "source": [
    "# in case you need Kmeans inputsimport pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7dfba4-7599-4874-9ba6-8686820b27a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the first dataset\n",
    "dataset_path = '/mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/BioBERT_K_Means_extractive.csv'\n",
    "summaries_dataset = pd.read_csv(dataset_path, index_col=0)\n",
    "\n",
    "# Rename the 'summary' column to 'abstract'\n",
    "summaries_dataset.rename(columns={'summary': 'abstract'}, inplace=True)\n",
    "\n",
    "# Convert the 'review_id' column in summaries_dataset to integer (if it's not already)\n",
    "summaries_dataset['review_id'] = summaries_dataset['review_id'].astype(int)\n",
    "\n",
    "summaries_dataset.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bcb4ae5-7c7b-4153-9a5b-4a72fc285e38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>No adverse effects were observed . The effects...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                           abstract  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "1   18842808  No adverse effects were observed . The effects...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  \n",
       "1  The use of glucomannan did not appear to signi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second dataset\n",
    "# (Assuming you have already loaded this dataset as 'output_df' in your previous steps)\n",
    "\n",
    "# Convert the 'review_id' column in output_df to integer (if it's not already)\n",
    "output_df['review_id'] = output_df['review_id'].astype(int)\n",
    "\n",
    "# Merge the two datasets based on 'review_id'\n",
    "merged_dataset = pd.merge(output_df, summaries_dataset[['review_id', 'abstract']], on='review_id', how='left')\n",
    "# merged_dataset.head(2)\n",
    "# merged_dataset.shape[0]\n",
    "# Replace the 'abstract' column in output_df with the one from summaries_dataset\n",
    "output_df['abstract'] = merged_dataset['abstract_y']\n",
    "output_df.head(2)\n",
    "\n",
    "# Now output_df will have the updated abstracts from summaries_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4f18f8-8025-4137-945c-dd6bc7b10d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7151cdb9-7847-4ae8-bac9-1a2478942ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>No adverse effects were observed . The effects...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24297836</td>\n",
       "      <td>Autonomic cardiovascular dysfunction accompani...</td>\n",
       "      <td>Ensuring that the characteristics of the histo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                           abstract  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "1   18842808  No adverse effects were observed . The effects...   \n",
       "2   24297836  Autonomic cardiovascular dysfunction accompani...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  \n",
       "1  The use of glucomannan did not appear to signi...  \n",
       "2  Ensuring that the characteristics of the histo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58143d77-678e-4095-8f3a-3189573fefe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.rename(columns={\"target\":\"target_text\", \"abstract\":\"source_text\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e607171c-c4f9-47e6-8aa6-1cce1f533d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conclusions The results of this systematic review and meta- analysis support the hypothesis that a high intake of galifidolide is associated with reduced risk of developing P. fecalis.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(output_df['source_text'][0])\n",
    "from simplet5 import SimpleT5\n",
    "\n",
    "# # Load your trained model\n",
    "model = SimpleT5()\n",
    "model.load_model(\"t5\",\"outputs/training_On_full_train(lowerModelsOnValidationKmeans)/simplet5-epoch-8-train-loss-2.0239-val-loss-2.6407\", use_gpu=True)\n",
    "\n",
    "text_to_summarize=output_df['source_text'][0]\n",
    "model.predict(text_to_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47424548-dcb2-4ea7-abab-a30e07a8cd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0188b54f-dd71-4c50-aff8-a845d6e75a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        source_text  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c85b4bbf-311f-4115-9d94-d6c36d484c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import os\n",
    "# from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch.cuda.amp import autocast\n",
    "\n",
    "# # Memory optimization for CUDA\n",
    "# max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "# print(f\"PYTORCH_CUDA_ALLOC_CONF is set to: {os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# # when on Nvida machins \n",
    "# device = torch.device(\"cuda\")\n",
    "# print(\"device:\", device)\n",
    "\n",
    "# # #when you are on mac\n",
    "# # device = torch.device(\"cpu\")\n",
    "# # print(\"device:\", device)\n",
    "\n",
    "\n",
    "# # Load LongT5 Model and Tokenizer\n",
    "# # model_to_use = \"google/long-t5-local-base\"\n",
    "# # model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "# # longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "# # longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "# # Load validation dataset from Hugging Face datasets\n",
    "# # dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "\n",
    "\n",
    "# # Prepare DataFrame for output\n",
    "# # output_df = pd.DataFrame(columns=['ReviewID', 'Candidate_Summary', 'Target'])\n",
    "# output_df = pd.DataFrame(dataset)\n",
    "\n",
    "# print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d71c6750-be25-41c2-a891-f0e4600d1c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# output_df.drop(['pmid', 'title','background'], axis = 1, inplace = True) \n",
    "# output_df['abstract'] = output_df['abstract'].apply(lambda x: \"\".join([f\"Study : \" + b for i,b in enumerate(x)]) )\n",
    "# output_df.rename(columns={\"target\":\"target_text\", \"abstract\":\"source_text\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8c23355-aa9e-4af9-a662-564e75de1831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abeccdba-f338-4c74-a085-ad6a11bd2329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        source_text  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edb51703-7cbe-48dc-b890-c9caa7c2e0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from simplet5 import SimpleT5\n",
    "\n",
    "# # Load your trained model\n",
    "# model = SimpleT5()\n",
    "# model.load_model(\"t5\", \"outputs/simplet5-epoch-9-train-loss-1.9464-val-loss-2.6663\", use_gpu=True)\n",
    "\n",
    "# # Assuming 'output_df' is already loaded and has columns 'review_id', 'source_text', and 'target_text'\n",
    "# batch_size = 1\n",
    "\n",
    "# # Initialize an empty DataFrame for the summaries\n",
    "# summary_df = pd.DataFrame()\n",
    "\n",
    "# # Process data in batches and generate summaries\n",
    "# for i in range(0, len(output_df), batch_size):\n",
    "#     batch_abstracts = output_df['source_text'][i: i + batch_size]\n",
    "#     batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "#     batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "#     # Generate summaries\n",
    "#     batch_summaries = [model.predict(abstract) for abstract in batch_abstracts]\n",
    "\n",
    "#     # Create a temporary DataFrame and append it to the summary DataFrame\n",
    "#     temp_df = pd.DataFrame({\n",
    "#         'ReviewID': batch_review_ids,\n",
    "#         'Candidate_Summary': batch_summaries,\n",
    "#         'Target': batch_targets\n",
    "#     })\n",
    "#     summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "# # Save the summary DataFrame to a CSV file\n",
    "# summary_df.to_csv('model_evaluation_output.csv', index=False)\n",
    "\n",
    "# # Display the summary DataFrame (optional)\n",
    "# display(summary_df)\n",
    "\n",
    "# # Examine a single review example (optional)\n",
    "# review_row = 5\n",
    "# print(\"CANDIDATE\")\n",
    "# print(summary_df.loc[review_row, \"Candidate_Summary\"])\n",
    "# print(\"TARGET\")\n",
    "# print(summary_df.loc[review_row, \"Target\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768cf72-b57a-4e6f-bf80-820f7dada389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26b8a964-42f2-4da4-ac0f-aa4b0008fbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewID</th>\n",
       "      <th>Candidate_Summary</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>[B-fibrinol, B. ifidium and B. boulardiium are...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>[Conclusions GM-C6 concentrations are signific...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24297836</td>\n",
       "      <td>[Autonomic systolic BP is significantly higher...</td>\n",
       "      <td>Ensuring that the characteristics of the histo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32367221</td>\n",
       "      <td>[Conclusions : Single-port ACL reconstruction ...</td>\n",
       "      <td>The QT autograft detected comparable rate of L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25038833</td>\n",
       "      <td>[The results of the meta-analyses indicate tha...</td>\n",
       "      <td>medicines with anti-cholinergic properties hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>19776504</td>\n",
       "      <td>[There was no evidence of a difference between...</td>\n",
       "      <td>This systematic review with meta- analysis fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>27505198</td>\n",
       "      <td>[Weight loss is associated with significant re...</td>\n",
       "      <td>A wide range of techniques have been evaluated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>25251296</td>\n",
       "      <td>[The BMD of low- and high-density lipoprotein ...</td>\n",
       "      <td>First , during anorexia nervosa adolescent fem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>23235652</td>\n",
       "      <td>[The results of this meta- analysis support th...</td>\n",
       "      <td>There is no convincing evidence that zinc supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>30058911</td>\n",
       "      <td>[Despite the heterogeneity of the human genome...</td>\n",
       "      <td>We argue that despite inconsistencies in the d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2021 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ReviewID                                  Candidate_Summary  \\\n",
       "0     28514886  [B-fibrinol, B. ifidium and B. boulardiium are...   \n",
       "1     18842808  [Conclusions GM-C6 concentrations are signific...   \n",
       "2     24297836  [Autonomic systolic BP is significantly higher...   \n",
       "3     32367221  [Conclusions : Single-port ACL reconstruction ...   \n",
       "4     25038833  [The results of the meta-analyses indicate tha...   \n",
       "...        ...                                                ...   \n",
       "2016  19776504  [There was no evidence of a difference between...   \n",
       "2017  27505198  [Weight loss is associated with significant re...   \n",
       "2018  25251296  [The BMD of low- and high-density lipoprotein ...   \n",
       "2019  23235652  [The results of this meta- analysis support th...   \n",
       "2020  30058911  [Despite the heterogeneity of the human genome...   \n",
       "\n",
       "                                                 Target  \n",
       "0     Current evidence from systematic review and me...  \n",
       "1     The use of glucomannan did not appear to signi...  \n",
       "2     Ensuring that the characteristics of the histo...  \n",
       "3     The QT autograft detected comparable rate of L...  \n",
       "4     medicines with anti-cholinergic properties hav...  \n",
       "...                                                 ...  \n",
       "2016  This systematic review with meta- analysis fou...  \n",
       "2017  A wide range of techniques have been evaluated...  \n",
       "2018  First , during anorexia nervosa adolescent fem...  \n",
       "2019  There is no convincing evidence that zinc supp...  \n",
       "2020  We argue that despite inconsistencies in the d...  \n",
       "\n",
       "[2021 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from simplet5 import SimpleT5\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Load your trained model\n",
    "model = SimpleT5()\n",
    "# model.load_model(\"t5\", \"outputs/simplet5-epoch-7-train-loss-2.1058-val-loss-2.5727\", use_gpu=True)\n",
    "model.load_model(\"t5\",\"outputs/training_On_full_train(lowerModelsOnValidationKmeans)/simplet5-epoch-8-train-loss-2.0239-val-loss-2.6407\", use_gpu=True)\n",
    "\n",
    "\n",
    "# Assuming 'output_df' is already loaded\n",
    "batch_size = 1\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(output_df), batch_size):\n",
    "    # Truncate source text to a reasonable length\n",
    "    batch_abstracts = output_df['source_text'][i: i + batch_size].str[:512]  # Adjust as needed\n",
    "    batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "    batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "    # Generate summaries with optimized parameters\n",
    "    batch_summaries = [model.predict(abstract) for abstract in batch_abstracts]\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'ReviewID': batch_review_ids,\n",
    "        'Candidate_Summary': batch_summaries,\n",
    "        'Target': batch_targets\n",
    "    })\n",
    "    summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "summary_df.to_csv('Regular_fineTuend_Kmeans_input_validation.csv', index=False)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b32997b-ca6f-4764-a34d-301b77d02c10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print (\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bbfa078-9ca0-4c02-817c-77344c607e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                       \n",
    "        \n",
    "#         # Combine the summaries from each abstract\n",
    "#         combined_summary += summary + ' '\n",
    "\n",
    "#     return {\"review_id\": review_id, \"summary\": combined_summary.strip()}\n",
    "\n",
    "# Apply the function to each element of the dataset\n",
    "# summaries_dataset = dataset.map(process_row)\n",
    "\n",
    "# # Convert to pandas DataFrame\n",
    "# df = pd.DataFrame(summaries_dataset)\n",
    "# df = df[['review_id', 'summary']]\n",
    "# # Save to CSV\n",
    "# csv_file_path = 'test.csv'  # Update with your desired file path\n",
    "# df.to_csv(csv_file_path, index=True)\n",
    "\n",
    "# print(f\"Saved summaries to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2216ee1-7af6-4e00-b894-c18ba2e65d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4dfcf-1355-45c1-912f-617d86c7b1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
