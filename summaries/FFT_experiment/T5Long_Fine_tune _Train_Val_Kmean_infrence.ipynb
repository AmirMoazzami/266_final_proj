{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6baf52d7-9b7e-477c-a1e4-161df03b3529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707c87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets sentencepiece rouge_score\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2385c429-3d90-412c-98ec-fd66c665efae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ytorch-lightning (/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip -q install torch\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28067337-faa8-4dee-ae51-b5a6b3f56de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722f043b-9ce4-402c-a11c-f1270ab1c501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF is set to: max_split_size_mb:256\n",
      "device: cpu\n",
      "['review_id', 'pmid', 'title', 'abstract', 'target', 'background']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Memory optimization for CUDA\n",
    "max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF is set to: {os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "#when on Nvida machins \n",
    "# device = torch.device(\"cuda\")\n",
    "# print(\"device:\", device)\n",
    "\n",
    "#when you are on mac\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "# Load LongT5 Model and Tokenizer\n",
    "# # model_to_use = \"google/long-t5-local-base\"\n",
    "# model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "# longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "# longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "# Load validation dataset from Hugging Face datasets\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "\n",
    "\n",
    "# Prepare DataFrame for output\n",
    "# output_df = pd.DataFrame(columns=['ReviewID', 'Candidate_Summary', 'Target'])\n",
    "output_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204c07ba-5173-4625-9643-b93211736d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>pmid</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "      <th>background</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>[15870317, 20863418, 17991656, 15585783, 20032...</td>\n",
       "      <td>[Quantitative Real-Time PCR Assays To Identify...</td>\n",
       "      <td>[ABSTRACT A healthy intestinal microbiota is c...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "      <td>Necrotizing enterocolitis ( NEC ) is one of th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                               pmid  \\\n",
       "0  28514886  [15870317, 20863418, 17991656, 15585783, 20032...   \n",
       "\n",
       "                                               title  \\\n",
       "0  [Quantitative Real-Time PCR Assays To Identify...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  [ABSTRACT A healthy intestinal microbiota is c...   \n",
       "\n",
       "                                              target  \\\n",
       "0  Current evidence from systematic review and me...   \n",
       "\n",
       "                                          background  \n",
       "0  Necrotizing enterocolitis ( NEC ) is one of th...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "847e1ad4-db68-447e-aea8-b398f174d113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.drop(['pmid', 'title','background'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbd1db-7ebc-402a-920b-7dcd48cb28fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f767c828-6b16-4f48-b768-f32f8f392689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>[ABSTRACT A healthy intestinal microbiota is c...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  28514886  [ABSTRACT A healthy intestinal microbiota is c...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12e54a5-fb63-4a05-a808-004d72d17280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df['abstract'] = output_df['abstract'].apply(lambda x: \"\".join([f\"Study : \" + b for i,b in enumerate(x)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed340481-15b9-4fac-a86f-77e7609f56f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Study : ABSTRACT A healthy intestinal microbio...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>Study : The effects of the soluble fiber konja...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24297836</td>\n",
       "      <td>Study : The aims of this study were 1 ) to eva...</td>\n",
       "      <td>Ensuring that the characteristics of the histo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  28514886  Study : ABSTRACT A healthy intestinal microbio...   \n",
       "1  18842808  Study : The effects of the soluble fiber konja...   \n",
       "2  24297836  Study : The aims of this study were 1 ) to eva...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  \n",
       "1  The use of glucomannan did not appear to signi...  \n",
       "2  Ensuring that the characteristics of the histo...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48dd9d16-5424-4d9c-91b6-a7ef0dced698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c7ca174-f4b4-454f-ab6f-56e71ab98912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers -q\n",
    "# !pip uninstall transformers\n",
    "# !pip install transformers\n",
    "# !pip uninstall -y pytorch-lightning\n",
    "# !pip install pytorch-lightning==1.5.10\n",
    "# !pip install -q --upgrade simplet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb4738fb-7770-4768-b124-7db68d83eb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !conda install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4112e2c1-e9de-4f14-87ad-cafc02ba47dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from sklearn.cluster import KMeans\n",
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# # Load the dataset and cut down to the first 5 for demonstration\n",
    "# # dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "# # dataset = dataset.select(range(3))  # Use select to create a subset\n",
    "\n",
    "# # Initialize BERT\n",
    "# # tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# # model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# def bert_sentence_embeddings(sentences):\n",
    "#     embeddings = []\n",
    "#     for sentence in sentences:\n",
    "#         inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True)\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(**inputs)\n",
    "#         embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "#     return np.array(embeddings)\n",
    "\n",
    "# def select_top_sentences(sentences, embeddings, n_sentences=5):\n",
    "#     if len(sentences) < n_sentences:\n",
    "#         return ' '.join(sentences)\n",
    "#     kmeans = KMeans(n_clusters=n_sentences, n_init=10)\n",
    "#     kmeans.fit(embeddings)\n",
    "#     top_sentences =[]\n",
    "#     i = 0\n",
    "#     while len(top_sentences) < n_sentences:\n",
    "#         top_sentence_indices = np.argmin(\n",
    "#         np.linalg.norm(embeddings[:, np.newaxis] - kmeans.cluster_centers_[i], axis=2), axis=0)\n",
    "#         top_sentences.append(sentences[top_sentence_indices[0]])\n",
    "#     return ' '.join(top_sentences)\n",
    "\n",
    "# def process_row( abstract_text):\n",
    "#     # Split abstract into sentences\n",
    "#     sentences = abstract_text.split('. ')\n",
    "#     # Generate embeddings for each sentence\n",
    "#     embeddings = bert_sentence_embeddings(sentences)\n",
    "#     # Select the top sentences from these embeddings\n",
    "#     summary = select_top_sentences(sentences, embeddings)\n",
    "        \n",
    "#     return summary\n",
    "        \n",
    "\n",
    "                             \n",
    "                             \n",
    "# output_df['abstract'] = output_df['abstract'].apply(lambda x:process_row(x) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1791ca14-a2ba-4420-bb15-7e3fcf706661",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Study : ABSTRACT A healthy intestinal microbio...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                           abstract  \\\n",
       "0  28514886  Study : ABSTRACT A healthy intestinal microbio...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad472d5-5d94-41ad-9417-1318e91bbb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06773bba-a77b-479c-996d-9838e2e8a9db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the dataset from a CSV file\n",
    "# dataset_path = '/mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/BioBERT_K_Means_extractive.csv'\n",
    "# summaries_dataset = pd.read_csv(dataset_path , index_col=False)\n",
    "# # Convert the dataset to a list of dictionaries\n",
    "# data_list = summaries_dataset.to_dict(orient='records')\n",
    "# summaries_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3dc79a-6a57-458f-be8c-e30321a185c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18842808</td>\n",
       "      <td>No adverse effects were observed . The effects...</td>\n",
       "      <td>The use of glucomannan did not appear to signi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                           abstract  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "1   18842808  No adverse effects were observed . The effects...   \n",
       "\n",
       "                                              target  \n",
       "0  Current evidence from systematic review and me...  \n",
       "1  The use of glucomannan did not appear to signi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first dataset\n",
    "dataset_path = '/mnt/wekamount/RI-Users/amir.moazami/Projects/266/266_final_proj/BioBERT_K_Means_extractive.csv'\n",
    "summaries_dataset = pd.read_csv(dataset_path, index_col=False)\n",
    "summaries_dataset.shape\n",
    "# Rename the 'summary' column to 'abstract'\n",
    "summaries_dataset.rename(columns={'summary': 'abstract'}, inplace=True)\n",
    "\n",
    "# Convert the 'review_id' column in summaries_dataset to integer (if it's not already)\n",
    "summaries_dataset['review_id'] = summaries_dataset['review_id'].astype(int)\n",
    "\n",
    "# Load the second dataset\n",
    "# (Assuming you have already loaded this dataset as 'output_df' in your previous steps)\n",
    "\n",
    "# Convert the 'review_id' column in output_df to integer (if it's not already)\n",
    "output_df['review_id'] = output_df['review_id'].astype(int)\n",
    "\n",
    "# Merge the two datasets based on 'review_id'\n",
    "merged_dataset = pd.merge(output_df, summaries_dataset[['review_id', 'abstract']], on='review_id', how='left')\n",
    "# merged_dataset.head(2)\n",
    "# merged_dataset.shape[0]\n",
    "# Replace the 'abstract' column in output_df with the one from summaries_dataset\n",
    "output_df['abstract'] = merged_dataset['abstract_y']\n",
    "output_df.head(2)\n",
    "\n",
    "# Now output_df will have the updated abstracts from summaries_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93795d07-ba9f-4ba0-87da-666e2d24a9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.rename(columns={\"target\":\"target_text\", \"abstract\":\"source_text\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04db8e34-06fe-42f6-8484-e3f2c513a4b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        source_text  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31a80d25-9352-4852-8164-be8882e8b86d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8de3d8c-92ff-42f7-b4d2-0e4972e72c9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load LongT5 Model and Tokenizer\n",
    "# model_to_use = \"google/long-t5-local-base\"\n",
    "# model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "# longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "# longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "from simplet5 import SimpleT5\n",
    "model=SimpleT5()\n",
    "model.from_pretrained(model_type=\"longt5\",model_name=\"pszemraj/long-t5-tglobal-base-16384-book-summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d919a104-c929-4dee-a117-1ac965a19cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model.train(train_df=output_df,\n",
    "# #             eval_df=output_df, \n",
    "# #             source_max_token_len=2048, \n",
    "# #             target_max_token_len=1024, \n",
    "# #             batch_size=2, max_epochs=5, use_gpu=True)\n",
    "# # Split the data into training and evaluation sets\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from simplet5 import SimpleT5\n",
    "# # Initialize SimpleT5\n",
    "# model = SimpleT5()\n",
    "# model.from_pretrained(model_type=\"t5\", model_name=\"pszemraj/long-t5-tglobal-base-16384-book-summary\")\n",
    "\n",
    "# train_df, eval_df = train_test_split(output_df, test_size=0.2)\n",
    "# model.train(train_df=train_df,\n",
    "#             eval_df=eval_df, \n",
    "#             source_max_token_len=2048, \n",
    "#             target_max_token_len=1024, \n",
    "#             batch_size=2, \n",
    "#             max_epochs=10, \n",
    "#             use_gpu=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c4ad0a-ff95-4fe0-b384-c304d26018bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e607171c-c4f9-47e6-8aa6-1cce1f533d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Conclusions The results of this systematic review and meta- analysis support the hypothesis that a high intake of galifidolide is associated with reduced risk of developing P. fecalis.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.predict(output_df['source_text'][0])\n",
    "\n",
    "model.load_model(\"t5\",\"outputs/training_On_full_train(lowerModelsOnValidationKmeans)/simplet5-epoch-8-train-loss-2.0239-val-loss-2.6407\", use_gpu=True)\n",
    "\n",
    "text_to_summarize=output_df['source_text'][0]\n",
    "model.predict(text_to_summarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47424548-dcb2-4ea7-abab-a30e07a8cd0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0188b54f-dd71-4c50-aff8-a845d6e75a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Breast-fed infants typically have an intestina...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                        source_text  \\\n",
       "0   28514886  Breast-fed infants typically have an intestina...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85b4bbf-311f-4115-9d94-d6c36d484c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_CUDA_ALLOC_CONF is set to: max_split_size_mb:256\n",
      "device: cuda\n",
      "['review_id', 'pmid', 'title', 'abstract', 'target', 'background']\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# Memory optimization for CUDA\n",
    "max_split_size_mb = 256  # Set the max_split_size_mb value (e.g., 512 MB)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = f\"max_split_size_mb:{max_split_size_mb}\"\n",
    "print(f\"PYTORCH_CUDA_ALLOC_CONF is set to: {os.environ['PYTORCH_CUDA_ALLOC_CONF']}\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "# when on Nvida machins \n",
    "device = torch.device(\"cuda\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# #when you are on mac\n",
    "# device = torch.device(\"cpu\")\n",
    "# print(\"device:\", device)\n",
    "\n",
    "\n",
    "# Load LongT5 Model and Tokenizer\n",
    "# model_to_use = \"google/long-t5-local-base\"\n",
    "model_to_use = \"pszemraj/long-t5-tglobal-base-16384-book-summary\"  # fined-tuned for summarization\n",
    "longt5_model = LongT5ForConditionalGeneration.from_pretrained(model_to_use).to(device)\n",
    "longt5_tokenizer = AutoTokenizer.from_pretrained(model_to_use)\n",
    "\n",
    "# Load validation dataset from Hugging Face datasets\n",
    "# dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "dataset = load_dataset(\"allenai/mslr2022\", \"ms2\", split='validation')\n",
    "\n",
    "\n",
    "# Prepare DataFrame for output\n",
    "# output_df = pd.DataFrame(columns=['ReviewID', 'Candidate_Summary', 'Target'])\n",
    "output_df = pd.DataFrame(dataset)\n",
    "\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71c6750-be25-41c2-a891-f0e4600d1c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "output_df.drop(['pmid', 'title','background'], axis = 1, inplace = True) \n",
    "output_df['abstract'] = output_df['abstract'].apply(lambda x: \"\".join([f\"Study : \" + b for i,b in enumerate(x)]) )\n",
    "output_df.rename(columns={\"target\":\"target_text\", \"abstract\":\"source_text\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c23355-aa9e-4af9-a662-564e75de1831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abeccdba-f338-4c74-a085-ad6a11bd2329",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>source_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28514886</td>\n",
       "      <td>Study : ABSTRACT A healthy intestinal microbio...</td>\n",
       "      <td>Current evidence from systematic review and me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_id                                        source_text  \\\n",
       "0  28514886  Study : ABSTRACT A healthy intestinal microbio...   \n",
       "\n",
       "                                         target_text  \n",
       "0  Current evidence from systematic review and me...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb51703-7cbe-48dc-b890-c9caa7c2e0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from simplet5 import SimpleT5\n",
    "\n",
    "# # Load your trained model\n",
    "# model = SimpleT5()\n",
    "# model.load_model(\"t5\", \"outputs/simplet5-epoch-9-train-loss-1.9464-val-loss-2.6663\", use_gpu=True)\n",
    "\n",
    "# # Assuming 'output_df' is already loaded and has columns 'review_id', 'source_text', and 'target_text'\n",
    "# batch_size = 1\n",
    "\n",
    "# # Initialize an empty DataFrame for the summaries\n",
    "# summary_df = pd.DataFrame()\n",
    "\n",
    "# # Process data in batches and generate summaries\n",
    "# for i in range(0, len(output_df), batch_size):\n",
    "#     batch_abstracts = output_df['source_text'][i: i + batch_size]\n",
    "#     batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "#     batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "#     # Generate summaries\n",
    "#     batch_summaries = [model.predict(abstract) for abstract in batch_abstracts]\n",
    "\n",
    "#     # Create a temporary DataFrame and append it to the summary DataFrame\n",
    "#     temp_df = pd.DataFrame({\n",
    "#         'ReviewID': batch_review_ids,\n",
    "#         'Candidate_Summary': batch_summaries,\n",
    "#         'Target': batch_targets\n",
    "#     })\n",
    "#     summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "# # Save the summary DataFrame to a CSV file\n",
    "# summary_df.to_csv('model_evaluation_output.csv', index=False)\n",
    "\n",
    "# # Display the summary DataFrame (optional)\n",
    "# display(summary_df)\n",
    "\n",
    "# # Examine a single review example (optional)\n",
    "# review_row = 5\n",
    "# print(\"CANDIDATE\")\n",
    "# print(summary_df.loc[review_row, \"Candidate_Summary\"])\n",
    "# print(\"TARGET\")\n",
    "# print(summary_df.loc[review_row, \"Target\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768cf72-b57a-4e6f-bf80-820f7dada389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26b8a964-42f2-4da4-ac0f-aa4b0008fbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/wekamount/RI-Users/amir.moazami/Projects/266/.venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'model_evaluation_output_\"outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     73\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m---> 75\u001b[0m \u001b[43msummary_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_evaluation_output_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutputs/training_On_full_Kmeans_val_inputs_train-loss-2.0239-val-loss-2.6407\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m display(summary_df)\n",
      "File \u001b[0;32m~/Projects/266/.venv/lib/python3.8/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/266/.venv/lib/python3.8/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Projects/266/.venv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/Projects/266/.venv/lib/python3.8/site-packages/pandas/io/common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 737\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/266/.venv/lib/python3.8/site-packages/pandas/io/common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'model_evaluation_output_\"outputs'"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from simplet5 import SimpleT5\n",
    "# import torch\n",
    "# import gc\n",
    "\n",
    "# # Load your trained model\n",
    "# model = SimpleT5()\n",
    "# model.load_model(\"t5\", \"outputs/simplet5-epoch-9-train-loss-1.9464-val-loss-2.6663\", use_gpu=True)\n",
    "\n",
    "# # Assuming 'output_df' is already loaded\n",
    "# batch_size = 1\n",
    "# summary_df = pd.DataFrame()\n",
    "\n",
    "# for i in range(0, len(output_df), batch_size):\n",
    "#     batch_abstracts = output_df['source_text'][i: i + batch_size]\n",
    "#     batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "#     batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "#     # Generate summaries\n",
    "#     batch_summaries = [model.predict(abstract) for abstract in batch_abstracts]\n",
    "\n",
    "#     temp_df = pd.DataFrame({\n",
    "#         'ReviewID': batch_review_ids,\n",
    "#         'Candidate_Summary': batch_summaries,\n",
    "#         'Target': batch_targets\n",
    "#     })\n",
    "#     summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "#     # Memory cleanup\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     # Memory cleanup\n",
    "#     # del inputs\n",
    "#     # del summary_ids\n",
    "#     # del batch_summaries\n",
    "#     # gc.collect()\n",
    "#     # torch.cuda.empty_cache()\n",
    "\n",
    "# summary_df.to_csv('model_evaluation_output.csv', index=False)\n",
    "# display(summary_df)\n",
    "import pandas as pd\n",
    "from simplet5 import SimpleT5\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Load your trained model\n",
    "model = SimpleT5()\n",
    "model.load_model(\"t5\", \"outputs/training_On_full_train(lowerModelsOnValidationKmeans)/simplet5-epoch-8-train-loss-2.0239-val-loss-2.6407\", use_gpu=True)\n",
    "\n",
    "# Assuming 'output_df' is already loaded\n",
    "batch_size = 1\n",
    "summary_df = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(output_df), batch_size):\n",
    "    # Truncate source text to a reasonable length\n",
    "    batch_abstracts = output_df['source_text'][i: i + batch_size].str[:512]  # Adjust as needed\n",
    "    batch_review_ids = output_df['review_id'][i: i + batch_size]\n",
    "    batch_targets = output_df['target_text'][i: i + batch_size] if 'target_text' in output_df.columns else [''] * batch_size\n",
    "\n",
    "    # Generate summaries with optimized parameters\n",
    "    batch_summaries = [model.predict(abstract, max_length=1280) for abstract in batch_abstracts]\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'ReviewID': batch_review_ids,\n",
    "        'Candidate_Summary': batch_summaries,\n",
    "        'Target': batch_targets\n",
    "    })\n",
    "    summary_df = pd.concat([summary_df, temp_df], ignore_index=True)\n",
    "\n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "summary_df.to_csv('model_evaluation_output_\"outputs/training_On_full_Kmeans_val_inputs_train-loss-2.0239-val-loss-2.6407\"', index=False)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32997b-ca6f-4764-a34d-301b77d02c10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bbfa078-9ca0-4c02-817c-77344c607e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "                       \n",
    "        \n",
    "#         # Combine the summaries from each abstract\n",
    "#         combined_summary += summary + ' '\n",
    "\n",
    "#     return {\"review_id\": review_id, \"summary\": combined_summary.strip()}\n",
    "\n",
    "# Apply the function to each element of the dataset\n",
    "# summaries_dataset = dataset.map(process_row)\n",
    "\n",
    "# # Convert to pandas DataFrame\n",
    "# df = pd.DataFrame(summaries_dataset)\n",
    "# df = df[['review_id', 'summary']]\n",
    "# # Save to CSV\n",
    "# csv_file_path = 'test.csv'  # Update with your desired file path\n",
    "# df.to_csv(csv_file_path, index=True)\n",
    "\n",
    "# print(f\"Saved summaries to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2216ee1-7af6-4e00-b894-c18ba2e65d15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
